{"./":{"url":"./","title":"Introduction","keywords":"","body":"Introduction 版权所有，盗版必究 all right reserved，powered by GitbookLast Modified On： 2021-10-17 15:13:54 "},"java/2019-08-12-简易却高效的HashMap实现.html":{"url":"java/2019-08-12-简易却高效的HashMap实现.html","title":"简易却高效的HashMap实现","keywords":"","body":"目录 目录 原理 代码实现 性能测试 总结 原理 我们每天都在使用HashMap,有没有想过,在很多情景下,HashMap做的其实没有特别好,他是一个很通用的k-v数据结构,却不一定在各个小方面都适合.因此我们实现了一个特定场景下使用的HashMap. 对于HashMap的原理,本文不做过分的重复,不甚了解的同学可以看一下 这篇文章. 我们可以针对基本类型实现自己的HashMap.比如IntHashMap. 当我们日常想要使用int->int的k-v形式的时候,我们必须使用HashMap,因为HashMap不支持基本类型,只支持对象,那么我们为了存储一个4字节的int类型,使用了多少空间呢? 首先包装类至少12字节(对象头8+对其填充4).然后在Hashmap中存放的是entry对象的数组,一个entry对象至少20几个字节了,然后entry持有的k-v.又有对象头.这样算下来,光对象头就32字节,加上一些填充和对象中的辅助变量,50字节差不多了. 而我们的初衷只是为了存储8个字节极其对应关系. 这个时候就想,当key和value都是int的时候,底层我们直接使用int数组好了. 数据结构确定之后,我们逐一确定下其他要素: 构造方法: 我们强制必须传入一个初始的容量值.然后初始化.容量的计算参考HashMap的. put方法: 我们对key进行hash取模后,依次放置,如果冲突,不采用拉链法,而是线性探测,向后遍历,找到空位置放下.减小我们的数据结构的复杂度. get方法: get方法没什么好讲的,hash然后寻找. 代码实现 下面具体的代码实现: /** * Created by pfliu on 2019/08/07. */ public class IntHashMap { private int[] keys; private int[] vals; private int size = 0; public IntHashMap(int capacity) { capacity = tableSizeFor(capacity); keys = new int[capacity]; vals = new int[capacity]; } public int size() { return size; } public int get(int key) { int h = hash(key); int size_1 = keys.length - 1; final int LOOP_UNROLLING = 3; for (int i = 0; i > 1) > keys.length) { int[] oldKeys = this.keys; int[] oldVals = this.vals; this.keys = new int[oldKeys.length * 2]; this.vals = new int[oldKeys.length * 2]; this.size = 0; for (int i = 0; i >> 1; n |= n >>> 2; n |= n >>> 4; n |= n >>> 8; n |= n >>> 16; return (n >> 16) ^ x) * 0x45d9f3b; x = ((x >>> 16) ^ x) * 0x45d9f3b; x = (x >>> 16) ^ x; return x; } } 性能测试 测试方法如下: 对IntHashMap和HashMap分别进行随机数字的X次插入和取出.统计时间以及占用内存大小.统计结果如下: 其中T1=IntHashMap消耗时间,T2=HashMap消耗时间,M1=IntHashMap占用内存,M2=HashMap占用内存. 其中时间单位为ms,内存占用单位为字节. Table T1 T2 M1 M2 10000 6ms 7ms 524344 666304 100000 17ms 31ms 1048632 4576320 1000000 157ms 299ms 8388664 44626736 10000000 2184ms 7613ms 134217784 471696400 测试代码如下: import jdk.nashorn.internal.ir.debug.ObjectSizeCalculator; import org.junit.Test; import java.util.*; public class IntHashMapTest { static final int NUM = 10000000; @Test public void t() { // 7,8 万的亚子 Ticker ticker = new Ticker(); IntHashMap intHashMap = new IntHashMap(1 map = new HashMap<>(1 总结 从测试结果我们可以看出来,效果还是不错的,因此在很追求性能的条件下,如有使用基本类型的HashMap的需求,不妨自己试一下.按照图中的代码,可以很轻易的扩展出针对long,float等其他基本类型的定制版HashMap. 完。 ChangeLog 2019-08-12 完成 以上皆为个人所思所得，如有错误欢迎评论区指正。 欢迎转载，烦请署名并保留原文链接。 联系邮箱：huyanshi2580@gmail.com 更多学习笔记见个人博客------>呼延十 版权所有，盗版必究 all right reserved，powered by GitbookLast Modified On： 2019-08-13 10:21:58 "},"java/2019-09-09-多级-HashMap的优化.html":{"url":"java/2019-09-09-多级-HashMap的优化.html","title":"多级-HashMap的优化","keywords":"","body":"最近忙的好久没有写文章了, 随便写点东西~ Java程序员想必对Map>类型的数据结构很熟悉, 并且深恶痛绝,在以前介绍过一种通用的处理方法, 我们可以用一些三方包或者自定义一种Table的数据结构, 可以让代码稍微清晰一点. 今天提出一个在特定条件下的解决方案: 当数据结构为Map> 当前很追求性能. 解决方案其实是利用了int 32位, long 64位, 使用一个long来存储两个int. 如下面的代码: // int->(int->double) Map> a = new HashMap<>(); Map value = new HashMap<>(); value.put(2, 0.2); a.put(1, value); //long->double Map b = new HashMap<>(); b.put((1L 我对以上这种方式进行了一些测试, 数据统计如下: 次数 两个int long long/int时间比例 1000000 0.64ms 10000000 163ms 103ms 0.65 100000000 1010ms 648 0.68 可以看到, 性能优化之后,时间基本上是原来的65%左右, 如果还想优化的话, 可以使用 简易却高效的HashMap实现文章中的方式,实现自己的IntHashMap,性能还能有一些提高. 在日常的编码中,我们更倾向于\"通用\",比如封装一个类,在什么情况下都能用, 什么对象都能存放,但在一些极致追求性能的场景, 一些定制化开发往往能够提升更多的性能. 完。 ChangeLog 2019-09-09 完成 以上皆为个人所思所得，如有错误欢迎评论区指正。 欢迎转载，烦请署名并保留原文链接。 联系邮箱：huyanshi2580@gmail.com 更多学习笔记见个人博客------>呼延十 版权所有，盗版必究 all right reserved，powered by GitbookLast Modified On： 2019-09-09 18:20:27 "},"java/集合/2019-04-27-Java对阻塞队列的实现.html":{"url":"java/集合/2019-04-27-Java对阻塞队列的实现.html","title":"Java对阻塞队列的实现","keywords":"","body":"什么是阻塞队列? 阻塞队列与队列基本一致,额外的支持阻塞添加和阻塞删除方法. 阻塞添加: 当队列满时,线程不断尝试向其中添加,直到有其他线程取走元素,使添加操作成功,在此期间,线程阻塞. 阻塞删除: 当队列为空时,线程不断尝试取出队头元素,直到有其他线程添加元素,使删除操作成功,在此期间,线程阻塞. 怎么实现阻塞呢?可以使用Java中Object类的wait(),notify(),notifyAll()等方法来实现. 阻塞添加: 当队列满的时候,当前线程阻塞,当生产成功之后,唤醒消费者(此时队列中至少有一个元素). 阻塞删除: 等队列为空的时候,当前线程阻塞,当消费成功后,唤醒生产者(此时队列中只有有一个空的位置可以用来添加元素). 更多的原理让注释体现吧! 下面的代码是一个简易版本的实现,仅仅实现了阻塞方法,对于队列常规的添加和移除方法没有实现: import mian.AbstractMain; import java.util.LinkedList; import java.util.concurrent.atomic.AtomicInteger; /** * Created by pfliu on 2019/04/28. */ public class BlockingQueueT extends AbstractMain { // 存放元素的linkedlist private LinkedList items = new LinkedList<>(); // 计数,使用AtomicInteger,防止冲突 private AtomicInteger count = new AtomicInteger(0); //定义队列的最大值与最小值,也就是(满/空)的定义,当然这里可以用其他方式实现,比如用一个定长的数组. private final int max = 100; private final int min = 0; // 新建一个对象,用来充当锁的作用 private final Object lock = new Object(); public void put(Integer integer) throws InterruptedException { // 加锁 synchronized (lock) { // 如果队列是满的,则当前线程不断的等待 while (count.get() == max) { lock.wait(); } // 添加元素,计数增加并且唤醒消费者 items.add(integer); count.incrementAndGet(); lock.notifyAll(); } } public Integer pop() throws InterruptedException { // 加锁 synchronized (lock) { // 如果队列是空的,则当前线程不断的等待 while (count.get() == min) { lock.wait(); } // 获取结果值,计数减少,唤醒消费者,返回结果 Integer ret = items.getFirst(); items.removeFirst(); count.decrementAndGet(); lock.notifyAll(); return ret; } } public static void main(String[] args) throws InterruptedException { new BlockingQueueT().parseArgsAndRun(args); } @Override public void run() throws InterruptedException { BlockingQueueT bt = new BlockingQueueT(); // 生成这线程,生成1000个元素 Thread producer = new Thread(() -> { for (int i = 0; i { while (true) { try { logger.info(\"get : {}\", bt.pop()); } catch (InterruptedException e) { e.printStackTrace(); } } }); consumer.setName(\"consumer\"); consumer.start(); } } 在main方法中,我们进行了一些测试,启动了一个生产者线程,不断的向阻塞队列中添加元素,同时启动了一个消费者线程,无限的从队列中读取.可以预期的是,在程序刚开始运行的时候,读写都会运行,而当生产者到1000之后停止,消费者会阻塞. 标准输出太多了不贴了,但是通过arthas可以看到当前的线程状态,可以看到消费者是出于wait状态的. 当然我们自己实现的这个考虑肯定不是很周全,那么就来看一下Java对阻塞队列的一些实现. ArrayBlockingQueue 首先来看一下ArrayBlockingQueue,它是一个使用定长的数组来实现的有界的阻塞队列,和我们实现的基本类似,只是加锁使用ReentrantLock实现,且存储结构使用数组,需要记忆当前的添加位置以及弹出位置.队列中的顺序使用FIFO策略. 此外,当多个线程阻塞等待入队或者出队时候,ArrayBlockingQueue支持公平和非公平两种形式. 构造方法 由于是有界的阻塞队列,所以构造时都需要传入队列的大小. ArrayblockingQueue有三个构造方法,如下: public ArrayBlockingQueue(int capacity) { this(capacity, false); } public ArrayBlockingQueue(int capacity, boolean fair) { if (capacity c) { this(capacity, fair); final ReentrantLock lock = this.lock; lock.lock(); // Lock only for visibility, not mutual exclusion try { int i = 0; try { for (E e : c) { checkNotNull(e); items[i++] = e; } } catch (ArrayIndexOutOfBoundsException ex) { throw new IllegalArgumentException(); } count = i; putIndex = (i == capacity) ? 0 : i; } finally { lock.unlock(); } } 可以发现,第一个和第三个构造方法都是对第二个的调用,而第二个构造方法中,初始化了存放元素的数组,以及用于实现阻塞机制的锁等. 插入方法 add(E) 如果队列不满则添加元素,如果队列满则抛出IllegalStateException异常.在阻塞队列中不建议使用. public boolean add(E e) { return super.add(e); } public boolean add(E e) { if (offer(e)) return true; else throw new IllegalStateException(\"Queue full\"); } offer(E) 如果队列不满,则添加元素,队列满则返回false.不抛异常. public boolean offer(E e) { checkNotNull(e); final ReentrantLock lock = this.lock; lock.lock(); try { if (count == items.length) return false; else { enqueue(e); return true; } } finally { lock.unlock(); } } offer(E,int,TimeUnit) 上一个offer方法的带有超时时间的版本,当队列满时,会尝试知道超时时间结束才返回false. public boolean offer(E e, long timeout, TimeUnit unit) throws InterruptedException { checkNotNull(e); long nanos = unit.toNanos(timeout); final ReentrantLock lock = this.lock; lock.lockInterruptibly(); try { while (count == items.length) { if (nanos put 当队列满时,线程等待,知道可以放入元素再执行操作. public void put(E e) throws InterruptedException { checkNotNull(e); final ReentrantLock lock = this.lock; lock.lockInterruptibly(); try { while (count == items.length) notFull.await(); enqueue(e); } finally { lock.unlock(); } } 移除方法 poll 当队列为空时,返回null.不为空则返回队头元素. public E poll() { final ReentrantLock lock = this.lock; lock.lock(); try { return (count == 0) ? null : dequeue(); } finally { lock.unlock(); } } poll(long,TimeUnit) 上一个poll方法的超时版本.当队列为空时,尝试获取元素,知道超时时间到达,返回null. public E poll(long timeout, TimeUnit unit) throws InterruptedException { long nanos = unit.toNanos(timeout); final ReentrantLock lock = this.lock; lock.lockInterruptibly(); try { while (count == 0) { if (nanos take 弹出元素的阻塞实现,当队列为空时,阻塞等待,知道可以获取到元素. public E take() throws InterruptedException { final ReentrantLock lock = this.lock; lock.lockInterruptibly(); try { while (count == 0) notEmpty.await(); return dequeue(); } finally { lock.unlock(); } } remove 循环删除某个元素. public boolean remove(Object o) { if (o == null) return false; final Object[] items = this.items; final ReentrantLock lock = this.lock; lock.lock(); try { if (count > 0) { final int putIndex = this.putIndex; int i = takeIndex; do { if (o.equals(items[i])) { removeAt(i); return true; } if (++i == items.length) i = 0; } while (i != putIndex); } return false; } finally { lock.unlock(); } } 其他方法 peek 返回队头的元素,但是该元素不出队. public E peek() { final ReentrantLock lock = this.lock; lock.lock(); try { return itemAt(takeIndex); // null when queue is empty } finally { lock.unlock(); } } size 返回当前队列中的元素数量. public int size() { final ReentrantLock lock = this.lock; lock.lock(); try { return count; } finally { lock.unlock(); } } remainingCapacity 返回当前队列中空闲的位置的数量. public int remainingCapacity() { final ReentrantLock lock = this.lock; lock.lock(); try { return items.length - count; } finally { lock.unlock(); } } LinkedBlockingQueue LinkedBlockingQueue的实现思路与ArrayBlockingQueue基本一致,只是将锁分为了取出锁和插入锁.当插入和取出数据时,可以分开加锁,互不影响.且它可以是无界的. ChangeLog 2019-04-28 完成 以上皆为个人所思所得，如有错误欢迎评论区指正。 欢迎转载，烦请署名并保留原文链接。 联系邮箱：huyanshi2580@gmail.com 更多学习笔记见个人博客------>呼延十 版权所有，盗版必究 all right reserved，powered by GitbookLast Modified On： 2019-05-05 20:25:55 "},"java/集合/2019-05-01-Guava中的一些增强集合类.html":{"url":"java/集合/2019-05-01-Guava中的一些增强集合类.html","title":"Guava中的一些增强集合类","keywords":"","body":"写了好多和Java集合类有关的文章,学习了好多集合类的用法,有没有感觉还是有一些常见的需求集合类没有办法满足呢?需要自己使用Java集合中的类去实现,但是这种常用的轮子Google和apache都帮我们造好啦. Java相关的工具包中有两个很有名,Google Guava和Apache Commons,今天就来看一下Guava中实现的一些其他的集合类,基本上都是在JDK的集合类上做了一些增强. Immutable Collections -> 真正的不可修改的集合 在上文Java Collections中,提到了Collections类中提供了一些可以返回集合不可变视图的方法,我们现在来试用一下. 我们新建一个包含5个元素的list.然后创建一个它的不可变视图. List list = new ArrayList<>(Arrays.asList(1,2,3,4,5)); List umList = Collections.unmodifiableList(list); 经过上面的步骤,我们拿到了umList,他是不可变的,但是list没有消失,它仍然是可变的,我们可以通过给list添加一个值来改变umList的元素集. 因为在Collections.unmodifiableList中,持有了一个list的引用,所有对list的更改也会同步体现在umList上. 而且上面的代码中,多了一个中间变量list.因为我们不需要它,我们创建它只是为了获取后面的不可变集合.比较繁琐. 使用Guava怎么做呢?像下面这样: ImmutableCollection li = ImmutableList.of(1, 2, 3, 4, 5); 是不是感觉清晰了很多,同时,这个li是真正的不可变的. ImmutableList还提供了多种创建的方法,比如: 使用任意个元素的参数直接创建. 使用copyOf从一个已有的List来创建 提供Builder模式来进行链式调用. 上面的代码以ImmutableList举例,但是Guava还提供了ImmutableSet,ImmutableMap,ImmutableCollection等类,可以根据需要的数据结构分别调用. MultiMap -> Map>的另一种解决办法 我们经常会有一种需求,需要在Map结构里面存List/Set. 比如,统计用户的签到日期用来画日历,那么我们想要的数据是:name->[2019-04-01,2019-04-28]这样子的数据结构. 那么我们先加入一个用户在5月1号的签到记录怎么办呢?写一下子代码, // 模拟已有的数据结构 static Map> userSign = new HashMap<>(); // 新放进去一条数据 public static void putIt(String name, String date) { // 正式的逻辑部分 List dates = userSign.getOrDefault(name, new ArrayList<>()); if (!dates.contains(date)) { dates.add(date); } userSign.put(name, dates); } 可以看到比较麻烦,而且要不是有Map的getOrDefault()方法,代码还得多几行,因为还要分为已存在和未存在来搞.. Guava中提供了一种数据结构,来保存这种一个key对应多个value的情况,就是MultiMap. 虽然他的名字带有map,但是看源码可以发现,他的类生命没有继承Map接口. 要使用MultiMap来实现上面的方法,只需要这样子: ArrayListMultimap userSign = ArrayListMultimap.create(); userSign.put(\"huyan\", \"2019-05-01\"); userSign.put(\"huyan\", \"2019-05-02\"); List huyanSign = userSign.get(\"huyan\"); 是的,直接声明放入就好了,要消费的时候,使用get方法可以获得一个Arratlist,遍历操作即可. 下载了Guava的源码就可以发现,其实他里面就是用Map>来实现的,这是定义的地方: 可以看到定义了一个:Map.定义为Collection是为了实现其他的集中数据结构. 比如: HashMultimap的值是放在set中 LinkedListMultimap的值放在LinkedList中. 等等. Multiset -> 一个名叫set的计数器 老实说这个挺好用的,但是为啥要叫set呢...大家对set的印象都是不可以放入重复元素,但是Multiset的作用就是对重复元素计数.. 使用方式如下: Multiset s = HashMultiset.create(); s.add(\"pf\"); s.add(\"pf\"); s.add(\"pf\"); s.add(\"hh\"); // i =3 int i = s.count(\"pf\"); 这个和我前几天写的计数器的作用是一样的,计数器传送门. 内部实现使用HashMap来保存key->count的一个映射关系. BiMap -> value也不可以重复的双向Map 这个类是真的实现了JDK的Map接口的,使用它必须保证key和value都没有重复值.因为他支持根据value获取key,即将HashMap的key和value进行调换. BiMap m = HashBiMap.create(); m.put(\"pf\", \"111\"); String value = m.get(\"pf\"); String key = m.inverse().get(\"111\"); 这个类适合用在key和value都唯一,且经常会出现根据value来获取key的情况. Table -> Map>的解决方案 碰到多个索引一个结果的时候,Map>这种实现方式当然是可以的,但是实在是太让人难以看懂和编码了. Guava提供了一种名叫Table的数据结构,可以优雅的实现. 使用如下: Table tt = HashBasedTable.create(); tt.put(1, 2, \"huyan\"); String name = tt.get(1, 2); Map row = tt.row(1); Map colum = tt.column(1); Set> ha = tt.cellSet(); 初始化方式和上面的几种结构没有什么区别,都是通过静态工厂方法进行初始化,get和put方法根据两个索引来存放和唯一索引一条数据. 此外,还可以拿到某一行或者某一列的Map结构,可以拿到所有单元格的一个set.极大的方便了处理类似于表格的数据. 当然,看一下源码就会发现,其实Table底层也是使用两个map的嵌套实现的,但是Java语言嘛,讲究的就是一个封装,虽然我们可以自己实现,但是我们应该做的是去学习一下好的实现方法,看懂,理解并且能够在其他场景应用类似的思想,而不是每次都要自己写两个map.毕竟现成好用的轮子,在适用的场景下还是应该多多使用加深理解. ComparisonChain -> 功能强大且好看的多字段比较方法 在面对多个字段排序比较的场景,一般我们的代码都会比较难看,比如对下面这个类: private static class Student { int id; String name; int age; } 我们现在是没有办法对其进行比较,或者进行排序的,因为没有定义对于他的比较策略,假设我们的策略是: 首先比较id,id相等比较name,name相等比较age,这是一种很常见的多字段比较策略.那么我们给Student类加上Comparable的实现. // 为了简洁起见,没有写外部类代码,只贴了重写的comparTo方法. @Override public int compareTo(Object o) { Student s = (Student) o; int idResult = s.id - this.id; int nameResult = s.name.compareTo(this.name); int ageResult = s.age - this.age; return idResult != 0 ? idResult : nameResult != 0 ? nameResult : ageResult; } 最后那一串?:?:是不是看的眼睛疼,当然你可以选择三重if-else,我觉得也没好到哪里去. 但是可以使用ComparisonChain,这名字一看就是比较链,非常适合我们的场景.改写如下: @Override public int compareTo(Object o) { Student s = (Student) o; return ComparisonChain.start().compare(s.id, this.id).compare(s.name, this.name).compare(s.age, this.age). result(); } 这个代码可读性的提升可谓是十分大了,语义十分清晰,可以很清楚的看懂开始,先比较,再比较,返回结果这样的一个过程. Ordering -> 多种比较器的组合 上面的ComparisonChain解决了在实现Comparable时候多个字段排序的情况,那么JDK中有很多的方法需要提供外部的比较器,这时候我们希望以多个比较器进行排序呢? Ordering提供了使用多个比较器的方法,它自身实现了Comparator接口,可以集成多个比较器. Ordering studentOrdering = Ordering.compound(Arrays.asList((o1, o2) -> { return ComparisonChain.start().result(); }, (o1, o2) -> 0, (o1, o2) -> 0)); Collections.sort(students, studentOrdering); 上面的代码中,使用Ordering集成了多个比较器,之后将其自身传入Collections的sort方法,使用它对list进行排序. ChangeLog 2019-05-01 完成 以上皆为个人所思所得，如有错误欢迎评论区指正。 欢迎转载，烦请署名并保留原文链接。 联系邮箱：huyanshi2580@gmail.com 更多学习笔记见个人博客------>呼延十 版权所有，盗版必究 all right reserved，powered by GitbookLast Modified On： 2019-05-01 21:57:19 "},"java/集合/2019-05-13-Map接口在1.8版本新增的几个方法.html":{"url":"java/集合/2019-05-13-Map接口在1.8版本新增的几个方法.html","title":"Map接口在1.8版本新增的几个方法","keywords":"","body":" 前言 V getOrDefault(Object key, V defaultValue) void replaceAll(BiFunction function) V putIfAbsent(K key, V value) boolean remove(Object key, Object value) replace default boolean replace(K key, V oldValue, V newValue) V replace(K key, V value) V computeIfAbsent(K key, Function mappingFunction) V computeIfPresent(K key, BiFunction remappingFunction) V compute(K key, BiFunction remappingFunction) V merge(K key, V value, BiFunction remappingFunction) 总结 前言 Map接口在1.8版本新增以下几个有趣的方法,今天参考源码来学习一下. getOrDefault replaceAll putIfAbsent remove replace computeIfAbsent computeIfPresent compute merge V getOrDefault(Object key, V defaultValue) 这可以说是最常用的方法了吧,获取指定key的value,当key不存在的时候返回一个默认值,也就是第二个参数. default V getOrDefault(Object key, V defaultValue) { V v; return (((v = get(key)) != null) || containsKey(key)) ? v : defaultValue; } void replaceAll(BiFunction function) 将所有value替换成给定lambda的计算结果,lambda的作用为根据key和value算出新的value. 源代码如下: default void replaceAll(BiFunction function) { Objects.requireNonNull(function); for (Map.Entry entry : entrySet()) { K k; V v; try { k = entry.getKey(); v = entry.getValue(); } catch(IllegalStateException ise) { // this usually means the entry is no longer in the map. throw new ConcurrentModificationException(ise); } // ise thrown from function is not a cme. v = function.apply(k, v); try { entry.setValue(v); } catch(IllegalStateException ise) { // this usually means the entry is no longer in the map. throw new ConcurrentModificationException(ise); } } } 示例代码如下: @Test public void test1() { Map test = new HashMap<>(); test.put(1, 1); test.put(2, 2); System.out.println(test.toString()); test.replaceAll((k, v) -> k + v); System.out.println(test.toString()); } 这段代码中传递了一个lambda,作用是将key和value相加作为新的value. 输出结果如下: {1=1, 2=2} {1=2, 2=4} V putIfAbsent(K key, V value) 当key不存在的时候,写入新值.始终返回执行操作后的新值. 源代码如下: default V putIfAbsent(K key, V value) { V v = get(key); if (v == null) { v = put(key, value); } return v; } 测试代码及输出如下: @Test public void test2() { Map test = new HashMap<>(); test.put(1, 1); test.put(2, 2); System.out.println(test.toString()); test.putIfAbsent(1, 3); test.putIfAbsent(3, 3); System.out.println(test.toString()); } ------------------------ {1=1, 2=2} {1=1, 2=2, 3=3} boolean remove(Object key, Object value) 如果给定的key在map中的value与给定值相等,则移除并且返回true,否则返回false. default boolean remove(Object key, Object value) { Object curValue = get(key); if (!Objects.equals(curValue, value) || (curValue == null && !containsKey(key))) { return false; } remove(key); return true; } replace 这个有两个重载方法. default boolean replace(K key, V oldValue, V newValue) 当key在map中的value与给定的oldValue相等,则用newValue替换掉并且返回true,否则返回false. default boolean replace(K key, V oldValue, V newValue) { Object curValue = get(key); if (!Objects.equals(curValue, oldValue) || (curValue == null && !containsKey(key))) { return false; } put(key, newValue); return true; } V replace(K key, V value) 当key存在,就替换掉并且返回新值,否则返回null. default V replace(K key, V value) { V curValue; if (((curValue = get(key)) != null) || containsKey(key)) { curValue = put(key, value); } return curValue; } V computeIfAbsent(K key, Function mappingFunction) 如果key不存在,则使用lambda计算并写入新值.永远返回执行操作后的新值.(可以存在,不做任何操作);放回计算的新值. 这个方法可以为一些耗时或者耗资源的操作构建本地缓存,当元素存在时直接返回,当不存在的时候进行耗时进行并存储,下一次可以直接返回. default V computeIfAbsent(K key, Function mappingFunction) { Objects.requireNonNull(mappingFunction); V v; if ((v = get(key)) == null) { V newValue; if ((newValue = mappingFunction.apply(key)) != null) { put(key, newValue); return newValue; } } return v; } 测试代码及输出如下: @Test public void test3() { Map test = new HashMap<>(); test.put(1, 1); test.put(2, 2); System.out.println(test.toString()); // 1 存在,不做任何操作 test.computeIfAbsent(1, key -> key + 2); // 3 不存在,将3 +2 = 5. test.computeIfAbsent(3, key -> key + 2); System.out.println(test.toString()); } ------------------------ {1=1, 2=2} {1=1, 2=2, 3=5} V computeIfPresent(K key, BiFunction remappingFunction) 当key存在时,计算新值,如果新值不为空,则将新值写入,如果新值为空,则移除掉此key.返回新值或者null. default V computeIfPresent(K key, BiFunction remappingFunction) { Objects.requireNonNull(remappingFunction); V oldValue; if ((oldValue = get(key)) != null) { V newValue = remappingFunction.apply(key, oldValue); if (newValue != null) { put(key, newValue); return newValue; } else { remove(key); return null; } } else { return null; } } 测试代码及输出如下: @Test public void test4() { Map test = new HashMap<>(); test.put(1, 1); test.put(2, 2); System.out.println(test.toString()); // 1 存在,计算 test.computeIfPresent(1, (key, oldValue) -> key + oldValue + 2); // 3 不存在,不作操作 test.computeIfPresent(3, (key, oldValue) -> key + oldValue + 2); System.out.println(test.toString()); } ------------------------------- {1=1, 2=2} {1=4, 2=2} 这个方法基本上是上一个方法的存在版本,但是要注意传入的lambda,参数是两个,computeIfAbsent的lambda传入key,计算值. 而computeIfPresent传入key和旧的value,并且由他们两个计算得到新的值. V compute(K key, BiFunction remappingFunction) 直接计算新值,新值为空,则删除key并且返回null,新值不为空则写入并且返回新值. default V compute(K key, BiFunction remappingFunction) { Objects.requireNonNull(remappingFunction); V oldValue = get(key); V newValue = remappingFunction.apply(key, oldValue); if (newValue == null) { // delete mapping if (oldValue != null || containsKey(key)) { // something to remove remove(key); return null; } else { // nothing to do. Leave things as they were. return null; } } else { // add or replace old mapping put(key, newValue); return newValue; } } 测试代码及输出如下: @Test public void test5() { Map test = new HashMap<>(); test.put(1, 1); test.put(2, 2); System.out.println(test.toString()); test.compute(1, (key, oldValue) -> key + 2); test.compute(3, (key, oldValue) -> key + 2); test.compute(2, (key, oldValue) -> null); System.out.println(test.toString()); } ---------------- {1=1, 2=2} {1=3, 3=5} 测试代码中对2进行compute->null,结果是2被删除. V merge(K key, V value, BiFunction remappingFunction) 使用旧值和给定的value来计算新值,如果新值为空,则删除key,不为空则写入并且返回. 注意:如果旧值为空,也就是原有的key不存在,新值等于给定值,不会再进行计算.因此下方的测试代码3=10而不是12. default V merge(K key, V value, BiFunction remappingFunction) { Objects.requireNonNull(remappingFunction); Objects.requireNonNull(value); V oldValue = get(key); V newValue = (oldValue == null) ? value : remappingFunction.apply(oldValue, value); if(newValue == null) { remove(key); } else { put(key, newValue); } return newValue; } 测试代码及输出如下: @Test public void test6() { Map test = new HashMap<>(); test.put(1, 1); test.put(2, 2); System.out.println(test.toString()); test.merge(1, 10, (v, oldV) -> v + oldV + 2); test.merge(3, 10, (v, oldV) -> v + oldV + 2); test.merge(2, 10, (v, oldV) -> null); System.out.println(test.toString()); } -------------------------- {1=1, 2=2} {1=13, 3=10} 总结 其实看过源码就可以发现,除了Function,BiFunction等函数式接口(也就是用于lambda)的接口是新声明的,其他调用的API都是原先已有的put,get,contain等常用API,因此这些新的方法并不能算是很难用的新功能,只能算是一些免去开发人员重复工作的语法糖,我们当然要多多享受语法糖带来的便利,但是不能忘却原理,要多多熟悉再使用. 完。 ChangeLog 2019-05-13 完成 以上皆为个人所思所得，如有错误欢迎评论区指正。 欢迎转载，烦请署名并保留原文链接。 联系邮箱：huyanshi2580@gmail.com 更多学习笔记见个人博客------>呼延十 版权所有，盗版必究 all right reserved，powered by GitbookLast Modified On： 2019-05-19 13:15:32 "},"java/集合/2018-10-11-ArrayList和LinkedList的区别.html":{"url":"java/集合/2018-10-11-ArrayList和LinkedList的区别.html","title":"ArrayList和LinkedList的区别","keywords":"","body":"PS：推荐大家先去了解一下链表这个数据结构。 ArrayList和LinkedList可以说是日常业务开发中最常使用的容器类了，同时，他们的区别也是面试高发区，虽然很简单，但是我们总是不能说的完整，今天就通过对他们源码的阅读来进一步加深理解。 首先，看他们类的定义可以发现： 他们都是实现了List接口，这个接口干了什么呢？ 这个接口定义了对列表的一些基本操作，如add,contains,indexof,remove等基本方法，由他的实现类各自进行实现。 因此，当你只是需要一个列表进行常规的添加移除查找操作，那么ArrayList和LinkedList在使用体验(不考虑性能)上基本没有区别，你甚至不用关心他的内部实现，而是调用一些List接口的方法就ok。 那么他们的具体实现有哪些区别呢？ 下面对他们常用的方法进行源码的阅读。 ArrayList 成员变量 ArrayList有两个成员变量，图中可以看到，一个Object的数组，一个int类型的size，用来定义数组的大小。 get()方法 首先检查传入的index，然后返回数组在该index的值。 add()方法 首先确保容量够用，然后将新加入的对象放在数组尾部。 remove()方法 首先确保容量够用，然后计算出需要移动的数量，例如size=10，要删除index=5的元素，则需要移动后面的四个元素，然后调用System.arraycopy()方法，将数组的后面4个依次向前移动一位，然后将数组最后一位置为null。 LinkedList 成员变量 LinkedList本身的属性比较少，主要有三个，一个是size，表明当前有多少个节点；一个是first代表第一个节点；一个是last代表最后一个节点。 get()方法 首先检查传入的index是否合法，然后调用了node(index)方法，那么来看看node()方法。 判断index值是否大于总数的一半。 如果小于，则从first节点向后遍历，直到找到index节点，然后返回该节点的值。 如果大于，则从last节点向前遍历，直到找到index节点，然后返回该节点的值。 add()方法 add方法，直接调用了linklast方法，将传入的值作为最后一个节点链接在链表上。 remove()方法 remove方法的思路是什么呢？从头开始遍历链表，当找到要删除的节点，将他删除。删除的方法呢？将该节点的前后节点链接起来，类似于下图： 对比 由上面的常用方法可以发现 1.ArrayList使用数组存储元素，因此在查询时速度较快，直接返回该位置的元素即可，时间复杂度为O(1);而LinkedList使用双向链表存储元素，在查询时需要从头或者尾遍历至查询元素，时间复杂度为O(n/2); 2.还是因为存储方式的问题，ArrayList在插入或者删除时，需要移动插入位置之后的所有元素，因此速度较慢，时间复杂度为O(n)。而LinkedList只需要找到该位置，移动”指针”即可,时间复杂度为O(1)。 结论 其实在日常的开发中，ArrayList更受欢迎，而且可以完成很多的任务，但是仍有一些特殊的情景适合使用LinkedList。他们的使用场景如下： 当你对列表更多的进行查询，即获取某个位置的元素时，应当优先使用ArrayList；当你对列表需要进行频繁的删除和增加，而很少使用查询时，优先使用LinkedList； 注意事项！ 1.上述结论适用于普遍的情景，有些极端情况不一定符合。比如频繁的在数组结尾附近插入数据，ArrayList也快于LinkedList。 2.LinkedList使用的空间大于ArrayList，因为本质上，ArrayList在每个位置存储了元素，而LinkedList存储了元素+前面节点+后面节点。 扩展 我们知道ArrayList和LinkedList都是有size的，那么当添加的元素过多，他们怎么扩容呢？ ArrayList： ArrayList使用数组存储元素，因此扩容时为： 可以看到，每次扩容后的大小为之前的1.5倍。int newCapacity = oldCapacity + (oldCapacity >> 1);,而且之后有一个复制全部元素的操作，这个操作很费时间。 LinkedList： 由于LinkedList是一个双向链表，因此不需要扩容机制，直接在前后添加元素即可。 因此：在使用ArrayList时，如果你能预估大小，最好直接定义初始容量，这样能节省频繁的扩容带来的额外开支。 初始化定义容量的构造方法为： 。 后记 其实想写这个很久了，一直拖延着，今天终于回忆起了面试的时候被ArrayList和LinkedList支配的恐惧。(都喜欢问，一直问(校招))。因此趁热打铁，阅读了他们的源码并记录下来。相信常常回顾之下不会再受困于此，也能让日常工作的编码水平有些许提升。 完。 ChangeLog 2018-10-11 完成 以上皆为个人所思所得，如有错误欢迎评论区指正。 欢迎转载，烦请署名并保留原文链接。 联系邮箱：huyanshi2580@gmail.com 更多学习笔记见个人博客------>呼延十 版权所有，盗版必究 all right reserved，powered by GitbookLast Modified On： 2019-06-11 14:16:41 "},"java/集合/2019-05-01-Java中-Collections工具类的学习.html":{"url":"java/集合/2019-05-01-Java中-Collections工具类的学习.html","title":"Java中-Collections工具类的学习","keywords":"","body":"前言 天天都在用Java集合,也偶尔用到了Collections类中的一些方法,但是一直没有对这个工具类进行一个较为系统的学习,今天放假比较无聊,闲来看一看.并且记录一下API. 5500多行的代码,,这个工具类是真的大,希望可以发现一些好用且常用的工具方法. 大部分API会在API记录部分写一下,少部分需要额外补充说明的,在某些特殊说明中单独记录. API记录 编号 方法 作用 备注 1 public static > void sort(List list) 对传入的list进行排序 使用该元素自己的Comparable 2 public static void sort(List list, Comparator c) 使用指定的Comparable进行排序 3 public static int binarySearch(List> list, T key) 在给定的list里面找key,使用二分查找算法. 4 public static int binarySearch(List list, T key, Comparator c) 上一个方法的指定Comparable版本. 5 public static void reverse(List list) 翻转list中元素的顺序 6 public static void shuffle(List list, Random rnd) 随机打乱list中的元素顺序 7 public static void swap(List list, int i, int j) 交换list在两个下标上的元素 所以我们日常的swap其实不用自己写的 8 public static void fill(List list, T obj) 用给定的元素将list的全部元素替换掉. 9 public static void copy(List dest, List src) 拷贝列表 10 public static > T min(Collection coll) 返回集合中最小的元素 当然他也有指定Comparable的版本.不贴了. 11 public static > T max(Collection coll) 返回集合中最大的元素 当然也有咯. 12 public static void rotate(List list, int distance) 回转当前列表 回转的定义:之前是1,2,3,以1回转之后就是3,1,2.以2回转就是,2,3,1. 13 public static boolean replaceAll(List list, T oldVal, T newVal) 批量用新值替换当前列表中的某一个值 14 public static int indexOfSubList(List source, List target) 返回target集合在source列表中的index,如果target不是source的子列表,返回-1; 15 public static int lastIndexOfSubList(List source, List target) 返回最后出现的index,比如1,2,3,2,target=2,返回3. 16 public static Collection unmodifiableCollection(Collection c) 返回一个不可变的视图 封装了一下,重写了所有可能修改集合的方法,抛出异常 17 public static Set unmodifiableSet(Set s) 不可变的set 接下来是几个set的变种,sortedset之类的. 18 public static List unmodifiableList(List list) 不可变的list. 19 public static Map unmodifiableMap(Map m) 不可变的Map 20 public static Collection synchronizedCollection(Collection c) 强行是用synchronized同步的集合类 返回的也是封装,重写之后的类,接下来和上面不可变一样,是list,map,set及其变种. 21 c static Collection checkedCollection(Collection c, Class type) 一堆进行了类型检查的集合类 也有map等等变种. 22 public static Iterator emptyIterator() 返回一个空的迭代器 接下来有许多空的list,set,map等等. 23 public static Set singleton(T o) 返回只有一个元素的set. 24 public static List singletonList(T o) 返回只有一个元素的List. 25 public static Map singletonMap(K key, V value) 返回只有一个元素的Map. 26 public static Enumeration enumeration(final Collection c) 返回当前集合的枚举 27 public static ArrayList list(Enumeration e) 从枚举返回ArrayList. 28 public static int frequency(Collection c, Object o) 返回输入对象在集合中的出现次数. 29 public static boolean disjoint(Collection c1, Collection c2) 返回两个集合是都有交集 有交集返回false,没有返回true. 30 public static boolean addAll(Collection c, T... elements) 将给定的元素全部添加到给定集合中 集合本身可以添加全部,但是必须要求也是集合参数,比如你有两个独立的元素,就可以直接使用这个类而不是用两个元素构造一个集合,然后调用集合本身的addall. 31 public static Set newSetFromMap(Map map) 返回当前map的keyset. set持有原来的map的引用. 32 public static Queue asLifoQueue(Deque deque) 将一个deque转换为队列,并且是LIFO(后进先出). ChangeLog 2019-05-01 完成 以上皆为个人所思所得，如有错误欢迎评论区指正。 欢迎转载，烦请署名并保留原文链接。 联系邮箱：huyanshi2580@gmail.com 更多学习笔记见个人博客------>呼延十 版权所有，盗版必究 all right reserved，powered by GitbookLast Modified On： 2019-04-30 18:40:21 "},"java/集合/2018-12-23-Vector源码阅读.html":{"url":"java/集合/2018-12-23-Vector源码阅读.html","title":"Vector源码阅读","keywords":"","body":"前言 前面已经学习过ArrayList和LinkedList的区别,今天再来学习一下List接口的另一个实现类Vector. Vector 可以实现可增长的对象数组。与数组一样，它包含可以使用整数索引进行访问的组件。不过，Vector 的大小是可以增加或者减小的，以便适应创建 Vector 后进行添加或者删除操作。 Vector与ArrayList没有太大区别,都具有List的基础功能,重要的是:Vector是同步的.也就是说,Vector可以用于多线程环境下,但是性能相比Arraylist要低一些. 源码阅读 定义 首先看一下Vector类的定义. public class Vector extends AbstractList implements List, RandomAccess, Cloneable, java.io.Serializable {} Vector 实现 List 接口，继承 AbstractList 类，所以我们可以将其看做列表，支持相关的添加、删除、修改、遍历等功能。 Vector 实现 RandomAccess 接口，即提供了随机访问功能，提供快速访问功能。在 Vector 我们可以直接访问元素。 Vector 实现了 Cloneable 接口，支持 clone() 方法，可以被克隆。 成员变量 protected Object[] elementData; protected int elementCount; protected int capacityIncrement; elementData是保存数据的数组 elementCount是当前元素的数量 capacityIncrement是容量增量,当它小于或者等于0时,则每次需要增大容量时，向量的容量将增大一倍. 构造方法 public Vector(int initialCapacity, int capacityIncrement) { } public Vector(int initialCapacity) { } public Vector() { } public Vector(Collection c) { } Vector有四个构造方法,参数分别制定初始容量及初始增量. 默认的构造方法,初始容量为10,初始增量为0,即每次扩容时容量翻倍. 常用方法 1.添加元素 /** * 数组末尾添加一个元素 */ public synchronized boolean add(E e) { modCount++; ensureCapacityHelper(elementCount + 1); elementData[elementCount++] = e; return true; } /** * 设置某个index上的元素为传入值 */ public synchronized E set(int index, E element) { if (index >= elementCount) throw new ArrayIndexOutOfBoundsException(index); E oldValue = elementData(index); elementData[index] = element; return oldValue; } /** * 在指定的index插入一个元素,后续元素向后顺移 */ public void add(int index, E element) { insertElementAt(element, index); } public synchronized void insertElementAt(E obj, int index) { modCount++; if (index > elementCount) { throw new ArrayIndexOutOfBoundsException(index + \" > \" + elementCount); } ensureCapacityHelper(elementCount + 1); System.arraycopy(elementData, index, elementData, index + 1, elementCount - index); elementData[index] = obj; elementCount++; } 2.获取元素 public synchronized E get(int index) { if (index >= elementCount) throw new ArrayIndexOutOfBoundsException(index); return elementData(index); } 3.移除元素 public boolean remove(Object o) { return removeElement(o); } public synchronized boolean removeElement(Object obj) { modCount++; int i = indexOf(obj); if (i >= 0) { removeElementAt(i); return true; } return false; } 由于Vector内部使用数组实现,因此简单的增加删除获取元素都是对数组的简单操作,这里就不细讲了. 扩容 既然Vector是一个可以动态改变自己大小的数组,那么我们来看一下他是怎么实现动态扩容的. public synchronized void ensureCapacity(int minCapacity) { if (minCapacity > 0) { modCount++; ensureCapacityHelper(minCapacity); } } private void ensureCapacityHelper(int minCapacity) { // overflow-conscious code if (minCapacity - elementData.length > 0) grow(minCapacity); } private void grow(int minCapacity) { // overflow-conscious code int oldCapacity = elementData.length; int newCapacity = oldCapacity + ((capacityIncrement > 0) ? capacityIncrement : oldCapacity); if (newCapacity - minCapacity 0) newCapacity = hugeCapacity(minCapacity); elementData = Arrays.copyOf(elementData, newCapacity); } private static int hugeCapacity(int minCapacity) { if (minCapacity MAX_ARRAY_SIZE) ? Integer.MAX_VALUE : MAX_ARRAY_SIZE; } 这是和扩容相关的几个方法,前两个方法是用来检验当前是否需要扩容. 在添加元素时,会用当前数组中元素的个数+1进行检验,如当前个数+1 > 数组长度,则需要扩容,调用grow方法. grow方法中: 旧的大小为当前数组长度 计算扩容后的大小,(oldCapacity+capacity/oldCapacity) 判断扩容后的size是否合法 调用Arrays.copy将当前所有值copy到新的数组. 后话 由于Vector内部使用数组实现,因此源码并不复杂. 同时,在学习源码的过程中我们可以发现,很多对数组进行操作的方法使用synchronized修饰,因此可以保证线程安全性,同时,synchronized会加锁,因此效率可能会相对于ArrayList低一些,在单线程的情况下建议还是使用ArrayList. 参考链接 http://wiki.jikexueyuan.com/project/java-enhancement/java-twentynine.html 完。 ChangeLog 2018-12-23 完成 以上皆为个人所思所得，如有错误欢迎评论区指正。 欢迎转载，烦请署名并保留原文链接。 联系邮箱：huyanshi2580@gmail.com 更多学习笔记见个人博客------>呼延十 版权所有，盗版必究 all right reserved，powered by GitbookLast Modified On： 2019-03-26 11:07:51 "},"java/集合/2019-05-19-跳表(SkipList)的原理及ConcurrentSkipListMap的源码学习.html":{"url":"java/集合/2019-05-19-跳表(SkipList)的原理及ConcurrentSkipListMap的源码学习.html","title":"跳表(SkipList)的原理及ConcurrentSkipListMap的源码学习","keywords":"","body":"目录 目录 前言 跳表 概述 原理 应用 ConcurrentSkilListMap的实现 内部数据结构 主要API的实现 put Get findPredecessor remove 总结 参考文章 前言 本文分为两个部分,第一个是对跳表(SKipList)这种数据结构的介绍,第二部分则是对Java中ConcurrentSkilListMap的源码解读. 跳表 关于跳表的概述,强力推荐这篇文章,漫画算法:什么是跳表,我也是看了这个之后才豁然开朗,讲解的通俗又生动. 概述 跳跃列表是一种数据结构。它允许快速查询一个有序元素的数据链表。跳跃列表的平均查找和插入时间复杂度都是O(log n)，优于普通队列的O(n)。 想一下我们日常对列表的存储方式: 数组 链表 数组查询较快,支持随机访问以及二分法查找,但是插入和删除数据需要移动较多的值,效率较低.时间复杂度为O(n). 链表的插入较快,但是在插入之前需要先寻找合适的位置,这一步骤也是O(n)的复杂度,因此链表的插入和查询都是O(n)的复杂度. 那么有没有一种在插入和查询上都表现比较好的数据结构呢? 有,各种查找树平衡树等,今天这里学习一种新的实现方式:跳表. 原理 其实跳表的原理,对计算机行业的同学来说,一张图就可以明了. 即原来的链表不变,额外维护一份索引(1级),记录某几个值的位置及值. 当数据量过大,比如有10w数据,那么维护的索引有一半的话也有5w,那么查找依然很慢,这个时候可以再加一层索引,数据量就只有2w5了. 一直这样添加索引,到最后会额外多维护一份数据,但是模拟了二分查找,因此在插入和查找上都是O(logn)的时间复杂度,空间复杂度为O(2n)也就是O(n). 当然跳表有非常多的变种,可以在上面的策略上进行各种调整,以使他的时间复杂度和空间复杂度接近自己的要求. 当删除或者添加的时候,会造成原来链表结构的变化,这时候上面的各层索引也需要相应的修改,那么如何决定一个节点是否应该被提升一层作为一个索引呢?在跳表中使用的是随机的方式,比在二叉搜索树中的方法要轻量级许多. 应用 redis中的sorted set数据结构,内部使用跳表实现 lucene ConcurrentSkilListMap的实现 ConcurrentSkipListMap 一个并发安全, 基于 skip list 实现有序存储的Map. 内部数据结构 ConcurrentSkilListMap内部封装了几个数据结构,我们看一下: // 一个节点,保存了key,value,还有指向下一个节点的指针 static final class Node { final K key; volatile Object value; volatile Node next; } // 索引,包含一个上面的节点,还有右边的索引(同一级),下边的索引(下一级) static class Index { final Node node; final Index down; volatile Index right; } // 每一层的头索引,带有当前的level. static final class HeadIndex extends Index { final int level; HeadIndex(Node node, Index down, Index right, int level) { super(node, down, right); this.level = level; } } 主要API的实现 直接看代码有点难以下手,我们根据他提供的一些公共的API来逐一看一下实现方式. put 这个方法我们必须首先看一下,是我们在使用HashMap等结构的时候常用的put方法. 这里大概说一下流程,代码里加上了注释. 找到当前数据应该存放的位置进行插入. 准备各层的索引. 插入索引. public V put(K key, V value) { if (value == null) throw new NullPointerException(); return doPut(key, value, false); } /** * Main insertion method. Adds element if not present, or * replaces value if present and onlyIfAbsent is false. * @param key the key * @param value the value that must be associated with key * @param onlyIfAbsent if should not insert if already present * @return the old value, or null if newly inserted */ /** * 插入的主方法,如果不存在则插入元素,如果存在且传入的`onlyIfAbsent`为false则替换掉值. */ private V doPut(K key, V value, boolean onlyIfAbsent) { Node z; // added node if (key == null) throw new NullPointerException(); Comparator cmp = comparator; outer: for (;;) { // 找到前置节点,在base-level上的. for (Node b = findPredecessor(key, cmp), n = b.next;;) { if (n != null) { Object v; int c; Node f = n.next; // 发生了多线程竞争,break.重新试一遍 if (n != b.next) // inconsistent read break; if ((v = n.value) == null) { // n is deleted n.helpDelete(b, f); break; } if (b.value == null || v == n) // b is deleted break; // 如果key大于前置节点,继续 if ((c = cpr(cmp, key, n.key)) > 0) { b = n; n = f; continue; } // 等于则赋值 if (c == 0) { if (onlyIfAbsent || n.casValue(v, value)) { @SuppressWarnings(\"unchecked\") V vv = (V)v; return vv; } // 竞争失败了,重新来 break; // restart if lost race to replace value } // else c (key, value, n); if (!b.casNext(n, z)) break; // restart if lost race to append to b break outer; } } // 获取level int rnd = ThreadLocalRandom.nextSecondarySeed(); if ((rnd & 0x80000001) == 0) { // test highest and lowest bits int level = 1, max; while (((rnd >>>= 1) & 1) != 0) ++level; Index idx = null; HeadIndex h = head; // 添加z的索引数据 if (level (z, idx, null); } else { // 添加新的一层索引 level = max + 1; // hold in array and later pick the one to use @SuppressWarnings(\"unchecked\")Index[] idxs = (Index[])new Index[level+1]; for (int i = 1; i (z, idx, null); for (;;) { h = head; int oldLevel = h.level; if (level newh = h; Node oldbase = h.node; for (int j = oldLevel+1; j (oldbase, newh, idxs[j], j); if (casHead(h, newh)) { h = newh; idx = idxs[level = oldLevel]; break; } } } // find insertion points and splice in splice: for (int insertionLevel = level;;) { int j = h.level; for (Index q = h, r = q.right, t = idx;;) { if (q == null || t == null) break splice; if (r != null) { Node n = r.node; // compare before deletion check avoids needing recheck int c = cpr(cmp, key, n.key); if (n.value == null) { if (!q.unlink(r)) break; r = q.right; continue; } if (c > 0) { q = r; r = r.right; continue; } } if (j == insertionLevel) { if (!q.link(r, t)) break; // restart if (t.node.value == null) { findNode(key); break splice; } if (--insertionLevel == 0) break splice; } if (--j >= insertionLevel && j Get get方法比较简单: /** * Gets value for key. Almost the same as findNode, but returns * the found value (to avoid retries during re-reads) * * @param key the key * @return the value, or null if absent */ private V doGet(Object key) { if (key == null) throw new NullPointerException(); Comparator cmp = comparator; outer: for (;;) { // 寻找前置节点 for (Node b = findPredecessor(key, cmp), n = b.next;;) { Object v; int c; // 如果为空则不存在,直接返回 if (n == null) break outer; Node f = n.next; // 多线程竞争,重新试一下 if (n != b.next) // inconsistent read break; if ((v = n.value) == null) { // n is deleted n.helpDelete(b, f); break; } if (b.value == null || v == n) // b is deleted break; // 如果相等,则返回值. if ((c = cpr(cmp, key, n.key)) == 0) { @SuppressWarnings(\"unchecked\") V vv = (V)v; return vv; } if (c findPredecessor 可以看到在get和put方法中,寻找前置节点都比较重要. 寻找前置节点的思路比较明了,就是跳表的查找思路: 从矩形索引的左上角开始向右查找 如果右侧索引为空,或者右侧索引的值大于要查找的值,则向下一层. 然后重复向右侧,向下进行查找,知道拿到前置节点. 代码如下: /** * Returns a base-level node with key strictly less than given key, * or the base-level header if there is no such node. Also * unlinks indexes to deleted nodes found along the way. Callers * rely on this side-effect of clearing indices to deleted nodes. * @param key the key * @return a predecessor of key */ private Node findPredecessor(Object key, Comparator cmp) { if (key == null) throw new NullPointerException(); // don't postpone errors for (;;) { // 拿到矩形索引的左上角的索引 for (Index q = head, r = q.right, d;;) { // 右侧索引不为空 if (r != null) { Node n = r.node; K k = n.key; // 竞争 if (n.value == null) { if (!q.unlink(r)) break; // restart r = q.right; // reread r continue; } // 如果小于传入的key,则向右查找. if (cpr(cmp, key, k) > 0) { q = r; r = r.right; continue; } } // 到达最后一层了,数据层,返回拿到的节点.就是后继几点. if ((d = q.down) == null) return q.node; // 这边是右侧的索引为空,则可以直接向下一层了. q = d; r = d.right; } } } remove 思路比较简单: 找到前置节点 删除节点 删除索引 /** * Main deletion method. Locates node, nulls value, appends a * deletion marker, unlinks predecessor, removes associated index * nodes, and possibly reduces head index level. * * Index nodes are cleared out simply by calling findPredecessor. * which unlinks indexes to deleted nodes found along path to key, * which will include the indexes to this node. This is done * unconditionally. We can't check beforehand whether there are * index nodes because it might be the case that some or all * indexes hadn't been inserted yet for this node during initial * search for it, and we'd like to ensure lack of garbage * retention, so must call to be sure. * * @param key the key * @param value if non-null, the value that must be * associated with key * @return the node, or null if not found */ final V doRemove(Object key, Object value) { if (key == null) throw new NullPointerException(); Comparator cmp = comparator; outer: for (;;) { // 寻找前置节点 for (Node b = findPredecessor(key, cmp), n = b.next;;) { Object v; int c; // 竞争 if (n == null) break outer; Node f = n.next; if (n != b.next) // inconsistent read break; if ((v = n.value) == null) { // n is deleted n.helpDelete(b, f); break; } if (b.value == null || v == n) // b is deleted break; // 如果节点不存在,直接返回 if ((c = cpr(cmp, key, n.key)) 0) { b = n; n = f; continue; } // 不删除了 if (value != null && !value.equals(v)) break outer; // 进行删除操作 if (!n.casValue(v, null)) break; // 删除索引 if (!n.appendMarker(f) || !b.casNext(n, f)) findNode(key); // retry via findNode else { findPredecessor(key, cmp); // clean index // 如果一层索引都空了,则删除这一层. if (head.right == null) tryReduceLevel(); } @SuppressWarnings(\"unchecked\") V vv = (V)v; return vv; } } return null; } 总结 跳表是一种可以在有序的列表上进行快速的查找的数据结构,他的查找删除插入的时间复杂度都O(logN).在跳表中,存储数据的就是底层的一个单链表,同时维护一份索引,索引是最多31条单链表,并且不同层的相同节点在纵向上也是一个链表,因此索引其实是一个矩形的结构,查找时,从矩形的左上角逐渐向右向下查找. ConcurrentSkilListMap是Java中对于跳表的一个并发实现,且没有使用锁机制,采用了CAS算法以提供并发的能力. 参考文章 http://blog.jobbole.com/111731/ https://www.jianshu.com/p/edc2fd149255 完。 ChangeLog 2019-05-19 完成 以上皆为个人所思所得，如有错误欢迎评论区指正。 欢迎转载，烦请署名并保留原文链接。 联系邮箱：huyanshi2580@gmail.com 更多学习笔记见个人博客------>呼延十 版权所有，盗版必究 all right reserved，powered by GitbookLast Modified On： 2019-05-19 18:35:52 "},"java/集合/2019-05-25-Java中-TreeMap和-TreeSet的使用.html":{"url":"java/集合/2019-05-25-Java中-TreeMap和-TreeSet的使用.html","title":"Java中-TreeMap和-TreeSet的使用","keywords":"","body":"目录 目录 前言 红黑树 TreeMap TreeSet 参考文章 前言 首先要注意的是,本文章不涉及到红黑树的具体实现,也就是说不会逐行分析TreeMap和TreeSet的源码实现,因为红黑树看了也会忘的... 所以本文只是记录红黑树的一些基础介绍,以及TreeMap和TreeSet两个类的公共API. 红黑树 红黑树，一种二叉查找树，但在每个结点上增加一个存储位表示结点的颜色，可以是Red或Black。 通过对任何一条从根到叶子的路径上各个结点着色方式的限制，红黑树确保没有一条路径会比其他路径长出俩倍，因而是接近平衡的。 红黑树首先是一颗二叉查找树,满足二叉查找树的一下特点: 若任意节点的左子树不空，则左子树上所有节点的值均小于它的根节点的值； 若任意节点的右子树不空，则右子树上所有节点的值均大于它的根节点的值； 任意节点的左、右子树也分别为二叉查找树； 没有键值相等的节点。 红黑树在二叉查找树的基础上又有以下性质: 每个结点要么是红的要么是黑的。 根结点是黑的。 每个叶结点（叶结点即指树尾端NIL指针或NULL结点）都是黑的。 如果一个结点是红的，那么它的两个儿子都是黑的。 对于任意结点而言，其到叶结点树尾端NIL指针的每条路径都包含相同数目的黑结点。 通过这5个性质,可以保证红黑树的高度永远是logn,所以红黑树的查找、插入、删除的时间复杂度最坏为O(log n). 红黑树有什么作用呢?那就是快,查找,插入,删除的时间复杂度最坏为O(logn). 红黑树的具体实现可以google一下,有很多开源的实现.中心思想就是各种旋转~. TreeMap TreeMap是一个有序的key-value集合,基于红黑树（Red-Black tree）实现。该映射根据其键的自然顺序进行排序，或者根据创建映射时提供的 Comparator 进行排序，具体取决于使用的构造方法。 具体的使用方法见下方API极其注释(常用的没有注释). // 返回(大于等输入key)的最小的key/entry,不存在返回null Entry ceilingEntry(K key) K ceilingKey(K key) void clear() Object clone() // 返回comparator Comparator comparator() boolean containsKey(Object key) // 降序返回key/map NavigableSet descendingKeySet() NavigableMap descendingMap() Set> entrySet() // 返回第一个key/entry Entry firstEntry() K firstKey() // 返回(小于等于输入key)的最大的key/entry,不存在返回null Entry floorEntry(K key) K floorKey(K key) V get(Object key) // 返回优先级高于指定k的部分map,inclusive为是否包含当前key NavigableMap headMap(K to, boolean inclusive) SortedMap headMap(K toExclusive) // 返回大于给定key的第一个节点 Entry higherEntry(K key) K higherKey(K key) boolean isEmpty() Set keySet() // 最后一个key/entry Entry lastEntry() K lastKey() // 返回小于给定key的第一个节点 Entry lowerEntry(K key) K lowerKey(K key) // 返回NavigableSet,可以导航..有low/high等方法 NavigableSet navigableKeySet() // 弹出第一个key/entry Entry pollFirstEntry() Entry pollLastEntry() V put(K key, V value) V remove(Object key) int size() SortedMap subMap(K fromInclusive, K toExclusive) NavigableMap subMap(K from, boolean fromInclusive, K to, boolean toInclusive) // 返回尾部map,小于给定k,inclusive为控制是否包含 NavigableMap tailMap(K from, boolean inclusive) SortedMap tailMap(K fromInclusive) TreeSet TreeSet是基于TreeMap实现的。TreeSet中的元素支持2种排序方式：自然排序 或者 根据创建TreeSet 时提供的 Comparator 进行排序。这取决于使用的构造方法。 因为他是基于TreeMap实现的,所以其实也是基于红黑树,其基本操作（add、remove 和 contains等）都是O(logn)的时间复杂度. API如下: boolean add(E object) boolean addAll(Collection collection) void clear() Object clone() boolean contains(Object object) // 返回第一个/最后一个元素 E first() E last() boolean isEmpty() // 弹出第一个或者最后一个元素 E pollFirst() E pollLast() // 返回大于/小于给定元素的元素 E higher(E e) E lower(E e) // 返回小于/大于给定元素的最大/最小的一个 E floor(E e) E ceiling(E e) boolean remove(Object object) int size() Comparator comparator() Iterator iterator() // 降序遍历 Iterator descendingIterator() // 返回大于/小于给定元素的所有元素集合,endInclusive为是否包含的控制量 SortedSet headSet(E end) NavigableSet headSet(E end, boolean endInclusive) SortedSet tailSet(E start) NavigableSet tailSet(E start, boolean startInclusive) // 降序的set NavigableSet descendingSet() // 子集合 SortedSet subSet(E start, E end) NavigableSet subSet(E start, boolean startInclusive, E end, boolean endInclusive) 参考文章 https://zh.wikipedia.org/wiki/%E7%BA%A2%E9%BB%91%E6%A0%91 完。 ChangeLog 2019-05-25 完成 以上皆为个人所思所得，如有错误欢迎评论区指正。 欢迎转载，烦请署名并保留原文链接。 联系邮箱：huyanshi2580@gmail.com 更多学习笔记见个人博客------>呼延十 版权所有，盗版必究 all right reserved，powered by GitbookLast Modified On： 2019-05-25 23:57:00 "},"java/集合/2018-11-07-Concurrent-Hash-Map源码阅读.html":{"url":"java/集合/2018-11-07-Concurrent-Hash-Map源码阅读.html","title":"Concurrent-Hash-Map源码阅读","keywords":"","body":"PS.本文基于JDK1.8 前言 大家都知道HashMap是线程不安全的,想要在并发的环境中使用,用什么呢?HashTable?采用syncgronized加锁,导致效率及其底下.在java5之后jdk提供了另一个类,ConcurrentHashMap,极大的提升了并发下的性能. 这次将阅读ConcurrentHashMap的源码并记录关键知识. 实现原理 数据结构 与HashMap的数据结构同步,在JDK1.7中使用数组+链表,在JDK1.8之后使用数组+链表+红黑树. 并发 在1.7版本,使用锁分离技术,即ConcurrentHashMap由Segment组成,每个Segment包含一些Node存储键值对. 而每个Segment都有一把锁.并发性能依赖于Segment的粒度,当你将整个HashMap放入同一个Segment,ConcurrentHashMap会退化成HashMap. 1.8版本中,摒弃了锁分离的概念,虽然保留了Segment,但是只是为了兼容老的版本. 1.8中使用CAS算法+锁来保证并发性能及线程安全 CAS 算法 通俗的讲(我的理解)就是:在每一次操作的时候参数中带有预期值(旧值),当且仅当内存中的值与预期值相同的时候,才写入新值. 源码逐步解析 注意,本文只解读JDK1.8版本的ConcurrentHashMap,在源码中与以前版本有关的东西略过. 常量 //最大容量 private static final int MAXIMUM_CAPACITY = 1 8 static final int TREEIFY_THRESHOLD = 8; //红黑树转链表的阀值， 常量的定义较为简单,这里只列出了一些常用的常量,还有一些在具体使用时再贴. 代码中已加入注释,一看就懂. 属性 //node的数组， transient volatile Node[] table; //node的数组，扩容时候使用 private transient volatile Node[] nextTable; //计数值，也是用CAS修改 private transient volatile long baseCount; /** * Table initialization and resizing control. When negative, the * table is being initialized or resized: -1 for initialization, * else -(1 + the number of active resizing threads). Otherwise, * when table is null, holds the initial table size to use upon * creation, or 0 for default. After initialization, holds the * next element count value upon which to resize the table. */ //这是一个标识位，当为-1的时候代表正在初始化，当为-N的时候代表有N - 1个线程正在扩容， //当为正数的时候代表下一次扩容后的大小 private transient volatile int sizeCtl; 这里面有一个重要的属性sizeCtl,保留了源码的注释及添加了我的理解. 数据节点Node类 static class Node implements Map.Entry { final int hash; final K key; volatile V val; volatile Node next; } 对于Node类的构造方法以及getter/setter进行了省略.只保留了属性. 可以看到共有四个属性 final修饰的hash值,初始化后不能再次改变. final修饰的key,初始化后不能再次改变. volatile 修饰的值 volatile 修饰的下一节点指针 hash和key都被final修饰,不会存在线程安全问题,而value及next被volatile修饰,保证了线程间的数据可见性. 三个重要的原子方法 //获取数组i位置的node @SuppressWarnings(\"unchecked\") static final Node tabAt(Node[] tab, int i) { return (Node)U.getObjectVolatile(tab, ((long)i boolean casTabAt(Node[] tab, int i, Node c, Node v) { return U.compareAndSwapObject(tab, ((long)i void setTabAt(Node[] tab, int i, Node v) { U.putObjectVolatile(tab, ((long)i 构造方法 构造方法十分简单,这里不再贴代码,只是需要注意: 在创建对象的时候没有进行Node数组的初始化,初始化操作在put时进行. get()方法 public V get(Object key) { Node[] tab; Node e, p; int n, eh; K ek; //获取hash值 int h = spread(key.hashCode()); //通过tabat获取hash桶 if ((tab = table) != null && (n = tab.length) > 0 && (e = tabAt(tab, (n - 1) & h)) != null) { //如果该hash桶的第一个节点就是查找结果,则返回 if ((eh = e.hash) == h) { if ((ek = e.key) == key || (ek != null && key.equals(ek))) return e.val; } //第一个节点是树的根节点,按照树的方式进行遍历查找 else if (eh 可以看到,在get()方法的过程中,是没有进行加锁操作的,那么是如何保证线程安全的呢? 首先通过tabat获取hash桶的根节点 遍历的时候根据node的volatile属性next. 返回时读取node的volatile属性val. 所有的操作属性都是volatile,由该关键字保证内存的可见性,进一步保证读取时的线程安全. put()方法 public V put(K key, V value) { return putVal(key, value, false); } /** Implementation for put and putIfAbsent */ final V putVal(K key, V value, boolean onlyIfAbsent) { if (key == null || value == null) throw new NullPointerException(); //获取hash值 int hash = spread(key.hashCode()); int binCount = 0; //遍历数组 for (Node[] tab = table;;) { Node f; int n, i, fh; //如果当前数组还未初始化,则进行初始化操作 if (tab == null || (n = tab.length) == 0) tab = initTable(); //如果已经初始化且要插入的位置为null,则直接使用cas方式进行插入,没有加锁 else if ((f = tabAt(tab, i = (n - 1) & hash)) == null) { if (casTabAt(tab, i, null, new Node(hash, key, value, null))) break; // no lock when adding to empty bin } //如果当前节点为扩容标识节点,则帮助扩容 else if ((fh = f.hash) == MOVED) tab = helpTransfer(tab, f); else { //对该hash桶进行加锁 V oldVal = null; synchronized (f) { if (tabAt(tab, i) == f) { //链表情况的插入 if (fh >= 0) { binCount = 1; for (Node e = f;; ++binCount) { K ek; if (e.hash == hash && ((ek = e.key) == key || (ek != null && key.equals(ek)))) { oldVal = e.val; if (!onlyIfAbsent) e.val = value; break; } Node pred = e; if ((e = e.next) == null) { pred.next = new Node(hash, key, value, null); break; } } } //红黑树的插入 else if (f instanceof TreeBin) { Node p; binCount = 2; if ((p = ((TreeBin)f).putTreeVal(hash, key, value)) != null) { oldVal = p.val; if (!onlyIfAbsent) p.val = value; } } } } //检查长度是否超过阀值,如果超过则由链表转成红黑树 if (binCount != 0) { if (binCount >= TREEIFY_THRESHOLD) treeifyBin(tab, i); if (oldVal != null) return oldVal; break; } } } //size属性加1,如果过长则扩容 addCount(1L, binCount); return null; } put方法中的流程: 获取hash值 遍历数组 如果未初始化则初始化 如果要插入的位置为null,则使用cas插入,不加锁 如果要插入的位置为扩容标识节点,则帮助其扩容 对插入的hash桶加锁 按照红黑树或者链表的方式进行插入 检查插入后链表长度是否超过阀值,如果超过则转为红黑树 添加计数,如果添加后的数量大于扩容阀值,则进行扩容. remove()方法 public V remove(Object key) { return replaceNode(key, null, null); } /** 参数value:当 value==null 时 ，删除节点 。否则 更新节点的值为value 参数cv:一个期望值， 当 map[key].value 等于期望值cv 或者 cv==null的时候 ，删除节点，或者更新节点的值 */ final V replaceNode(Object key, V value, Object cv) { int hash = spread(key.hashCode()); for (Node[] tab = table;;) { Node f; int n, i, fh; //table还没有初始化或者key对应的hash桶为空 if (tab == null || (n = tab.length) == 0 || (f = tabAt(tab, i = (n - 1) & hash)) == null) break; //正在扩容 else if ((fh = f.hash) == MOVED) tab = helpTransfer(tab, f); else { V oldVal = null; boolean validated = false; synchronized (f) { //cas获取tab[i],如果此时tab[i]!=f,说明其他线程修改了tab[i]。回到for循环开始处，重新执行 if (tabAt(tab, i) == f) { //node链表 if (fh >= 0) { validated = true; for (Node e = f, pred = null;;) { K ek; //找的key对应的node if (e.hash == hash && ((ek = e.key) == key || (ek != null && key.equals(ek)))) { V ev = e.val; //cv参数代表期望值 //cv==null:表示直接更新value/删除节点 //cv不为空，则只有在key的oldValue等于期望值的时候，才更新value/删除节点 //符合更新value或者删除节点的条件 if (cv == null || cv == ev || (ev != null && cv.equals(ev))) { oldVal = ev; //更新value if (value != null) e.val = value; //删除非头节点 else if (pred != null) pred.next = e.next; //删除头节点 else //因为已经获取了头结点锁，所以此时不需要使用casTabAt setTabAt(tab, i, e.next); } break; } //当前节点不是目标节点，继续遍历下一个节点 pred = e; if ((e = e.next) == null) //到达链表尾部，依旧没有找到，跳出循环 break; } } //红黑树 else if (f instanceof TreeBin) { validated = true; TreeBin t = (TreeBin)f; TreeNode r, p; if ((r = t.root) != null && (p = r.findTreeNode(hash, key, null)) != null) { V pv = p.val; if (cv == null || cv == pv || (pv != null && cv.equals(pv))) { oldVal = pv; if (value != null) p.val = value; else if (t.removeTreeNode(p)) setTabAt(tab, i, untreeify(t.first)); } } } } } if (validated) { if (oldVal != null) { //如果删除了节点，更新size if (value == null) addCount(-1L, -1); return oldVal; } break; } } } return null; } remove方法中流程: 获取hash值 如果未初始化或者该hash值对应的hash桶为空,则直接返回 如果正在扩容则帮助扩容 对该hash桶加锁 遍历该hash桶处的链表或者红黑树,更新或者删除节点. 后话 本文记录了ConcurrentHashMap的基本原理及几个常用方法的实现,但由于才疏学浅以及ConcurrentHashMap的复杂性,文中可能会有些许疏漏,如有错误欢迎随时指出. 对于ConcurrentHashMap,建议还是先学会使用,在有一定的并发基础后再学习源码,至少要了解volatile及synchronized关键字的实现机制以及JMM(java内存模型)的一些基础知识.否则学习起来十分费劲(我看了好久,,),并且囫囵吞枣,学习之后收获也不一定很大. 参考链接 https://www.jianshu.com/p/cf5e024d9432 https://blog.csdn.net/u010723709/article/details/48007881 https://www.jianshu.com/p/5bc70d9e5410 完。 ChangeLog 2018-11-18 完成 以上皆为个人所思所得，如有错误欢迎评论区指正。 欢迎转载，烦请署名并保留原文链接。 联系邮箱：huyanshi2580@gmail.com 更多学习笔记见个人博客------>呼延十 版权所有，盗版必究 all right reserved，powered by GitbookLast Modified On： 2019-03-26 11:07:51 "},"java/集合/2018-10-16-HashMap源码阅读.html":{"url":"java/集合/2018-10-16-HashMap源码阅读.html","title":"HashMap源码阅读","keywords":"","body":"HashMap是什么想必大家都是知道的，日常开发中经常使用，而且常驻于笔试题目及面试中，那么今天将从源码的角度来深入理解一下HashMap。 PS:本文以下分析基于jdk1.7，1.8的改动会在文后总结。 1.什么是HashMap？ HashMap是基于哈希表的Map接口实现，是一个key-value型的数据结构。他在性能良好的情况下，存取的时间复杂度皆为O(1). 要知道数组的获取时间复杂度为O(1),但是他的插入时间复杂度为O(n). 那么HashMap是怎么做到的呢？ 看一下HashMap的属性： //内部数组的默认初始容量，作为hashmap的初始容量，是2的4次方，2的n次方的作用是减少hash冲突 static final int DEFAULT_INITIAL_CAPACITY = 1 [] EMPTY_TABLE = {}; //内部数组表，用来装entry，大小只能是2的n次方。 transient Entry[] table = (Entry[]) EMPTY_TABLE; //存储的键值对的个数 transient int size; /** * 扩容的临界点，如果当前容量达到该值，则需要扩容了。 * 如果当前数组容量为0时（空数组），则该值作为初始化内部数组的初始容量 */ int threshold; //由构造函数传入的指定负载因子 final float loadFactor; //Hash的修改次数 transient int modCount; //threshold的最大值 static final int ALTERNATIVE_HASHING_THRESHOLD_DEFAULT = Integer.MAX_VALUE; //计算hash值时候用，初始是0 transient int hashSeed = 0; //含有所有entry节点的一个set集合 private transient Set> entrySet = null; private static final long serialVersionUID = 362498820763181265L; 注释已经比较完备，便不再做过多的说明。 由里面的 可以看出，HashMap的主体其实是个数组，是Entry这个内部类的数组。 Entry内部类是啥呢？ 这是Entry内部类的属性，可以看出这是个单链表的节点，因为它内部有指向下一个节点的next。 那么就相当明了了，HashMap内部是一个数组，数组的每一个节点是一个链表的头结点，也就是拉链式。 2.HashMap具体是怎么做到的 对于HashMap来说，日常使用的就是两个方法，get(),put(). 我们首先看put. public V put(K key, V value) { //判断当前HashMap是否为空，为空则初始化 if (table == EMPTY_TABLE) { inflateTable(threshold); } //判断传入的key是否为null，为null则放到table[0]的位置或者其链表上 if (key == null) return putForNullKey(value); //计算key的hash值 int hash = hash(key); //计算key存放在数组中的下标 int i = indexFor(hash, table.length); //遍历该位置上的链表，如果存在key值和传入的key值相等，则替换掉旧值 for (Entry e = table[i]; e != null; e = e.next) { Object k; if (e.hash == hash && ((k = e.key) == key || key.equals(k))) { V oldValue = e.value; e.value = value; e.recordAccess(this); return oldValue; } } modCount++; //如果没有这个值，则添加一个Entry addEntry(hash, key, value, i); return null; } /** * Offloaded version of put for null keys */ private V putForNullKey(V value) { for (Entry e = table[0]; e != null; e = e.next) { if (e.key == null) { V oldValue = e.value; e.value = value; e.recordAccess(this); return oldValue; } } modCount++; addEntry(0, null, value, 0); return null; } void addEntry(int hash, K key, V value, int bucketIndex) { //判断是否需要扩容，是的话进行扩容 if ((size >= threshold) && (null != table[bucketIndex])) { resize(2 * table.length); hash = (null != key) ? hash(key) : 0; bucketIndex = indexFor(hash, table.length); } //新建一个Entry createEntry(hash, key, value, bucketIndex); } void createEntry(int hash, K key, V value, int bucketIndex) { //将传入的key-value放在链表的头部，并且指向原链表的头。 Entry e = table[bucketIndex]; table[bucketIndex] = new Entry<>(hash, key, value, e); size++; } 代码中添加了一些注释，大概是可以看懂的，那么这里总结一下流程。 判断当前hashMap是否为空，为空则初始化。 判断传入的key是否为null，为null的话直接放到数组的0位置或者0位置的链表上。 key不为空，计算key的hash值。 计算key在数组中应该存储的下标 遍历数组在该下标的链表，如果找到已经存在的key和传入的key相等，则用新的value替换旧的value。 没找到，则在数组的i位置添加一个Entry。 添加Entry时，先判断是否需要扩容，需要的话扩容，不需要的话下一步。 创建一个Entry，创建的方法是将新传入的key-value放在数组i位置的链表头结点，并且指向原链表头结点。 接下来是get()方法。 public V get(Object key) { //key为null，则在数组0位置寻找值 if (key == null) return getForNullKey(); Entry entry = getEntry(key); return null == entry ? null : entry.getValue(); } private V getForNullKey() { if (size == 0) { return null; } for (Entry e = table[0]; e != null; e = e.next) { if (e.key == null) return e.value; } return null; } final Entry getEntry(Object key) { //如果hashMap中存的值数量为0，则返回null if (size == 0) { return null; } //计算key的hash值 int hash = (key == null) ? 0 : hash(key); //用indexof函数算出数组下标 //在该下标位置上的链表中遍历，寻找与传入key相等的key，否则返回null for (Entry e = table[indexFor(hash, table.length)]; e != null; e = e.next) { Object k; if (e.hash == hash && ((k = e.key) == key || (key != null && key.equals(k)))) return e; } return null; } 同样这里总结一下流程： 判断key==null，如果为null，在数组0位置寻找。 key！=null，判断hashMap中存的值数量是否为0，如果为0直接返回null。 计算key的hash值。 计算key应该在数组中的下标。 遍历Entry数组在该位置的链表，寻找与传入key相等的key，并返回值，如果遍历结束找不到，则返回null。 hash()方法和indexOf()方法 大家可能注意到了，在get()和put()方法的实现中，都使用到了这两个方法，那么这里看一下源码： //通过一系列复杂的计算拿到一个int类型的hash值 final int hash(Object k) { int h = hashSeed; if (0 != h && k instanceof String) { return sun.misc.Hashing.stringHash32((String) k); } h ^= k.hashCode(); // This function ensures that hashCodes that differ only by // constant multiples at each bit position have a bounded // number of collisions (approximately 8 at default load factor). h ^= (h >>> 20) ^ (h >>> 12); return h ^ (h >>> 7) ^ (h >>> 4); } /** * Returns index for hash code h. */ //将hash值和数组长度与，结果等同于hash%length，拿到数组下标 static int indexFor(int h, int length) { // assert Integer.bitCount(length) == 1 : \"length must be a non-zero power of 2\"; return h & (length-1); } 这里重点是：indexOf()方法，将hash值和数组长度与，结果等同于hash%length，拿到数组下标。 结果等同于取模法，但是运算过程更加快速。这里有一个重要的知识点，后续会说噢。 resize()方法 在put()方法及其调用的方法中，当在数组上新添加一个节点时，会判断当前是否需要扩容，怎么判断的呢？ void addEntry(int hash, K key, V value, int bucketIndex) { if ((size >= threshold) && (null != table[bucketIndex])) { resize(2 * table.length); hash = (null != key) ? hash(key) : 0; bucketIndex = indexFor(hash, table.length); } createEntry(hash, key, value, bucketIndex); } 可以看到，当当前已经存储值得size大于阀值，则将数组扩容为原来的两倍。 阀值threshold怎么计算呢？容量 * 负载因子。即 capacity * loadFactory 扩容的方法为： void resize(int newCapacity) { Entry[] oldTable = table; int oldCapacity = oldTable.length; if (oldCapacity == MAXIMUM_CAPACITY) { threshold = Integer.MAX_VALUE; return; } Entry[] newTable = new Entry[newCapacity]; boolean oldAltHashing = useAltHashing; useAltHashing |= sun.misc.VM.isBooted() && (newCapacity >= Holder.ALTERNATIVE_HASHING_THRESHOLD); boolean rehash = oldAltHashing ^ useAltHashing; transfer(newTable, rehash); table = newTable; threshold = (int)Math.min(newCapacity * loadFactor, MAXIMUM_CAPACITY + 1); } /** * Transfers all entries from current table to newTable. */ void transfer(Entry[] newTable, boolean rehash) { int newCapacity = newTable.length; for (Entry e : table) { while(null != e) { Entry next = e.next; if (rehash) { e.hash = null == e.key ? 0 : hash(e.key); } int i = indexFor(e.hash, newCapacity); e.next = newTable[i]; newTable[i] = e; e = next; } } } 新建一个容量为原来两倍的数组，然后将旧数组中的值，rehash之后重新放入新数组，以保证散列均匀。 rehash这个操作是比较费时间的，总的来说扩容操作就比较费时间，因为需要将旧的值移动到新的数组中，因此如果在使用前能预估数量，尽量使用带有参数的构造方法，指定初始容量，尽量避免过多的扩容操作 remove()方法 差点忘记remove()方法了。。 public V remove(Object key) { Entry e = removeEntryForKey(key); return (e == null ? null : e.value); } /** * Removes and returns the entry associated with the specified key * in the HashMap. Returns null if the HashMap contains no mapping * for this key. */ final Entry removeEntryForKey(Object key) { if (size == 0) { return null; } //计算hash int hash = (key == null) ? 0 : hash(key); //计算下标 int i = indexFor(hash, table.length); Entry prev = table[i]; Entry e = prev; while (e != null) { Entry next = e.next; Object k; if (e.hash == hash && ((k = e.key) == key || (key != null && key.equals(k)))) { modCount++; size--; if (prev == e) table[i] = next; else prev.next = next; e.recordRemoval(this); return e; } prev = e; e = next; } return e; } 具体的实现思路也是一样的：首先计算hash继而计算下标，然后遍历数组在该位置的链表，找到该key-value然后将其移除掉。 3.HashMap的一些为什么？ 3.1.为什么扩容的阀值在capacity * loadFactory? 首先了解一下 capacity是指容量，数组最大的容量 loadfactory是指负载因子，是形容当前数组装的有多满的一个值。默认为0.75.也就是如果初始capacity为16，那么当不发生hash碰撞，也就是没有用到链表结构时，写入12个元素即会扩容了。 数组在性能上是比链表优秀的(在HashMap中，数组可以存null，不用进行值的移位)。 HashMap的数据结构，导致即使容量只有16，也可以存储32(还可以更多)个值，只需要每个位置上的链表多链几个节点就好了。 因此可以发现，HashMap的性能问题又来到了时间和空间的取舍上，当你不扩容，仍然可以存储，只是由于链表的变长，性能下降。当你进行太多的扩容，hash碰撞减少，链表长度统一减少，性能提高了但是浪费的空间又多了。0.75这个值是开发者定义的一个对时间空间的折中值。 3.2.性能极限的情况 当存入的值越来越多，却不扩容，HashMap性能就会下降，那么我们极限一点。 HashMap的容量只有1，存入了100个值。由上面的分析可知，这时候HashMap退化成了单链表，存取得时间复杂度都是O(n)。 HashMap的容量为16，存入一个值，在存入第二个值，立即扩容，这样可以尽量的避免hash碰撞，避免产生链表，存取时间复杂度都为O(1). 因此，当你对存取速度要求很高，可以适当调低loadfactory，当你当前对速度无所谓，但是内存很小，可是调大loadfactory，当然大部分时候默认值0.75都是一个不错的选择。 loadfactory的值为：0.75，2，4等数字都是合法值 3.3.为什么HashMap的容量永远是2的次幂？ 看过上面的代码我们可以发现，HashMap的初始容量为16，扩容为原容量乘以2。 也就是说，HashMap的容量永远是2的次幂，这是为什么呢？ 想一想哪里使用到了容量这个参数呢？ 在拿到key的hash值，计算当前key在数组中的下标的时候，运用了如下的方法进行计算： 真实的length为16，我们假设一个假的lengthWrong = 15； 同时我们有两个key，hash之后拿到的hash=8，和hash=9； length - 1 二进制 8 & length - 1 9 & length- 1 15 1111 1000 & 1111 = 1000 = 8 1001 & 1111 = 1001 = 9 14 1110 1000 & 1110 = 1000 = 8 1001 & 1110 = 1000 = 8 可以看到当长度为15时，当h = 8,h =9 h & length - 1 拿到的结果一样都为8，也就是这两个key都存在数组中下标为8的链表上。这是为什么呢？ 当length为偶数时，length- 1位奇数，奇数的二进制最后一位必然为1，而当length = 奇数时，length - 1位偶数，偶数的二进制最后一位为0. 二进制与运算有如下规则： 1 & 任意 = 任意； 0 & 任意 = 0； 也就是说，当length = 16时，计算的下标可以为1-16任意数字，而当length=15时，计算的下标只能为2，4，6，8 等等偶数，这样就浪费了一般的存储空间，同时还增大了hash碰撞的概率，使得HashMap的性能变差。 因此length必须为偶数，而length为2的次幂不仅能保证为偶数，还可以实现h & length - 1 = h % length,可谓是一举两得了。666啊。 扩展(Java8 的hashMap有哪些改进？） 在3.2中提到，当极限情况下HashMap会退化成链表，存取时间复杂度变为O(n)，这显然是不能接受的，因此在java8中对这一点做了优化。 在java7中，存储在数组上的是一个链表的头结点，当哈希碰撞之后，不断的增长链表的长度，这会导致性能下降。在java8中，引入了红黑树数据结构，当链表长度小于8时，仍然使用链表存储，而当长度大于8时，会将链表转化为红黑树。同时，当树的节点数小于6时，会从红黑树变成链表。 这样改进之后，即使在性能最差的情况下，hashMap的存取时间复杂仍为O(logn). 而红黑树的具体实现，这里不再详细叙述，这属于数据结构的范围了，在HashMap中展开不合适。 小bug 今天在编码过程中,对Map 用long作为key去取值,结果自然是取不到的,但是代码并不报错. Map testMap = new HashMap<>(); testMap.put(1, 1); Integer i = testMap.get((long)1); System.out.println(i); 在装箱过后,会变成Long,实际取值时候的HashCode是不一样的,下面是Integer和Long的HashCode方法. // Integer public static int hashCode(int value) { return value; } //Long public static int hashCode(long value) { return (int)(value ^ (value >>> 32)); } 所以不要忽略代码中的警告哦~并不是只有error才会导致错误. 完. ChangeLog 2018-10-17 完成 2019-06-28 补充bug 以上皆为个人所思所得，如有错误欢迎评论区指正。 欢迎转载，烦请署名并保留原文链接。 联系邮箱：huyanshi2580@gmail.com 更多学习笔记见个人博客------>呼延十 版权所有，盗版必究 all right reserved，powered by GitbookLast Modified On： 2019-06-28 17:14:16 "},"java/集合/2018-11-03-HashTable和-HashMap的区别.html":{"url":"java/集合/2018-11-03-HashTable和-HashMap的区别.html","title":"HashTable和-HashMap的区别","keywords":"","body":"在前面的一片文章写了HashMap的源码阅读，这次来说一下HashTable的一些知识。 在阅读源码过后，我发现HashMap与HashTable的实现方式基本一致，因此这篇文章不再介绍HashTable中每个方法的源码实现，知识列举两者的区别与联系，有兴趣的读者可以点击上面的链接去看一下HashMap的实现。 区别 1.HashTable不能存储空值，而HashMap可以。 在HashTable的源码中put()方法，开始就检查了存入的值是否为空，如果为空则抛出了空指针异常。 2.HashTable是线程安全的，而HashMap不是。 查看源码可以发现，HashTable中所有改变值得操作都使用了synchronized关键字修饰。 synchronized关键字可以保证同一时间可以保证只有一个线程可以访问该实例。 结论 1.如果需要存储空值，则不能使用HashTable。 2.HashTable使用synchronized关键字来保证了线程安全性，但是在单线程的使用环境下，会造成一定的性能浪费，在使用前需要进行选择。 注意事项 1.可否让HashMap线程安全？ 答案是：可以,通过下面的方式可以获得同步的Map。 HashMap hashMap = new HashMap<>(); Map syMap = Collections.synchronizedMap(hashMap); 2.在Java5之后，更加建议使用ConcurrentHashMap，该类线程安全且性能远优于HashTable。 完。 ChangeLog 2018-11-03 完成 以上皆为个人所思所得，如有错误欢迎评论区指正。 欢迎转载，烦请署名并保留原文链接。 联系邮箱：huyanshi2580@gmail.com 更多学习笔记见个人博客------>呼延十 版权所有，盗版必究 all right reserved，powered by GitbookLast Modified On： 2019-03-26 11:07:51 "},"java/集合/2018-12-16-LinkedHashMap源码分析.html":{"url":"java/集合/2018-12-16-LinkedHashMap源码分析.html","title":"LinkedHashMap源码分析","keywords":"","body":"LInkedHashMap是基于HashMap的,因此如果不太清楚HashMap的实现的话,请先阅读HashMap 源码阅读 我们都知道,HashMap 是无序的,也就是说,遍历时候的顺序与访问的顺序无关. 而在一些场景下,我们即需要HashMap的特性,又需要它能够保持一定的顺序呢? JAVA 在 JDK1.4 以后提供了 LinkedHashMap 来帮助我们实现了有序的 HashMap！ LinkedHashMap可以有两种保存的顺序:插入顺序及访问顺序. 在如下的代码中,我们以1,2,4,3的顺序分别向HashMap,插入顺序的LinkedHashMap,访问顺序的LinkedHashMap中插入四条数据,并在访问顺序的LinkedHashMap中按照4231的顺序访问元素. 代码如下: public void linkedHashMapTest() { Map test = new LinkedHashMap<>(); test.put(\"1\", 1); test.put(\"2\", 2); test.put(\"4\", 4); test.put(\"3\", 3); System.out.println(); System.out.print(\"LinkedHashMap:\"); test.forEach((key, value) -> System.out.print(value)); //hashmap Map test1 = new HashMap<>(); test1.put(\"1\", 1); test1.put(\"2\", 2); test1.put(\"4\", 4); test1.put(\"3\", 3); System.out.println(); System.out.print(\"HashMap:\"); test1.forEach((key, value) -> System.out.print(value)); //linkedHashMap 按照访问顺序 Map test2 = new LinkedHashMap<>(16,0.75f,true); test2.put(\"1\", 1); test2.put(\"2\", 2); test2.put(\"4\", 4); test2.put(\"3\", 3); test2.get(\"4\"); test2.get(\"2\"); test2.get(\"3\"); test2.get(\"1\"); System.out.println(); System.out.print(\"linkedHashMap ---with use:\"); test2.forEach((key, value) -> System.out.print(value)); } 输出结果如下: LinkedHashMap:1243 HashMap:1234 linkedHashMap ---with use:4231 可以看到,HashMap是无序的,遍历结果的顺序和插入顺序无关,是key值的自然排序,而LinkedHashMap的顺序是插入顺序或者访问顺序. LInkedHashMap怎么保存顺序的? 在HashMap的基础上,对每个节点添加指向上一个元素和下一个元素的\"指针\",这样在数据的保存时,仍使用HashMap的原理.同时,添加向前向后指针,使得所有的节点形成双向链表,在遍历时使用双向链表遍历,保证顺序. 源码阅读 下面将通过阅读LinkedHashMap的源码来学习使用这个类. 类的定义 public class LinkedHashMap extends HashMap implements Map{ } LinkedHashMap集成了HashMap类以及实现了Map接口,那么LinkedHashMap作为HashMap的子类,天然集成了HashMap的所有方法,也拥有了HashMap的一切特性. 类的成员 /** * The head (eldest) of the doubly linked list. */ transient LinkedHashMap.Entry head; /** * The tail (youngest) of the doubly linked list. */ transient LinkedHashMap.Entry tail; /** * The iteration ordering method for this linked hash map: true * for access-order, false for insertion-order. * * @serial */ final boolean accessOrder; LInkedHashMap新增了三个成员变量,首先是双链表的头部节点和尾部节点.然后是一个标识位,标识此LinkedHashMap使用插入顺序还是访问顺序. 那么LinkedHashMap.Entry是什么呢? static class Entry extends HashMap.Node { Entry before, after; Entry(int hash, K key, V value, Node next) { super(hash, key, value, next); } } 他继承自HashMap的内部类Node,之后又添加了指向上一节点的before和指向下一节点的after,这样就形成了双向链表,用来记录元素的顺序. 构造方法 LinkedHashMap的构造方法共有5个,除了最后一个,其他的在内部实现都是调用了父类HashMap对应的构造方法,并将标识位accessOrder置为false.(默认值即false).在最后一个构造方法中,将accessOrder置为参数传入的值. get()方法 public V get(Object key) { Node e; if ((e = getNode(hash(key), key)) == null) return null; if (accessOrder) afterNodeAccess(e); return e.value; } void afterNodeAccess(Node e) { // move node to last LinkedHashMap.Entry last; if (accessOrder && (last = tail) != e) { LinkedHashMap.Entry p = (LinkedHashMap.Entry)e, b = p.before, a = p.after; p.after = null; if (b == null) head = a; else b.after = a; if (a != null) a.before = b; else last = b; if (last == null) head = p; else { p.before = last; last.after = p; } tail = p; ++modCount; } } LinkedHashMap对get方法进行了重写,具体流程为: 调用父类HashMap的的getNode()方法,如果结果值为空,则返回空. 如果accessOrder为true,则调用afterNodeAccess()方法将当前访问的元素移动到链表的末尾.(当初始化为访问顺序的LinkedHashMap时,才会执行此操作.) 如果accessOrder为false,返回getNode()获得的值. put()方法 Node newNode(int hash, K key, V value, Node e) { LinkedHashMap.Entry p = new LinkedHashMap.Entry(hash, key, value, e); linkNodeLast(p); return p; } private void linkNodeLast(LinkedHashMap.Entry p) { LinkedHashMap.Entry last = tail; tail = p; if (last == null) head = p; else { p.before = last; last.after = p; } } LInkedHashMap并没有重写put()方法,但是重写了put()方法中会调用的newNode()方法,代码如上面所示. 在重写后的newNode()方法中,调用父类的构造方法新建一个节点后,调用linkNodeLast()方法,将新插入的节点链接在双链表的尾部. remove()方法 void afterNodeRemoval(Node e) { // unlink LinkedHashMap.Entry p = (LinkedHashMap.Entry)e, b = p.before, a = p.after; p.before = p.after = null; if (b == null) head = a; else b.after = a; if (a == null) tail = b; else a.before = b; } LinkedHashMap也没有重写remove()方法,但是对remove方法中removeNode()方法中调用的回调函数afterNodeRemoval进行了重写. 在按照HashMap的方式删除节点后,将该节点同步的从双链表中移除掉. containsVaule()方法 public boolean containsValue(Object value) { for (LinkedHashMap.Entry e = head; e != null; e = e.after) { V v = e.value; if (v == value || (value != null && value.equals(v))) return true; } return false; } 想必与HashMap,LinkedHashMap重写后的containsVaule()更为高效一些,直接在双链表中进行遍历判断是否存在value相等的值. forEach public void forEach(BiConsumer action) { if (action == null) throw new NullPointerException(); int mc = modCount; for (LinkedHashMap.Entry e = head; e != null; e = e.after) action.accept(e.key, e.value); if (modCount != mc) throw new ConcurrentModificationException(); } LinkedHashMap的遍历方式上面的代码所示: 直接从双链表的头部开始遍历,逐个输出即可. 总结 在读懂了HashMap的源码后,LinkedHashMap会显得比较简单,因为他的大多数操作都是在HashMap的基础上完成的. LinkedHashMap有几个比较关键的问题如下: 1.如何实现的元素有序? 在HashMap的基础上,对每一个节点添加向前向后指针,这样所有的节点形成了双向链表,自然就是有序的. 2.如何保证顺序的正确以及同步 通过重写的一些关键的方法,在元素发生增删改查等行为时,除了在Hash桶上进行操作,也对链表进行相应的更新,以此来保证顺序的正确. 3.如何实现两种顺序(插入顺序或者访问顺序)? 通过内部的标识位accessOrder来记录当前LinkedHashMap是以什么为序,之后再处理元素时通过读取accessOrder的值来控制链表的顺序. 4.为什么重写containsValue()而不重写containsKey()? 可以看一下他们分别是怎么实现的,就知道原因了. 在HashMap中: public boolean containsValue(Object value) { Node[] tab; V v; if ((tab = table) != null && size > 0) { for (int i = 0; i e = tab[i]; e != null; e = e.next) { if ((v = e.value) == value || (value != null && value.equals(v))) return true; } } } return false; } public boolean containsKey(Object key) { return getNode(hash(key), key) != null; } containsKey()是通过hash值直接计算出该key对应的数组下标,之后在该hash桶的链表上进行查找相同的key. containsValue()是对table进行遍历,对其中的每一个hash桶的所有值进行遍历,去寻找相同的value. 而在LinkedHashMap中,如果都改为对双向链表的遍历来寻找key和value. 无疑在value的查找时会有性能的提升,而对于key的查找则更为低效了. 如果改为遍历双向链表进行查找key值,则从key->hash->index的方法退化到逐一遍历,丧失了HashMap的最大特性. 完。 ChangeLog 2018-12-16 完成 以上皆为个人所思所得，如有错误欢迎评论区指正。 欢迎转载，烦请署名并保留原文链接。 联系邮箱：huyanshi2580@gmail.com 更多学习笔记见个人博客------>呼延十 版权所有，盗版必究 all right reserved，powered by GitbookLast Modified On： 2019-03-26 11:07:51 "},"java/juc/2019-04-23-(juc系列)从-AtomicInteger来学习-Java的原子类.html":{"url":"java/juc/2019-04-23-(juc系列)从-AtomicInteger来学习-Java的原子类.html","title":"(juc系列)从-AtomicInteger来学习-Java的原子类","keywords":"","body":"前言 Java的concurrent包一直都是很重要的知识点,因为他是进阶高级工程师必备,而其中的atomic包中的原子类是最为经常使用到的,所以学习一下atomic下的一些类的源码. Java原子类实现了线程安全的操作,比如AtomicInteger实现了对int值的安全的加减等. 所以我们学习主要分为两部分,首先学习为什么可以实现线程安全?其次是学习这些类的API,加强记忆方便后续使用. 怎么实现线程安全? 这个我们以AtomicInteger为例,其中的incrementAndGet()方法实现方式为: //API public final int incrementAndGet() { return unsafe.getAndAddInt(this, valueOffset, 1) + 1; } //CAS public final int getAndAddInt(Object var1, long var2, int var4) { int var5; do { var5 = this.getIntVolatile(var1, var2); } while(!this.compareAndSwapInt(var1, var2, var5, var5 + var4)); return var5; } 可以看到实现比较简单,调用了Unsafe类的getAndAddInt方法,该方法的实现也贴了出来,其中调用了两个native方法. 实现原子操作的机制是:CAS. CAS:compare and swap,比较交换,当且仅当目标值等于给定值的时候才进行写入操作.具体原理可以google一下. 可以看到在上面的getAndAddInt方法中,显示获取了当前内存地址的值,然后进行比较交换,如果相同则成功,不相同则轮询. AtomicInteger的常用API incrementAndGet: 自增一且返回新值. getAndIncrement: 获取当前值之后将其自增. decrementAndGet: 自减一之后返回新值. getAndDecrement: 获取当前值之后自减. get: 获取当前值. set: 设置一个值. getAndSet: 设置新值,返回旧值. AtomicBoolean的常用API getAndSet:设置新值返回旧值. get: 返回当前值. set: 设置一个值. compareAndSet: CAS实现的set. AtomicLong 略过 AtomicReference 原子的引用....可以随便放进去什么值. API出来了get和set外: updateAndGet: 更新值并获取新值. getAndUpdate: 获取旧值之后更新值. 注意传入的参数是声明的V. AtomicIntegerArray int数组的原子类. 和AtomicInteger并没有什么不同,只是对传入的数组下标进行了一下计算,来实现对数组的某个index上的值的原子更改. 完.好水啊...以为原子类要看很久呢. ChangeLog 2019-04-23 完成 以上皆为个人所思所得，如有错误欢迎评论区指正。 欢迎转载，烦请署名并保留原文链接。 联系邮箱：huyanshi2580@gmail.com 更多学习笔记见个人博客------>呼延十 版权所有，盗版必究 all right reserved，powered by GitbookLast Modified On： 2021-10-17 17:42:19 "},"java/juc/2019-03-07-(juc系列)Java中Executors提供的的4种线程池.html":{"url":"java/juc/2019-03-07-(juc系列)Java中Executors提供的的4种线程池.html","title":"(juc系列)Java中Executors提供的的4种线程池","keywords":"","body":"前言 了解一下线程池的源码实现. ThreadPoolExecutor jdk中关于线程池一个比较核心的类是ThreadPoolExecutor,先来看一下他的实现. 构造方法 public ThreadPoolExecutor(int corePoolSize, int maximumPoolSize, long keepAliveTime, TimeUnit unit, BlockingQueue workQueue) { this(corePoolSize, maximumPoolSize, keepAliveTime, unit, workQueue, Executors.defaultThreadFactory(), defaultHandler); } public ThreadPoolExecutor(int corePoolSize, int maximumPoolSize, long keepAliveTime, TimeUnit unit, BlockingQueue workQueue, ThreadFactory threadFactory) { this(corePoolSize, maximumPoolSize, keepAliveTime, unit, workQueue, threadFactory, defaultHandler); } public ThreadPoolExecutor(int corePoolSize, int maximumPoolSize, long keepAliveTime, TimeUnit unit, BlockingQueue workQueue, RejectedExecutionHandler handler) { this(corePoolSize, maximumPoolSize, keepAliveTime, unit, workQueue, Executors.defaultThreadFactory(), handler); } public ThreadPoolExecutor(int corePoolSize, int maximumPoolSize, long keepAliveTime, TimeUnit unit, BlockingQueue workQueue, ThreadFactory threadFactory, RejectedExecutionHandler handler) { if (corePoolSize 可以看到\bThreadPoolExecutor提供了4中构造方法,分别传入了不同的参数,而前三个构造函数都是调用的第四个构造函数,对其参数进行了赋值. 参数 那么我们了解一下这些参数的作用: corePoolSize:核心池的大小.即正常情况下,保持活跃的线程的数量. maximumPoolSize:线程最大数量. keepAliveTime:线程未使用保持活跃的时间.一般情况下,只有在当前线程数大于corePoolSize才会生效. workQueue:一个阻塞队列,用来存放待执行的任务. threadFactory: 线程工厂,负责创建线程. handler: 拒绝处理任务时的策略. 四种线程池 Java通过Executors提供四种线程池，分别为： newCachedThreadPool创建一个可缓存线程池，如果线程池长度超过处理需要，可灵活回收空闲线程，若无可回收，则新建线程。 newFixedThreadPool 创建一个定长线程池，可控制线程最大并发数，超出的线程会在队列中等待。 newScheduledThreadPool 创建一个定长线程池，支持定时及周期性任务执行。 newSingleThreadExecutor 创建一个单线程化的线程池，它只会用唯一的工作线程来执行任务，保证所有任务按照指定顺序(FIFO, LIFO, 优先级)执行。 我们来一一看一下: newCachedThreadPool public static ExecutorService newCachedThreadPool() { return new ThreadPoolExecutor(0, Integer.MAX_VALUE, 60L, TimeUnit.SECONDS, new SynchronousQueue()); } 通过指定参数,返回ThreadPoolExecutor来实现. 参数为: 核心线程池大小=0 最大线程池大小为Integer.MAX_VALUE 线程过期时间为60s 使用SynchronousQueue作为工作队列. 所以线程池为0-max个线程,并且会60s过期,实现了可以缓存的线程池. newFixedThreadPool public static ExecutorService newFixedThreadPool(int nThreads) { return new ThreadPoolExecutor(nThreads, nThreads, 0L, TimeUnit.MILLISECONDS, new LinkedBlockingQueue()); } 核心线程池大小=传入参数 最大线程池大小为传入参数 线程过期时间为0ms LinkedBlockingQueue作为工作队列. 通过最小与最大线程数量来控制实现定长线程池. newScheduledThreadPool public ScheduledThreadPoolExecutor(int corePoolSize) { super(corePoolSize, Integer.MAX_VALUE, 0, NANOSECONDS, new DelayedWorkQueue()); } 核心线程池大小=传入参数 最大线程池大小为Integer.MAX_VALUE 线程过期时间为0ms DelayedWorkQueue作为工作队列. 主要是通过DelayedWorkQueue来实现的定时线程. newSingleThreadExecutor public static ExecutorService newSingleThreadExecutor() { return new FinalizableDelegatedExecutorService (new ThreadPoolExecutor(1, 1, 0L, TimeUnit.MILLISECONDS, new LinkedBlockingQueue())); } 核心线程池大小=1 最大线程池大小为1 线程过期时间为0ms LinkedBlockingQueue作为工作队列. 综上,java提供的4种线程池,只是预想了一些使用场景,使用参数定义的而已,我们在使用的过程中,完全可以根据业务需要,自己去定义一些其他类型的线程池来使用(如果需要的话). 其中多种阻塞队列的实现方式显然比4种线程池更难一些. 完. ChangeLog 2019-01-28 完成 以上皆为个人所思所得，如有错误欢迎评论区指正。 欢迎转载，烦请署名并保留原文链接。 联系邮箱：huyanshi2580@gmail.com 更多学习笔记见个人博客------>呼延十 版权所有，盗版必究 all right reserved，powered by GitbookLast Modified On： 2021-10-17 17:42:06 "},"java/juc/2021-10-14-(juc系列)ForkJoin框架源码学习.html":{"url":"java/juc/2021-10-14-(juc系列)ForkJoin框架源码学习.html","title":"(juc系列)ForkJoin框架源码学习","keywords":"","body":"简介 JUC系列提供的又一个线程池，采用分治思想，及工作窃取策略，能获得更高的并发性能. 分治思想 通过将大任务，切割成小任务并发执行，由每一个任务等待所有子任务的返回. 大概可以理解为递归的思路. 比如要计算1~100的累加和. 那么任务: sum(1,100). 首先不断的切分，直到单个任务足够小，然后并发运行，之后再进行join收集操作. 工作窃取策略 工作窃取（work-stealing）算法是指某个线程从其他队列里窃取任务来执行。 每个线程有自己的工作队列，当自己的工作队列为空，随机从别的线程的工作队列尾部窃取一个任务进行执行.这样可以有效的提升并发度. 框架 Fork/Join框架，主要分为三个部分: ForkJoinPool 线程池，管理线程 ForkJoinTask 任务基类，定义一个任务 ForkJoinWorkerThread 线程，实现任务执行等 这三个模块的关系是: ForkJoinPool调用池中的ForkJoinWorkerThread,来执行ForkJoinTask. 下面就结合源码，逐一介绍这三个部分. 源码阅读 ForkJoinPool 线程池,负责调度 官方注释简介 这是官方注释的简单翻译版本. 用来运行ForkJoinTask的一个线程池. ForkJoinPool提供了提交非fork/join任务的客户端，以及管理和监控操作. ForkJoinPool和其他线程池不同的是，它实现了工作窃取算法: 所有池中的线程都尝试去寻找并执行任务. 包括提交到线程池的任务或者被其他任务创建的任务.(如果一个任务都没有， 最终所有的线程阻塞). 这个算在大多数任务都会创建一些新的子任务,或者大量的小任务被提交时，有更好的效率. 尤其当asyncMode在构造函数中被设置为true时, ForkJoinPool也可以适配事件型的任务. 所有的工作线程初始化为守护线程. 静态的commonPool()是对大多数应用是可用且合适的. 公用的池用来执行那些没有被明确提交给特殊线程池的任务. 使用公用的线程池通常能够减少资源的使用. 需要分离的或者定制化的线程池的任务，ForkJoinPool用一个给定的并发等级来进行初始化. 默认情况下，这个数字等于可用的处理器的数量. 线程池尝试保持足够活跃的线程，通过动态的添加暂停或者唤醒内部的工作线程. 然而，没有什么调整是保证的， 在面对阻塞式IO或者其他没有被管理的同步操作时. 嵌套的ManagedBlocker接口允许扩展一些同步器. 默认的策略可以使用构造器来覆盖. 具体的文档在ThreadPoolExecutor里面. 为了执行和生命周期的管理，这个类提供了状态检查方法, getStealCount等用来帮助开发,调试和监控fork/join的应用程序. 另外，toString返回线程池状态，以进行一些非正式的监控. 在其他的ExecutorService中，有三种主要的执行策略，总结在下面的表中. 他们主要设计用于没有进行fork/join操作的客户端使用. 这些方法的主要形式接受 ForkJoinTask 的实例，但重载形式也允许混合执行普通的基于 Runnable 或 Callable 的活动。但是，已经在池中执行的任务通常应该使用表中列出的计算内形式，除非使用通常不加入的异步事件样式任务，在这种情况下，方法选择之间几乎没有区别 构造共用池的参数，可以被一下属性进行控制: parallelism 并发等级，一个不为负数的整数 threadFactory 线程工厂， exceptionHandler 异常处理器 maximumSpares 为了保持目标并发等级，最大允许的线程数量 注意,这个类限制最大的运行线程树为32767.尝试创建更多的线程将会抛出异常. 源码 类继承结构图: 工作队列 WorkQueue 首先介绍一个内部类,是一个工作队列的实现. 它实现了双端的队列,用来对单个任务进行管理. 且一个工作队列被一个工作的线程持有. 属性 volatile int source; // source queue id, or sentinel 源队列ID int id; // pool index, mode, tag 池ID int base; // index of next slot for poll // 下一个拿的index int top; // index of next slot for push // 下一个放的index volatile int phase; // versioned, negative: queued, 1: locked // 1是锁定. 负数是有队列 int stackPred; // pool stack (ctl) predecessor link // int nsteals; // number of steals // 偷取任务数量 ForkJoinTask[] array; // the queued tasks; power of 2 size // 队列中的任务 final ForkJoinPool pool; // the containing pool (may be null) // 池子 final ForkJoinWorkerThread owner; // owning thread or null if shared // 所属线程 核心属性: array保存了队列中的所有任务,同时提供队列头和尾两个指针,用于进行双端队列的出队和入队等. push 入队任务 这是个内部的方法,仅被非共享的队列调用. 主要用于任务分解为子任务后,调用fork.此时,将任务放到当前线程已经持有的队列中.会调用这个方法. final void push(ForkJoinTask task) { ForkJoinTask[] a; int s = top, d = s - base, cap, m; ForkJoinPool p = pool; // 已有队列 if ((a = array) != null && (cap = a.length) > 0) { // CAS更新任务 QA.setRelease(a, (m = cap - 1) & s, task); // 下标+1 top = s + 1; // 数组满了,扩容 if (d == m) growArray(false); else if (QA.getAcquire(a, m & (s - 1)) == null && p != null) { VarHandle.fullFence(); // was empty // 新搞一个线程过来? TODO p.signalWork(null); } } } 通过CAS向数组中添加任务，成功后如果需要扩容任务数组. poll 出队 final ForkJoinTask poll() { int b, k, cap; ForkJoinTask[] a; // 队列中有值， while ((a = array) != null && (cap = a.length) > 0 && top - (b = base) > 0) { // 从数组中获取一个任务 ForkJoinTask t = (ForkJoinTask) QA.getAcquire(a, k = (cap - 1) & b); if (base == b++) { if (t == null) Thread.yield(); // await index advance // 置为空 else if (QA.compareAndSet(a, k, t, null)) { BASE.setOpaque(this, b); // 返回任务 return t; } } } return null; } 从工作队列中取一个任务返回. // 获取第一个任务 final ForkJoinTask peek() { int cap; ForkJoinTask[] a; return ((a = array) != null && (cap = a.length) > 0) ? a[(cap - 1) & ((id & FIFO) != 0 ? base : top - 1)] : null; } 变量 // 权限 static final RuntimePermission modifyThreadPermission; // common pool static final ForkJoinPool common; // 并发度 static final int COMMON_PARALLELISM; // 偷取数量 volatile long stealCount; // collects worker nsteals // 保持活跃的时间 final long keepAlive; // milliseconds before dropping if idle // 下一个工作线程的下标 int indexSeed; // next worker index // 最小最大线程 final int bounds; // min, max threads packed as shorts // 并发度 volatile int mode; // parallelism, runstate, queue mode // 工作队列 WorkQueue[] workQueues; // main registry // 工作线程的前缀 final String workerNamePrefix; // for worker thread string; sync lock // 线程工厂 final ForkJoinWorkerThreadFactory factory; // 异常处理器 final UncaughtExceptionHandler ueh; // per-worker UEH // 是否饱和的判断方法 final Predicate saturate; // 核心的状态控制 @jdk.internal.vm.annotation.Contended(\"fjpctl\") // segregate volatile long ctl; // main pool control ForkJoinPool的一些属性,核心属性: workQueues: 保存了当前的一些工作队列 ctl 线程池的状态记录,由一个long. 按位进行编码,存储相关信息. 构造方法 public ForkJoinPool() { this(Math.min(MAX_CAP, Runtime.getRuntime().availableProcessors()), defaultForkJoinWorkerThreadFactory, null, false, 0, MAX_CAP, 1, null, DEFAULT_KEEPALIVE, TimeUnit.MILLISECONDS); } public ForkJoinPool(int parallelism) { this(parallelism, defaultForkJoinWorkerThreadFactory, null, false, 0, MAX_CAP, 1, null, DEFAULT_KEEPALIVE, TimeUnit.MILLISECONDS); } public ForkJoinPool(int parallelism, ForkJoinWorkerThreadFactory factory, UncaughtExceptionHandler handler, boolean asyncMode) { this(parallelism, factory, handler, asyncMode, 0, MAX_CAP, 1, null, DEFAULT_KEEPALIVE, TimeUnit.MILLISECONDS); } public ForkJoinPool(int parallelism, ForkJoinWorkerThreadFactory factory, UncaughtExceptionHandler handler, boolean asyncMode, int corePoolSize, int maximumPoolSize, int minimumRunnable, Predicate saturate, long keepAliveTime, TimeUnit unit) { // check, encode, pack parameters // 并行度 if (parallelism MAX_CAP || maximumPoolSize 1) ? parallelism - 1 : 1; // at least 2 slots // 初始工作队列的数量 n |= n >>> 1; n |= n >>> 2; n |= n >>> 4; n |= n >>> 8; n |= n >>> 16; n = (n + 1) 提供了4个构造方法，都是调用的最后一个。 计算了一堆参数.比如并行度,活跃时间,初始的工作队列数量,模式,ctl变量的初始值等等. 提交任务 由ForkJoinPool进行任务管理,因此它负责接受外部提交的任务. invoke execute execute submit submit submit submit invokeAll 这些方法都是类似于execute方法,接受Runnable,Callable,ForkJoinTask三种任务,进行一定的封装,然后进行提交. 内部都是调用的externalSubmit方法.见下面的解析: execute public void execute(Runnable task) { if (task == null) throw new NullPointerException(); ForkJoinTask job; if (task instanceof ForkJoinTask) // avoid re-wrap job = (ForkJoinTask) task; else job = new ForkJoinTask.RunnableExecuteAction(task); // 核心的外部提交方法 externalSubmit(job); } ForkJoinTask.RunnableExecuteAction 是对ForkJoinTask进行简单实现，包装一个Runnable的简单内部类. 首先对提交的任务进行wrap.之后调用externalSubmit. externalSubmit private ForkJoinTask externalSubmit(ForkJoinTask task) { Thread t; ForkJoinWorkerThread w; WorkQueue q; if (task == null) throw new NullPointerException(); // 当前线程就是一个`ForkJoin`类型的线程，直接调用该线程的队列进行push, 说明是内部分裂开的任务,直接入队当前线程的队列 if (((t = Thread.currentThread()) instanceof ForkJoinWorkerThread) && (w = (ForkJoinWorkerThread)t).pool == this && (q = w.workQueue) != null) // 调用上方介绍过的`workQueue.push`方法 q.push(task); else // 调用externalPush进行提交任务 externalPush(task); return task; } 核心逻辑: 如果当前线程,就是一个ForkJoin类型的线程,那么说明是内部分裂开的任务,直接入队当前线程的任务队列即可. 否则调用externalPush进行提交任务.见下方. externalPush final void externalPush(ForkJoinTask task) { int r; // initialize caller's probe // 随机一个探针 if ((r = ThreadLocalRandom.getProbe()) == 0) { ThreadLocalRandom.localInit(); r = ThreadLocalRandom.getProbe(); } for (;;) { WorkQueue q; int md = mode, n; WorkQueue[] ws = workQueues; if ((md & SHUTDOWN) != 0 || ws == null || (n = ws.length) [] qa = new ForkJoinTask[INITIAL_QUEUE_CAPACITY]; q = new WorkQueue(this, null); q.array = qa; q.id = qid; q.source = QUIET; if (lock != null) { // unless disabled, lock pool to install synchronized (lock) { // 放到对应位置上. WorkQueue[] vs; int i, vn; if ((vs = workQueues) != null && (vn = vs.length) > 0 && vs[i = qid & (vn - 1) & SQMASK] == null) vs[i] = q; // else another thread already installed } } } // 如果工作队列的当前位置在忙，重新随机一个位置. else if (!q.tryLockPhase()) // move if busy r = ThreadLocalRandom.advanceProbe(r); else { // 该位置不为空,且不忙,就唤醒来干活了. if (q.lockedPush(task)) signalWork(null); return; } } } 在已有的工作队列中,随机一个位置: 如果该位置为空,则为当前的任务新建一个工作队列. 如果该位置有工作队列,且正在忙,随机另外一个位置. 如果当前位置有工作队列,但是空闲,则唤醒让其工作. ForkJoinTask 任务定义,负责计算逻辑,任务拆分等 官方注释简单翻译 使用ForkJoinPool执行的任务的一个基类. 一个ForkJoinTask是一个类似于线程的实体，但是比一个真正的线程更加轻量级. 在ForkJoinPool中,很多的任务和子任务，可能被少量的实际线程管理. 作为代价，有些使用受限制. 一个主要的ForkJoinTask在明确提交给ForkJoinPool时开始执行，或者当前任务没有参与到ForkJoin囧穿，则通过fork,invoke等相关的方法，在ForkJoinPool.commonPool()中执行. 一旦开始执行，它通常会依次执行其他子任务.就像类名一样，大多数程序使用ForkJoinTask只采用Fork,join方法，或者像invokeAll这种衍生品. 然而，这个类还提供了许多可以在高级用法中发挥作用的其他方法，以及允许支持新形式的 fork/join 处理的扩展机制。 ForkJoinTask是Future的轻量级形式. 他的高效来源于一组限制(仅部分静态强制执行).它主要应用在计算纯函数，或者对隔离对象进行操作的计算任务. 主要的协调机制是: fork 安排异步执行 join 等待任务的计算结果 计算中应该尽量避免同步方法或者代码块, 同时尽量减少其他的阻塞同步，除了等待其他任务或者使用Phasers等可以与fork/join调度合作的同步器. 子任务也应该尽量避免阻塞IO. 并且理想情况下，应该访问完全独立于其他任务的变量. 通过不允许抛出IOException等已检查异常，这些限制被强制执行. 但是，计算仍然可能遇到未经检查的异常，这些异常会被抛出. 可以定义和使用会阻塞的ForkJoinTask.但是这样做要考虑以下三个因素: 如果其他任务应该阻塞在外部的同步器或者io. 将无法完成. 事件类型的异步任务将永远不会joined，他们通常属于这一类. 为了尽量减少资源消耗，任务应该尽量小. 理想情况下只执行阻塞操作. 除非ForkJoinPool.ManagedBlocker被使用，或者已知可能阻塞的任务数量小于ForkJoinPool.getParallelism等级.池子不保证有足够的线程，以达到较好的性能表现. 等待完成并提取结果的主要方法是join, 但是有一些变体: Future.get()方法支持可中断，可超时的等待。 invoke方法在语义上等效与fork方法 join()方法永远尝试在当前线程开始执行. 这些方法都是静默形式的，不会提取结果或者报告异常. 这些方法在有一系列的任务等待执行，并且你需要延迟处理结果时很有用. invokeAll方法和最常见的并发调用一样: 派生一系列的任务然后等待全部. 在典型的使用场景中，fork-join对就像递归调用中，一个call和一个return一样. 像其他的递归调用一样，返回操作应该尽快被执行. 任务的执行状态，可能会通过几种级别来查询细节, isDone返回true,如果任务完成的话(包括被取消) isCompletedNormally返回true,如果任务没有取消或者抛出异常，而是正常执行结束. isCancelled返回ture,如果任务被取消。包含任务抛出取消异常. isCompletedAbnormally返回true, 如果一个任务被取消或者抛出异常了. ForkJoinTask类通常不直接被继承，而是 ForkJoinTask类通常不会直接子类化。子类化一个支持特殊的fork/join处理风格的抽象类， 通常情况下，对于大多数不返回结果的计算，我们使用RecursiveAction; 对于返回结果的计算，我们使用RecursiveTask; 对于完成的操作触发其他操作的计算，我们使用CountedCompleter。 通常，具体的ForkJoinTask子类声明包含其参数的字段，在构造函数中建立，然后定义一个计算方法，该方法以某种方式使用该基类提供的控制方法。 join方法和他的变体只适合在没有循环以来的情况下使用. 也就是说，并行计算可以使用有向无环图(DAG)来描述. 否则，循环依赖的任务之间互相等待，可能造成死锁. 然后，这个框架支持一些其他的方法和技术(Phasers,helpQuiesce,complete), 可以为那些不是dag的问题构造子类. 大多数的基础方法都是final,以防止覆盖本质上与底层轻量级任务调度框架相关联的实现. 创建新的fork/join风格的开发人员应该最低限度的实现protected方法. exec,setRawResutl,getRawResult等. 同时还引入一个可以在其子类中实现的抽象计算方法，可能依赖于该类提供的其他受保护的方法。 ForkJoinTasks应该执行相对较少的计算量。通常通过递归分解将大任务分解为更小的子任务。 一个非常粗略的经验法则是，一个任务应该执行超过100个和少于10000个基本计算步骤，并且应该避免无限循环。 如果任务太大，并行性就不能提高吞吐量。如果太小，那么内存和内部任务维护开销可能会压倒处理。 这个类为Runnable和Callable提供了适配的方法， 当混合执行ForkJoinTasks和其他类型的任务时，这些方法可能会很有用。当所有任务都是这种形式时，考虑使用asyncMode构造池。 ForkJoinTasks是可序列化的，这使得它们可以用于远程执行框架等扩展。 合理的做法是只在执行之前或之后序列化任务，而不是在执行期间。在执行过程中并不依赖于序列化。 源码 类结构图: 在模块结构中提过, ForkJoinTask负责任务的实际运行. 同时, 它实现了分治算法. 任务运行 doExec final int doExec() { int s; boolean completed; // 当前任务状态正常 if ((s = status) >= 0) { try { // 调用抽象方法,进行任务的实际执行过程. completed = exec(); } catch (Throwable rex) { completed = false; // 遇到异常了 s = setExceptionalCompletion(rex); } if (completed) // 任务完成 s = setDone(); } return s; } 由于当前类,只是所有fork/join类型任务的基类,因此运行部分比较简单,判断任务状态正常后,调用exec()方法,进行计算逻辑的真正执行. 之后处理异常以及任务正常结束的情况即可. exec()方法是预留给子类的接口, 方便子类嵌入具体的逻辑代码. 分治 分治有两步,第一步,fork,也就是切分任务执行. 第二部,join,从子任务收集结果. fork public final ForkJoinTask fork() { Thread t; // 如果是工作线程的子任务切分,直接调用之前的`workQueue.push`将任务添加到当前线程的任务队列中去 if ((t = Thread.currentThread()) instanceof ForkJoinWorkerThread) ((ForkJoinWorkerThread)t).workQueue.push(this); else // 如果是外部服务,直接调用fork,则调用之前的`externalPush`进行一个任务的提交 ForkJoinPool.common.externalPush(this); return this; } join public final V join() { int s; // 调用doJoin如果出错,报告异常. if (((s = doJoin()) & ABNORMAL) != 0) reportException(s); // 拿到结果 return getRawResult(); } 其中getRawResult也是留给子类实现,返回当前任务的结果. 子类实现 按照官方的设计, 我们很少会直接继承ForkJoinTask,而是继承它的几个给定的子类,去实现自己的逻辑. 官方介绍中,子类有三个. RecursiveAction 一个递归的,没有返回结果的ForkJoinTask实现,定义了没有返回结果的行为,,应该返回一个Void. 代码: public abstract class RecursiveAction extends ForkJoinTask { private static final long serialVersionUID = 5232453952276485070L; /** * The main computation performed by this task. */ protected abstract void compute(); /** * Always returns {@code null}. * * @return {@code null} always */ // 返回值永远是空 public final Void getRawResult() { return null; } /** * Requires null completion value. */ protected final void setRawResult(Void mustBeNull) { } /** * Implements execution conventions for RecursiveActions. */ protected final boolean exec() { compute(); return true; } } 和上面的描述差不多,没有定义任何计算逻辑,但是定义了返回值是Void.且永远返回null. 这个类通常用来包装Runnable,因此Runnable真的没有返回值. 简单使用案例: 一个简单的,ForkJoin模式的排序. static class SortTask extends RecursiveAction { final long[] array; final int lo, hi; SortTask(long[] array, int lo, int hi) { this.array = array; this.lo = lo; this.hi = hi; } SortTask(long[] array) { this(array, 0, array.length); } // 实现计算接口 protected void compute() { // 排序范围不大,就排序 if (hi - lo >> 1; invokeAll(new SortTask(array, lo, mid), new SortTask(array, mid, hi)); merge(lo, mid, hi); } } // implementation details follow: static final int THRESHOLD = 1000; void sortSequentially(int lo, int hi) { Arrays.sort(array, lo, hi); } // 合并结果集 void merge(int lo, int mid, int hi) { long[] buf = Arrays.copyOfRange(array, lo, mid); for (int i = 0, j = lo, k = mid; i 这是一个将ForkJoin思路应用于排序的典型案例. 如果数据量很小,就直接排序 如果数据量较大,就分成两部分,各自提交任务排序 合并两个子部分的排序结果 一个更加简单的案例: 对数组中的每个元素递增1,也可以分治思想来做. class IncrementTask extends RecursiveAction { final long[] array; final int lo, hi; IncrementTask(long[] array, int lo, int hi) { this.array = array; this.lo = lo; this.hi = hi; } protected void compute() { if (hi - lo >> 1; invokeAll(new IncrementTask(array, lo, mid), new IncrementTask(array, mid, hi)); } } } 如果数组元素很少,就遍历递增. 如果数组元素较多,就切分成两部分,进行计算 不用收集结果了,因为是原址的递增 第三个小🌰: 对一个整数序列进行累加平方和. double sumOfSquares(ForkJoinPool pool, double[] array) { int n = array.length; Applyer a = new Applyer(array, 0, n, null); pool.invoke(a); return a.result; } class Applyer extends RecursiveAction { final double[] array; final int lo, hi; double result; Applyer next; // keeps track of right-hand-side tasks // 初始化 Applyer(double[] array, int lo, int hi, Applyer next) { this.array = array; this.lo = lo; this.hi = hi; this.next = next; } // 叶子节点 // 叶子节点不再继续分治,而是真的执行对应的计算 double atLeaf(int l, int h) { double sum = 0; for (int i = l; i 1 && getSurplusQueuedTaskCount() >> 1; right = new Applyer(array, mid, h, right); right.fork(); h = mid; } double sum = atLeaf(l, h); while (right != null) { // 如果右边的节点没有被偷, 继续计算 if (right.tryUnfork()) // directly calculate if not stolen sum += right.atLeaf(right.lo, right.hi); else { right.join(); sum += right.result; } right = right.next; } result = sum; } } 这里使用的不是一分为2的分治思想,而是不断向右分治. 如果数组元素太多,且动态临界值符合条件,就不断的提交右边的任务 计算当前叶子节点 如果右边的任务没有被偷,也就是没有被别的工作线程执行,那么当前线程继续执行. 收集结果比较简单,累加即可. 通过特殊的分治方式,能够获得更好的性能. RecursiveTask 一个递归的, 有结果返回的ForkJoinTask.主要用于封装Callable. 代码: public abstract class RecursiveTask extends ForkJoinTask { private static final long serialVersionUID = 5232453952276485270L; /** * The result of the computation. */ V result; /** * The main computation performed by this task. * @return the result of the computation */ protected abstract V compute(); // 返回结果 public final V getRawResult() { return result; } // 设置结果 protected final void setRawResult(V value) { result = value; } /** * Implements execution conventions for RecursiveTask. */ protected final boolean exec() { result = compute(); return true; } } 由于支持返回值,因此是一个泛型类, 有个泛型参数V. 提供了设置结果和获取结果的方法. 示例: 计算斐波那契 class Fibonacci extends RecursiveTask { final int n; Fibonacci(int n) { this.n = n; } protected Integer compute() { // 小于1,返回 if (n 经典的斐波那契问题,采用递归算法,如果nn-1和n-2. 然后调用join方法获取子任务的返回值. 需要注意,和RecursiveAction的不同, 在RecursiveAction的第三个示例中,虽然也有获取子任务的结果的操作,但是都是通过局部变量, 或者共享的数组来获取结果的,而不是像RecursiveTask,通过调用join来拿到子任务返回的值. CountedCompleter CountedCompleter 在任务完成执行后会触发执行一个自定义的钩子函数. 这个类执行子任务更加的厉害但是有点反直觉.pending个任务必须完成,以用来触发完成的钩子行为(onCompletion)定义. pending count初始化为0,但是可以动态的修改,在tryComplete之前,如果代办的数量不为0, 将递减. 否则才执行完成的钩子行为. 代办的任务可以根据需要,由子类创建. CountedCompleter必须实现compute方法,并且在返回之前调用一次tryComplete.这个类还可以重写onCompletion, 来重写一个新的完成行为, onExceptionalCompletion, 可以重写一个新的异常完成行为. 一般情况下,CountedCompleter应该使用不需要返回值的版本, 他被定义为返回Void,然后一直返回null.如果需要返回值,需要自己去重写getRawResult. 代码: 代码比较长,这里就不贴了,如上面所述,对于 compute onCompletion 两个方法,没有做出实现,需要子类去具体的进行实现. 默认的 getRawResult 方法,返回的永远都是null. 如果需要有返回值的版本, 需要自己去定义且实现. 示例: public static void forEach(E[] array, Consumer action) { class Task extends CountedCompleter { final int lo, hi; Task(Task parent, int lo, int hi) { super(parent); this.lo = lo; this.hi = hi; } public void compute() { if (hi - lo >= 2) { int mid = (lo + hi) >>> 1; // must set pending count before fork // 分解任务后, 需要先设置需要等待的子任务的数量 setPendingCount(2); // 然后调用子任务的fork new Task(this, mid, hi).fork(); // right child new Task(this, lo, mid).fork(); // left child } else if (hi > lo) // 执行操作 action.accept(array[lo]); // 尝试完成整个任务. tryComplete(); } } new Task(null, 0, array.length).invoke(); } ForkJoinWorkerThread 负责执行ForkJoinTask A thread managed by a ForkJoinPool, which executes ForkJoinTasks. 继承自Thread. 在ForkJoinPool中运行,执行ForkJoinTask. 源码 属性 final ForkJoinPool pool; // the pool this thread works in final ForkJoinPool.WorkQueue workQueue; // work-stealing mechanics 构造函数 protected ForkJoinWorkerThread(ForkJoinPool pool) { // Use a placeholder until a useful name can be set in registerWorker super(\"aForkJoinWorkerThread\"); this.pool = pool; this.workQueue = pool.registerWorker(this); } ForkJoinWorkerThread(ForkJoinPool pool, ClassLoader ccl) { super(\"aForkJoinWorkerThread\"); super.setContextClassLoader(ccl); ThreadLocalRandom.setInheritedAccessControlContext(this, INNOCUOUS_ACC); this.pool = pool; this.workQueue = pool.registerWorker(this); } ForkJoinWorkerThread(ForkJoinPool pool, ClassLoader ccl, ThreadGroup threadGroup, AccessControlContext acc) { super(threadGroup, null, \"aForkJoinWorkerThread\"); super.setContextClassLoader(ccl); ThreadLocalRandom.setInheritedAccessControlContext(this, acc); ThreadLocalRandom.eraseThreadLocals(this); // clear before registering this.pool = pool; this.workQueue = pool.registerWorker(this); } 除了进行权限等赋值之外: 记录当前线程在哪个线程池中工作. 向线程池中注册当前线程.拿到当前线程对应的工作队列. 注册的方法调用的是ForkJoinPool.registerWorker. final WorkQueue registerWorker(ForkJoinWorkerThread wt) { UncaughtExceptionHandler handler; wt.setDaemon(true); // configure thread if ((handler = ueh) != null) wt.setUncaughtExceptionHandler(handler); int tid = 0; // for thread name int idbits = mode & FIFO; String prefix = workerNamePrefix; // 以当前线程创建一个工作队列, WorkQueue w = new WorkQueue(this, wt); if (prefix != null) { synchronized (prefix) { WorkQueue[] ws = workQueues; int n; int s = indexSeed += SEED_INCREMENT; idbits |= (s & ~(SMASK | FIFO | DORMANT)); if (ws != null && (n = ws.length) > 1) { int m = n - 1; tid = m & ((s >> 1;;) { // find empty slot WorkQueue q; if ((q = ws[tid]) == null || q.phase == QUIET) break; else if (--probes == 0) { tid = n | 1; // resize below break; } else tid = (tid + 2) & m; } w.phase = w.id = tid | idbits; // now publishable if (tid = n) break; as[j] = ws[j]; // copy worker } workQueues = as; } } } wt.setName(prefix.concat(Integer.toString(tid))); } return w; } 以当前线程,创建一个工作队列. 在线程池原有的工作队列数组中,找一个空位放下当前的工作队列. 如果没地方,就扩容一下原有的数组,复制老的所有工作队列过来,并且放入当前的工作队列. run 线程运行 既然是一个线程的子类,那么启动也是调用run方法. public void run() { // 线程启动时,当前线程需要执行的任务必须为空. if (workQueue.array == null) { // only run once Throwable exception = null; try { // 调用启动前的hook onStart(); // 启动当前工作线程 pool.runWorker(workQueue); } catch (Throwable ex) { exception = ex; } finally { try { // 调用终止时的hook. onTermination(exception); } catch (Throwable ex) { if (exception == null) exception = ex; } finally { // 注销当前工作线程 pool.deregisterWorker(this, exception); } } } } 当工作线程被启动: 调用相关hook. 调用ForkJoinPool.runWorker,启动当前工作队列.开始干活. 结束前向线程注销自己这个工作队列. 一个工作线程,封装成一个工作队列,带有自己的任务列表,启动! ForkJoinPool.runWorker 工作线程启动 final void runWorker(WorkQueue w) { int r = (w.id ^ ThreadLocalRandom.nextSecondarySeed()) | FIFO; // rng // 初始化任务数组 w.array = new ForkJoinTask[INITIAL_QUEUE_CAPACITY]; // initialize for (;;) { int phase; // 扫描到任务了. if (scan(w, r)) { // scan until apparently empty r ^= r >> 17; r ^= r = 0) { // enqueue, then rescan long np = (w.phase = (phase + SS_SEQ) | UNSIGNALLED) & SP_MASK; long c, nc; do { w.stackPred = (int)(c = ctl); nc = ((c - RC_UNIT) & UC_MASK) | np; } while (!CTL.weakCompareAndSet(this, c, nc)); } else { // already queued // 没任务了,休眠一阵时间 int pred = w.stackPred; Thread.interrupted(); // clear before park w.source = DORMANT; // enable signal long c = ctl; int md = mode, rc = (md & SMASK) + (int)(c >> RC_SHIFT); if (md 一个工作线程启动后,首先进行自旋: 扫描任务, 没有任务,重新扫描 还是没有,就休眠一段时间.等待唤醒. scan 扫描任务 private boolean scan(WorkQueue w, int r) { WorkQueue[] ws; int n; // 检查参数, 当前线程池必须有工作队列的数组,且要扫描的当前工作队列不为空 if ((ws = workQueues) != null && (n = ws.length) > 0 && w != null) { for (int m = n - 1, j = r & m;;) { WorkQueue q; int b; if ((q = ws[j]) != null && q.top != (b = q.base)) { int qid = q.id; ForkJoinTask[] a; int cap, k; ForkJoinTask t; if ((a = q.array) != null && (cap = a.length) > 0) { t = (ForkJoinTask)QA.getAcquire(a, k = (cap - 1) & b); if (q.base == b++ && t != null && QA.compareAndSet(a, k, t, null)) { q.base = b; w.source = qid; // 如果任务比较多,唤醒其他工作线程 if (a[(cap - 1) & b] != null) signalWork(q); // help signal if more tasks // 当前工作线程干活 w.topLevelExec(t, q, // random fairness bound (r | (1 0) j = (j + 1) & m; else break; } } return false; } 扫描任务时,如果发现任务过多,就协助唤醒一些工作线程.然后让当前工作线程开始干活. signalWork 唤醒其他工作线程 final void signalWork(WorkQueue q) { for (;;) { long c; int sp; WorkQueue[] ws; int i; WorkQueue v; // 有足够多的工作线程,说明不需要唤醒了，退出 if ((c = ctl) >= 0L) // enough workers break; // 没有空闲线程 else if ((sp = (int)c) == 0) { // no idle workers // 线程数很少，添加一个线程 if ((c & ADD_WORKER) != 0L) // too few workers tryAddWorker(c); break; } // 线程池终止了,退出 else if ((ws = workQueues) == null) break; // unstarted/terminated else if (ws.length 进行一些参数的判断: 如果当前工作线程够用,退出. 如果当前没有空闲的线程,新创建一个工作线程. 其他情况找一个工作线程,唤醒他.让他干活. tryAddWorker // 尝试添加一个工作线程 private void tryAddWorker(long c) { do { long nc = ((RC_MASK & (c + RC_UNIT)) | (TC_MASK & (c + TC_UNIT))); if (ctl == c && CTL.compareAndSet(this, c, nc)) { // 创建线程 createWorker(); break; } } while (((c = ctl) & ADD_WORKER) != 0L && (int)c == 0); } // 创建工作线程 private boolean createWorker() { ForkJoinWorkerThreadFactory fac = factory; Throwable ex = null; ForkJoinWorkerThread wt = null; try { // 创建一个线程并运行 if (fac != null && (wt = fac.newThread(this)) != null) { // 默认的实现是下方的Thread. wt.start(); return true; } } catch (Throwable rex) { ex = rex; } // 注销一个工作线程 deregisterWorker(wt, ex); return false; } topLevelExec 顶层的执行任务 final void topLevelExec(ForkJoinTask t, WorkQueue q, int n) { int nstolen = 1; for (int j = 0;;) { // 调用`doExec`执行一个`ForkJoinTask`. if (t != null) t.doExec(); if (j++ 总结工作线程的一生 懒得画流程图,打字吧. 提交新任务时,会创建一个工作线程. 然后启动. 启动后扫描任务,扫描到任务就自己执行.扫描不到就自己休眠等待唤醒. 扫描过程中,如果发现任务太多,就唤醒2中处于休眠状态的其他工作线程一起干活. 唤醒过程中,发现没有空闲的线程,都很累,活还干不完,就新建一个线程,这个新的线程也从1开始执行. 总结 ForkJoin框架的代码,是目前我看jdk代码看的最懵的一次,十分复杂. 本文主要从基本原理上阅读了相关代码, 对于其中ctl的属性按位编码,没有过于深究,需要了解的朋友们可以自行阅读及调试. 注意事项 ForkJoin框架,提供了对线程池调度任务,更好的灵活性,更高的并行性及性能,但是也不是无敌的. 使用时尤其需要注意以下几点: 避免不必要的fork fork是提交进入队列操作,如果一个任务会分割成两个任务,那么两个任务都fork,是有一次进队出队的浪费的. 应该 task -> task1 + task2 task1.fork(); task2.compute(); 合理的任务粒度 这个和普通线程池一样, 任务过大,无法充分发挥并行性,任务过小,调度浪费的算力都赶上使用线程池增大的算力了. 实践出真知,代码开发的灵活一些,设置参数调试最优解吧~ fork与join的顺序 在同一个工作线程中, 将大任务分割成两个子任务,分别提交,等待返回.和普通的多线程开发很相似,这时就要注意任务的提交和等待顺序,否则可能白忙活一场.比如: task -> task1 + task2 task1.fork(); task1.join(); task2.fork(); task2.join(); 这样的代码,本质上接近于串行执行了,性能肯定好不了. 避免重量级的任务划分和结果合并操作 从上面的例子可见,对于ForkJoinPool的使用,很多时候都是在处理集合List/Array中的数据等, 那么在划分任务和收集结果时,避免设计出大量的拷贝,二次计算操作. 从而尽量避免调度任务的开销,将算力花在真正的\"计算逻辑\"上. 参考文章 源码作者的《A Java Fork/Join Framework》 Java全栈知识体系的一篇文章 给我很多启发,尤其是最后的注意事项部分. 完。 联系我 最后，欢迎关注我的个人公众号【 呼延十 】，会不定期更新很多后端工程师的学习笔记。 也欢迎直接公众号私信或者邮箱联系我，一定知无不言，言无不尽。 以上皆为个人所思所得，如有错误欢迎评论区指正。 欢迎转载，烦请署名并保留原文链接。 联系邮箱：huyanshi2580@gmail.com 更多学习笔记见个人博客或关注微信公众号 ------>呼延十 版权所有，盗版必究 all right reserved，powered by GitbookLast Modified On： 2021-10-17 02:51:51 "},"java/juc/2019-05-05-(juc系列)Java中的-ThreadPoolExecutor类.html":{"url":"java/juc/2019-05-05-(juc系列)Java中的-ThreadPoolExecutor类.html","title":"Java中的-ThreadPoolExecutor类","keywords":"","body":"前言 在之前的文章Java中executors提供的的4种线程池中,学习了一下Executors类中提供的四种线程池. 在该文中提到,这四种线程池只是四个静态工厂方法而已,本质上其实是调用的ThreadPoolExecutor类的构造方法,并且对其中的一些参数进行了了解.比如corePoolSize,maximumPoolSize等等. 但是对其中剩余的两个参数,queen阻塞队列,handler拒绝策略等没有了解的十分透彻.因此今天来补充一下. 本文主要对以上两个参数的作用以及实现方法,使用方法来学习一下,中间可能夹杂部分ThreadPoolExecutor的源码学习. 阻塞队列 对阻塞队列完全不了解的同学可以查看一下这篇文章,Java中对阻塞队列的实现. 这里不会在对阻塞队列的原理做过多的探讨,主要聚焦于在线程池中阻塞队列的作用. 我前一阵面试的时候,对线程池这一块仅限于使用,一知半解(现在也是呢哈哈哈),在一次面试中问到了线程池中阻塞队列的作用,以及在什么情景下任务会被放入阻塞队列,而我一脸懵逼,今天也回答一下这个问题. 要想知道怎么放入,我们直接从execute方法来看,因为一般情况下我们都是通过这个方法来提交任务的,它的代码如下: /** * Executes the given task sometime in the future. The task * may execute in a new thread or in an existing pooled thread. * * If the task cannot be submitted for execution, either because this * executor has been shutdown or because its capacity has been reached, * the task is handled by the current {@code RejectedExecutionHandler}. * * @param command the task to execute * @throws RejectedExecutionException at discretion of * {@code RejectedExecutionHandler}, if the task * cannot be accepted for execution * @throws NullPointerException if {@code command} is null */ public void execute(Runnable command) { if (command == null) throw new NullPointerException(); /* * Proceed in 3 steps: * * 1. If fewer than corePoolSize threads are running, try to * start a new thread with the given command as its first * task. The call to addWorker atomically checks runState and * workerCount, and so prevents false alarms that would add * threads when it shouldn't, by returning false. * * 2. If a task can be successfully queued, then we still need * to double-check whether we should have added a thread * (because existing ones died since last checking) or that * the pool shut down since entry into this method. So we * recheck state and if necessary roll back the enqueuing if * stopped, or start a new thread if there are none. * * 3. If we cannot queue task, then we try to add a new * thread. If it fails, we know we are shut down or saturated * and so reject the task. */ int c = ctl.get(); if (workerCountOf(c) 我一般copy源代码都是删除注释的,因为实在太长了...但是这个的源代码我觉得十分的棒,简洁并且极其清晰.可以看一下. 方法上的注释: 将在未来的某个时间执行给定的任务,任务可能会在一个新的线程或者一个旧的线程里执行. 如果任务不可以被执行,可能是因为线程池关闭了或者容量满了,任务将会被RejectedExecutionHandler处理. 看起来是不是没有什么用?其实在大的逻辑上说的很清晰了,接下来是代码中的这一段注释. 分为三步:1.如果当前运行的线程数量小于核心池的数量,试着以给定的任务作为第一个任务去创建一个新的线程.这个添加worker的请求会原子性的检查线程的运行状态以及工作线程的数量,如果添加失败,会返回false. 2.如果这个任务可以被成功的放入队列,我们将在添加一个线程前进行double-check双重检查,因为可能在此期间有一个线程挂掉了或者线程池挂掉了.所以我们再次检查状态,如果必要的话回滚对象,或者新建一个线程. 3.如果我们不能讲任务放进队列,我们将新增一个线程,如果这也失败了,我们知道我们挂掉了或者说线程池的容量满了,然后我们拒绝这个任务. 这就是对上面那个问题的回答.也就是阻塞队列在线程池中的使用方法. 那么使用哪种阻塞队列呢?Java有很多的阻塞队列的实现的. 在Executors的四种静态工厂中,使用的阻塞队列实现有两种,LinkedBlockingQueue和SynchronousQueue. LinkedBlockingQueue: 这个阻塞队列在前一篇文章中讲过了,主要强调一点,他可以是一个无界的阻塞队列,可以放下大量的任务. SynchronousQueue: 这个阻塞队列内部没有容器,不会持有任务,而是将每一个生产者阻塞,知道等到与他配对的消费者. 从上面阻塞队列的使用方法中可以看出来,maximumPoolSize和阻塞队列的长度这两个值会互相影响,当阻塞队列很大时,相应的maximumPoolSize可以小一点,对CPU的压力也就会相应的小一点.而当阻塞队列很小的时候,会频繁的出现放入队列失败,然后尝试新建线程,这时会出现两种可能,线程数暴增或者大量的拒绝任务,都不是很好的选择, 因此在决定使用哪种阻塞队列的时候,需要对吞吐量和CPU的压力之间做一个权衡. 拒绝策略 当你的阻塞队列以及线程池容量全部爆掉之后,再次提交任务就会被拒绝,拒绝的策略由构造参数中的handler来提供. 这是ThreadPoolExecutor中默认使用的拒绝策略AbortPolicy: /** * A handler for rejected tasks that throws a * {@code RejectedExecutionException}. */ public static class AbortPolicy implements RejectedExecutionHandler { /** * Creates an {@code AbortPolicy}. */ public AbortPolicy() { } /** * Always throws RejectedExecutionException. * * @param r the runnable task requested to be executed * @param e the executor attempting to execute this task * @throws RejectedExecutionException always */ public void rejectedExecution(Runnable r, ThreadPoolExecutor e) { throw new RejectedExecutionException(\"Task \" + r.toString() + \" rejected from \" + e.toString()); } } 可以看到这个策略比较粗暴,直接抛出了异常. JDK中还有一些其他的拒绝策略,如下: ThreadPoolExecutor#AbortPolicy：这个策略直接抛出 RejectedExecutionException 异常。 ThreadPoolExecutor#CallerRunsPolicy：这个策略将会使用 Caller 线程来执行这个任务，这是一种 feedback 策略，可以降低任务提交的速度。 ThreadPoolExecutor#DiscardPolicy：这个策略将会直接丢弃任务。 ThreadPoolExecutor#DiscardOldestPolicy：这个策略将会把任务队列头部的任务丢弃，然后重新尝试执行，如果还是失败则继续实施策略。 那么我们能不能自己实现一种策略呢,当然可以,还很简单. 我们实现一种策略,当被拒绝时候,打印一句日志然后给我们发一个邮件好了(不值当鸭). ThreadPoolExecutor ex = new ThreadPoolExecutor(10, 100, 100L, TimeUnit.SECONDS, new LinkedBlockingQueue<>(10), new MyRejectPolicy()); private static class MyRejectPolicy implements RejectedExecutionHandler { @Override public void rejectedExecution(Runnable r, ThreadPoolExecutor executor) { System.out.println(\"reject me,555\"); // send email ... } } 我们新建了一个线程池,核心池大小为10,最大大小为100,存活时间为100s,使用容量为10的LinkedBlockingQueue为工作队列,拒绝策略使用我们自己实现的一个策略,类定义如上所示. 只需要实现RejectedExecutionHandler接口并且实现他的唯一方法即可. 额外的小技巧 在看源代码的过程中,我发现了一个属性,private volatile boolean allowCoreThreadTimeOut; 这个属性可以控制核心池中的线程会不会因为空闲时间过程而死亡,虽然听起来没什么用,因为我们可以通过减小核心池的大小来达到差不多的目的,但是总是有区别的,记录一下,说不定就遇到合适使用的场景了呢. 钩子Hook 在git中,hook十分有用,可以让我们进行很多事情,比如自动化部署,发邮件等等.那么在线程池中怎么能没有呢? ThreadPoolExecutor提供了三个Hook来让我们执行一些定制化的东西,可以通过继承此类然后重写钩子来实现,三个Hook分别是: protected void beforeExecute(Thread t, Runnable r) { } protected void afterExecute(Runnable r, Throwable t) { } protected void terminated() { } 他们分别在任务执行前,执行后,以及线程池终止的时候被调用.让我们来测试一下. 我们的类如下: private static class MyExecutor extends ThreadPoolExecutor{ public MyExecutor(int corePoolSize, int maximumPoolSize, long keepAliveTime, TimeUnit unit, BlockingQueue workQueue, RejectedExecutionHandler handler) { super(corePoolSize, maximumPoolSize, keepAliveTime, unit, workQueue, handler); } @Override protected void beforeExecute(Thread t, Runnable r) { System.out.println(\"before\"); } @Override protected void afterExecute(Runnable r, Throwable t) { System.out.println(\"after\"); } @Override protected void terminated() { System.out.println(\"executor terminate\"); } } 测试代码: public static void main(String[] args) { ThreadPoolExecutor ex = new MyExecutor(10, 100, 100L, TimeUnit.SECONDS, new LinkedBlockingQueue<>(10), new MyRejectPolicy()); ex.execute(()->{ for (int i = 0; i { for (int i = 0; i 打印输出如下: before i:0 i:1 i:2 i:3 i:4 i:5 before i:6 i:7 i:8 i:9 j:0 j:1 j:2 j:3 j:4 j:5 j:6 j:7 after j:8 j:9 after executor terminate 可以看到我们对钩子的实现,完全的被执行了,所以我们可以用它做很多东西,比如记录日志,比如发推送消息,比如更加高级一点在执行之前设置ThreadLocal等等.具体操作就看我们的想象力了! 但是请注意一点,钩子中的内容如果执行错误,会影响任务本身的执行结果,要尽力保证钩子的正确性,不要顾此失彼. 完. 参考文章 https://mp.weixin.qq.com/s/Epi-cBVFkeZWgvKvOMQZqw ChangeLog 2019-05-05 完成 以上皆为个人所思所得，如有错误欢迎评论区指正。 欢迎转载，烦请署名并保留原文链接。 联系邮箱：huyanshi2580@gmail.com 更多学习笔记见个人博客------>呼延十 版权所有，盗版必究 all right reserved，powered by GitbookLast Modified On： 2021-10-17 17:42:26 "},"java/juc/2021-10-12-(juc系列)ThreadPoolExecutor源码学习.html":{"url":"java/juc/2021-10-12-(juc系列)ThreadPoolExecutor源码学习.html","title":"(juc系列)ThreadPoolExecutor源码学习","keywords":"","body":"前言 其实早在19年，就简单的写过ThreadPoolExecutor. 但是只涉及到了其中两个参数，理解也不深刻，今天重新看一下代码。 简介 这个类是Java中常用的线程池的一个类，相关的类图： 继承自父类: AbstractExecutorService,实现了Executor和ExecutorService接口. 使用一些池化的线程来执行每一个提交的任务,一般使用Executors的工厂方法来进行相关的配置. 线程池解决两个不同的问题：由于减少了每个任务的调用开销，它们通常在执行大量异步任务时提供更好的性能， 并且它们提供了一种限制和管理资源的方法，包括在执行集合时消耗的线程任务。 每个 ThreadPoolExecutor 还维护一些基本的统计信息，例如已完成的任务数。 为了在更加广泛的上下文中可用，这个类提供了许多可以调整的参数和可以扩展的挂钩. 但是强烈建议程序员使用Executors的工厂方法来进行这个类的创建. 如果你要手动创建和配置的话，以下是一些使用指南: 核心线程数和最大线程数 线程池自动调整池子的大小，调整范围在corePoolSize和maximumPoolSize之间. 如果正在运行的线程少于核心线程数, 处理请求时将创建一个新的线程.即使当前有一些线程是空闲的. 如果当前运行的线程数少于最大线程数.只有当工作队列满了的时候，才会创建新的线程. 设置核心线程数等于最大线程数，就创建了一个固定大小的线程池. 设置一个无限大的最大线程数，就允许线程池拥有任意数量的线程. 通常，核心线程数和最大线程数只在调用构造方法时设置，但是也可以被对应的set方法修改. 按需构建 默认情况下，　核心线程也是在有新的任务到来时才会初始化. 但是这一点可以被动态的重写，使用prestartCoreThread和prestartAllCoreThreads. 如果你创建线程时已经有一个不为空的队列，你可能想要预启动线程. 创建新线程 使用ThreadFactory创建新线程. 默认使用Executors.defaultThreadFactory. 他创建的线程全在同一个ThreadGroup中. 有用相同的优先级，且不是守护线程. 使用其他的线程工厂，你可以修改线程的名字，线程组，优先级，是否是守护线程等等. 如果线程工厂在创建新线程时出错，调用newThread时返回null.执行器会继续，但是可能没有办法执行任务了. 线程应该有用\"修改线程\"的运行时权限. 如果工作线程或者其他线程没有取得这个权限，服务将退化.配置的更改可能不起效，一个终止的线程池可能还处在未完成状态中. 活跃时间 如果一个线程池有超过核心线程数的线程数量，超过核心线程数的线程将在空闲超过keepAliveTime时间后被终止. 当线程池没有完全应用起来时，这提供了一个减少资源消耗的方法.如果之后线程池变得更加活跃，将新创建线程. 这个参数也可以动态的更改. 使用Long.Max_Value意味着空闲线程永远不会终止. 默认实现中，保持活跃策略只有在线程数大于核心线程时被应用. 但是allowCoreThreadTimeOut可以将这个策略也应用在核心线程上. 排队 线程池应用一个BlockingQueue来持有提交的任务，这个队列的使用和线程池的大小有关系： 如果运行的线程小于核心线程数，优先新建线程而不是入队等待. 如果运行线程数大于等于核心线程数，新来的任务优先入队等待而不是新创建线程. 如果一个任务不能入队，将会新创建一个线程。如果线程数已经到达最大线程数，这个任务将会被拒绝. 常见的排队策略有三个: 直接交接 工作队列的一个默认实现是SynchronousQueue,他将任务直接交给线程，而不是使用其他方式来保留任务。 这种实现下，如果当前没有一个线程是立刻可用的，那么入队一个任务将会失败. 因此会创建一个新的线程. 这个策略避免了处理一系列内部依赖的任务时造成的锁定. 直接交接通常要求吴杰的最大线程数，以避免拒绝新任务. 当任务的到达速度，大于处理速度时，线程池将会无限增长. 无界队列 使用一个无界队列(没有给定容量的LinkedBlockingQueue)将会使新任务在队列中等待，如果所有的核心线程都在忙碌时. 因此，不会有超过核心线程数的线程被创建. (最大线程数这个参数就没有作用了.) 当任务之间完全互相独立时，这可能是有用的，因为任务不会影响彼此的执行. 比如在web网页服务中. 这个风格的排队策略，在处理平滑的请求速度中的尖刺时很有用，但是当任务的到达速度大于处理速度时，工作队列将会无线增长. 有界队列 有界队列防止资源耗尽，但是会更加难以控制. 队列的大小和最大线程数可能会不断影响彼此. 使用大的等待队列和比较小的线程池意味着较小的cpu使用率，系统资源以及上下文切换的浪费， 但是吞吐量会较低. 如果任务频繁的阻塞，系统可能可以调度时间到更多线程，远超过你搜允许的。 使用较小的队列通常要求更大的线程池，会导致CPU繁忙但是可能会遇到不可调度开销，这也会降低吞吐量. 拒绝任务 如果当前线程池已经终止了，或者所有的可用线程和工作队列都满了，新提交的任务将会被拒绝. 在这些情况下，执行方法将会调用RejectedExecutionHandler.rejectedExecution. 提供了４种预定义的处理策略: AbortPolicy 默认实现，拒绝时直接抛出异常 CallerRunsPolicy 拒绝时让调用方的线程执行这个任务，这是一个反馈型的控制策略，可以让提交任务的速度慢下来 DiscardPolicy　不能执行的任务直接丢弃掉. DiscardOldestPolicy 拒绝时，丢弃掉最老的任务，也就是等待队列的第一个节点. 还可以实现其他的拒绝策略，也可以自己实现 挂钩方法 这个类提供了beforeExecute和afterExecute方法，　在每个任务被执行之前和之后进行调用. 这些方法用来操作执行环境. 比如, 初始化ThreadLocal的值, 搜集一些统计信息，或者添加统计信息. terminated方法可以被重写，以在线程池完全终止后，执行一些特殊的操作. 如果挂钩，回调，等待队列等抛出异常，内部的工作线程可能会失败，终止，或者被替换. 队列维护 getQueue允许访问工作队列，以用来监控或者进行调试.如果用于其他目的的话，很不好. 当大量排队任务被取消时，remove和purge两个方法可以用来协助回收存储. 回收 程序中不再引用并且没有剩余线程的线程池可以在不显示关闭的情况下，被垃圾回收收集。 您可以通过设置合适的存活时间，使用一个较少的核心线程数，或者允许allowCoreThreadTimeOut来允许所有未使用的线程死亡. 扩展示例 这个类的大部分扩展类都重写了一个或者多个hook. 比如下面这个子类添加了一个简单的暂停，继续功能: class PausableThreadPoolExecutor extends ThreadPoolExecutor { // 暂停 private boolean isPaused; private ReentrantLock pauseLock = new ReentrantLock(); private Condition unpaused = pauseLock.newCondition(); public PausableThreadPoolExecutor(...) { super(...); } protected void beforeExecute(Thread t, Runnable r) { super.beforeExecute(t, r); pauseLock.lock(); try { while (isPaused) unpaused.await(); } catch (InterruptedException ie) { t.interrupt(); } finally { pauseLock.unlock(); } } public void pause() { pauseLock.lock(); try { isPaused = true; } finally { pauseLock.unlock(); } } public void resume() { pauseLock.lock(); try { isPaused = false; unpaused.signalAll(); } finally { pauseLock.unlock(); } } } 在执行每一个任务之前，检查当前线程池是否被暂停了，如果是，自旋，等待外部唤醒. 源码阅读 常量 // 线程数的bit为. private static final int COUNT_BITS = Integer.SIZE - 3; // 线程树的掩码 private static final int COUNT_MASK = (1 由于内部使用一个int来存储当前活跃的线程数和线程池的状态，因为需要一些bit位以及状态的定义，都在常量里面了. 变量 // 状态及当前线程数 private final AtomicInteger ctl = new AtomicInteger(ctlOf(RUNNING, 0)); // 工作队列 private final BlockingQueue workQueue; // 内部锁 private final ReentrantLock mainLock = new ReentrantLock(); // 工作线程 private final HashSet workers = new HashSet<>(); // 等待条件 private final Condition termination = mainLock.newCondition(); // 到达过的最大线程数, 是一个实际的数量 private int largestPoolSize; // 已完成任务数量 private long completedTaskCount; // 线程工厂，负责创建线程 private volatile ThreadFactory threadFactory; // 拒绝策略 private volatile RejectedExecutionHandler handler; // 线程空闲后保持活跃的时间 private volatile long keepAliveTime; // 是否允许核心线程超时死亡 private volatile boolean allowCoreThreadTimeOut; // 核心线程数 private volatile int corePoolSize; // 允许的最大线程数,是一个限制数量 private volatile int maximumPoolSize; 内部同步器　Worker 工作线程 private final class Worker extends AbstractQueuedSynchronizer implements Runnable { /** * This class will never be serialized, but we provide a * serialVersionUID to suppress a javac warning. */ private static final long serialVersionUID = 6138294804551838833L; // 线程 final Thread thread; /** Initial task to run. Possibly null. */ // 这个线程的第一个任务 Runnable firstTask; /** Per-thread task counter */ // 完成的任务数量 volatile long completedTasks; // TODO: switch to AbstractQueuedLongSynchronizer and move // completedTasks into the lock word. /** * Creates with given first task and thread from ThreadFactory. * @param firstTask the first task (null if none) */ // 第一个需要时，用一个任务创建一个线程 Worker(Runnable firstTask) { setState(-1); // inhibit interrupts until runWorker this.firstTask = firstTask; this.thread = getThreadFactory().newThread(this); } /** Delegates main run loop to outer runWorker. */ public void run() { runWorker(this); } // Lock methods // // The value 0 represents the unlocked state. // The value 1 represents the locked state. // 独占锁 protected boolean isHeldExclusively() { return getState() != 0; } // 申请锁 protected boolean tryAcquire(int unused) { // 从0->1,设置持有锁的线程 if (compareAndSetState(0, 1)) { setExclusiveOwnerThread(Thread.currentThread()); return true; } return false; } // 释放锁 protected boolean tryRelease(int unused) { // 设置为0 setExclusiveOwnerThread(null); setState(0); return true; } // 加解锁 public void lock() { acquire(1); } public boolean tryLock() { return tryAcquire(1); } public void unlock() { release(1); } public boolean isLocked() { return isHeldExclusively(); } // 如果工作线程启动了，就中断它 void interruptIfStarted() { Thread t; // State大于0 -> 启动了 // thread !=null -> 正在运行且没有中断 if (getState() >= 0 && (t = thread) != null && !t.isInterrupted()) { try { // 中断它 t.interrupt(); } catch (SecurityException ignore) { } } } // 其实是ThreadPoolExecutor的方法，但是只有在这里面用了，我就挪进来了 final void runWorker(Worker w) { Thread wt = Thread.currentThread(); // 第一个任务 Runnable task = w.firstTask; w.firstTask = null; w.unlock(); // allow interrupts // 状态设置为0,代表这个工作线程启动了，可以响应中断了 boolean completedAbruptly = true; try { // 有任务 while (task != null || (task = getTask()) != null) { // 加锁 w.lock(); // If pool is stopping, ensure thread is interrupted; // if not, ensure thread is not interrupted. This // requires a recheck in second case to deal with // shutdownNow race while clearing interrupt if ((runStateAtLeast(ctl.get(), STOP) || (Thread.interrupted() && runStateAtLeast(ctl.get(), STOP))) && !wt.isInterrupted()) wt.interrupt(); try { // 调用before挂钩 beforeExecute(wt, task); try { // 执行任务 task.run(); // 调用after挂钩 afterExecute(task, null); } catch (Throwable ex) { // 出错也得执行挂钩 afterExecute(task, ex); throw ex; } } finally { // 任务为空 task = null; // 完成任务+1 w.completedTasks++; // 解锁 w.unlock(); } } completedAbruptly = false; } finally { processWorkerExit(w, completedAbruptly); } } } 构造方法 这个类提供了4个构造方法，不过本质上都是最后一个. public ThreadPoolExecutor(int corePoolSize, int maximumPoolSize, long keepAliveTime, TimeUnit unit, BlockingQueue workQueue, ThreadFactory threadFactory, RejectedExecutionHandler handler) { if (corePoolSize 比较简单，首先做了一些参数的检查，之后进行赋值. 提交任务 execute 一个线程池，最重要，最常用的方法就是提交任务了，让我们从这里开始正式的看代码. public void execute(Runnable command) { // 为空，抛出异常 if (command == null) throw new NullPointerException(); /* * Proceed in 3 steps: * * 1. If fewer than corePoolSize threads are running, try to * start a new thread with the given command as its first * task. The call to addWorker atomically checks runState and * workerCount, and so prevents false alarms that would add * threads when it shouldn't, by returning false. * * 2. If a task can be successfully queued, then we still need * to double-check whether we should have added a thread * (because existing ones died since last checking) or that * the pool shut down since entry into this method. So we * recheck state and if necessary roll back the enqueuing if * stopped, or start a new thread if there are none. * * 3. If we cannot queue task, then we try to add a new * thread. If it fails, we know we are shut down or saturated * and so reject the task. */ int c = ctl.get(); // 当前线程数，小于核心线程数，直接新增一个工作线程 if (workerCountOf(c) 将一个任务提交至线程池，主要有三个分支: 当前工作线程数小于核心线程数，新增一个工作线程 如果线程大于核心线程数，但是可以入队成功. 如果新增线程失败，且工作队列满了，就拒绝任务. 这里涉及到最重要的一个方法，就是新增一个工作线程. 新增工作线程 addWorker 新增工作线程时，需要提供两个参数: 新增的第一个任务, 以及是否是核心线程 private boolean addWorker(Runnable firstTask, boolean core) { retry: for (int c = ctl.get();;) { // Check if queue empty only if necessary. // 1. 线程池没有在运行 // 2. 线程池已经终止, 第一个任务不为空, 队列为空三选一 // 这两个条件都满足，直接返回失败 if (runStateAtLeast(c, SHUTDOWN) && (runStateAtLeast(c, STOP) || firstTask != null || workQueue.isEmpty())) return false; for (;;) { // 这次申请的新工作线程，数量超过允许了，要么超过核心线程数，要么超过了最大线程数, 返回失败 if (workerCountOf(c) >= ((core ? corePoolSize : maximumPoolSize) & COUNT_MASK)) return false; // 增加工作线程计数成功，退出外层循环 if (compareAndIncrementWorkerCount(c)) break retry; // 状态C c = ctl.get(); // Re-read ctl // 如果线程池没在运行，继续外层循环，要么失败退出，要么CAS递增数量成功 if (runStateAtLeast(c, SHUTDOWN)) continue retry; // else CAS failed due to workerCount change; retry inner loop } } boolean workerStarted = false; boolean workerAdded = false; Worker w = null; try { // 新建工作线程 w = new Worker(firstTask); final Thread t = w.thread; // 要能从工厂拿到一个ok 的线程 if (t != null) { // 加锁 final ReentrantLock mainLock = this.mainLock; mainLock.lock(); try { // Recheck while holding lock. // Back out on ThreadFactory failure or if // shut down before lock acquired. int c = ctl.get(); // 再一次检查状态，害怕在获取锁之前被改了 if (isRunning(c) || (runStateLessThan(c, STOP) && firstTask == null)) { if (t.getState() != Thread.State.NEW) throw new IllegalThreadStateException(); // 添加这个工作线程 workers.add(w); workerAdded = true; int s = workers.size(); // 更新到达过的最大线程数 if (s > largestPoolSize) largestPoolSize = s; } } finally { // 解锁 mainLock.unlock(); } // 如果添加成功了，就运行它 if (workerAdded) { t.start(); workerStarted = true; } } } finally { // 失败了 if (! workerStarted) addWorkerFailed(w); } // 返回是否: 新增一个工作线程，且让他运行了 return workerStarted; } // 添加一个工作线程失败了 private void addWorkerFailed(Worker w) { final ReentrantLock mainLock = this.mainLock; mainLock.lock(); try { // 如果刚才创建了，就移除掉 if (w != null) workers.remove(w); // 减去一个工作线程 decrementWorkerCount(); // 终止线程池 tryTerminate(); } finally { mainLock.unlock(); } } // 尝试终止线程池 final void tryTerminate() { for (;;) { // 线程池还在跑，终止不了 int c = ctl.get(); if (isRunning(c) || runStateAtLeast(c, TIDYING) || (runStateLessThan(c, STOP) && ! workQueue.isEmpty())) return; // 工作线程大于0,把空闲的都给中断掉 if (workerCountOf(c) != 0) { // Eligible to terminate interruptIdleWorkers(ONLY_ONE); return; } // 到这里已经线程池已经完蛋了 final ReentrantLock mainLock = this.mainLock; mainLock.lock(); try { // 设置状态为整理中 if (ctl.compareAndSet(c, ctlOf(TIDYING, 0))) { try { // 终止后可以用来执行一个行为的hook. 可以被子类重写. terminated(); } finally { // 设置状态为成功终止 ctl.set(ctlOf(TERMINATED, 0)); termination.signalAll(); } return; } } finally { mainLock.unlock(); } // else retry on failed CAS } } 上面已经备注了一些关键注释，这里再总结下新增工作线程时做了什么: 如果线程池状态不ok,返回失败. 自旋判断数量是否超出核心线程数或者最大线程数的限制，没有的话尝试增加工作线程计数.直到成功 新建一个工作线程(同时从线程工厂新创建一个线程),将工作线程添加到集合中，然后让工作线程运行第一个任务. 如果期间失败了，就清理相关属性，尝试终止线程池. 任务出队 在提交任务时，如果核心线程数满了，此时会将任务放入工作队列，那么什么时候出队呢? 每一个工作线程启动后，首先会执行创建它时的第一个任务，执行完后，会调用getTask()来获取下一个任务. // 为当前的工作线程，获取下一个任务 private Runnable getTask() { boolean timedOut = false; // Did the last poll() time out? for (;;) { // 当前状态 int c = ctl.get(); // Check if queue empty only if necessary. // 状态不ok,返回null if (runStateAtLeast(c, SHUTDOWN) && (runStateAtLeast(c, STOP) || workQueue.isEmpty())) { decrementWorkerCount(); return null; } // 工作线程数 int wc = workerCountOf(c); // Are workers subject to culling? // 是否要过期死亡 boolean timed = allowCoreThreadTimeOut || wc > corePoolSize; // 1. 数量超过最大线程数了 或者 已经空闲超过给定时间了 // 2. 工作线程数大于1, 等待队列为空 if ((wc > maximumPoolSize || (timed && timedOut)) && (wc > 1 || workQueue.isEmpty())) { // CAS递减工作线程数成功, 返回null, 让调用的工作线程死去吧 if (compareAndDecrementWorkerCount(c)) return null; continue; } try { // 从队列中获取第一个元素 Runnable r = timed ? workQueue.poll(keepAliveTime, TimeUnit.NANOSECONDS) : workQueue.take(); // 返回这个任务 if (r != null) return r; // 拿到的为空，说明超时了，调用方的线程可以去死了 timedOut = true; } catch (InterruptedException retry) { timedOut = false; } } } 这个方法比较简单，核心思路就是从等待队列中获取第一个元素，给调用的工作线程执行. 只是在其中夹杂了一些是否需要超时死亡，是否已经超时的代码. 用是否返回一个任务，来控制调用方的工作线程是否应该死亡. 如何拒绝任务? 回顾下拒绝任务的几种情况: 线程池终止了 线程池的工作线程以及工作队列都满了. 拒绝时调用reject(command). final void reject(Runnable command) { handler.rejectedExecution(command, this); } 额，比较简单，就是直接调用RejectedExecutionHandler.rejectedExecution方法，因此当需要实现自己的拒绝策略时，记得实现一个这个接口的实现类即可. 等待终止 经常在我们提交完任务后，想要等线程池中的所有方法执行完毕，我们再进行下一步操作，这个当然是可以通过CountDownLatch和CyclicBarrier等同步器来实现的,但是线程池其实已经实现了类似的功能. // 手动关闭线程池 public void shutdown() { final ReentrantLock mainLock = this.mainLock; mainLock.lock(); try { // 检查权限 checkShutdownAccess(); // 更改状态 advanceRunState(SHUTDOWN); // 中断空闲的工作者 interruptIdleWorkers(); onShutdown(); // hook for ScheduledThreadPoolExecutor } finally { mainLock.unlock(); } // 尝试关闭线程池 tryTerminate(); } public boolean awaitTermination(long timeout, TimeUnit unit) throws InterruptedException { long nanos = unit.toNanos(timeout); // 加锁 final ReentrantLock mainLock = this.mainLock; mainLock.lock(); try { while (runStateLessThan(ctl.get(), TERMINATED)) { if (nanos 分为两步. 手动调用shutdown来关闭线程池,线程池会将所有能关闭的工作线程都关闭掉.之后尝试终止线程池 阻塞调用awaitTermination来等待线程池关闭，继续下一个步骤. 预热线程 如果在创建线程池之前，已经有一个有大量值的工作队列，我们可能希望预创建一些线程. prestartAllCoreThreads 预创建所有线程 prestartCoreThread 预创建核心线程 删除任务 如果我们已经提交了一个任务，后悔了，或者说我们想删除掉所有等待的任务怎么办呢? // 移除给定任务 public boolean remove(Runnable task) { boolean removed = workQueue.remove(task); tryTerminate(); // In case SHUTDOWN and now empty return removed; } // 遍历等待队列，移除掉所有在等待的任务 public void purge() { final BlockingQueue q = workQueue; try { Iterator it = q.iterator(); while (it.hasNext()) { Runnable r = it.next(); if (r instanceof Future && ((Future)r).isCancelled()) it.remove(); } } catch (ConcurrentModificationException fallThrough) { // Take slow path if we encounter interference during traversal. // Make copy for traversal and call remove for cancelled entries. // The slow path is more likely to be O(N*N). for (Object r : q.toArray()) if (r instanceof Future && ((Future)r).isCancelled()) q.remove(r); } tryTerminate(); // In case SHUTDOWN and now empty } 监控方法 这个类提供了大量的get/set方法，来监控当前线程池内的各种状态，以及动态的修改一些参数. isShutdown 是否关闭 isTerminating 是否正在终止 isTerminated 是否已经终止 setThreadFactory 设置线程工厂 getThreadFactory 获取线程工厂 setRejectedExecutionHandler 设置拒绝策略 getRejectedExecutionHandler 获取拒绝策略 setCorePoolSize 设置核心线程数 getCorePoolSize 获取核心线程数 allowsCoreThreadTimeOut 核心线程是否允许超时死亡 setMaximumPoolSize 设置最大线程数 getMaximumPoolSize 获取最大线程数 setKeepAliveTime 设置活跃时间 getKeepAliveTime 获取活跃时间 getQueue 获取工作队列 getPoolSize 获取当前线程池的大小 getActiveCount 获取活跃工作线程数量 getLargestPoolSize 获取到达过的最大线程池大小 getTaskCount 获取任务数量 getCompletedTaskCount 获取已经完成的任务数量 线程工厂 线程工厂实现了ThreadFactory接口. 在Executors中的默认实现为: private static class DefaultThreadFactory implements ThreadFactory { // 数量 private static final AtomicInteger poolNumber = new AtomicInteger(1); // 分组 private final ThreadGroup group; // 数量 private final AtomicInteger threadNumber = new AtomicInteger(1); // 名字前缀 private final String namePrefix; // 工厂构造方法 DefaultThreadFactory() { SecurityManager s = System.getSecurityManager(); // 同一个线程组 group = (s != null) ? s.getThreadGroup() : Thread.currentThread().getThreadGroup(); // 固定的前缀 namePrefix = \"pool-\" + poolNumber.getAndIncrement() + \"-thread-\"; } public Thread newThread(Runnable r) { // 创建一个线程 Thread t = new Thread(group, r, namePrefix + threadNumber.getAndIncrement(), 0); // 不是守护线程 if (t.isDaemon()) t.setDaemon(false); // 优先级为统一的正常优先级 if (t.getPriority() != Thread.NORM_PRIORITY) t.setPriority(Thread.NORM_PRIORITY); return t; } } 比较简单，采用统一的线程组，递增的线程池编号，递增的线程编号，统一的前缀，不是守护线程作为参数创建一个线程. 拒绝策略 ThreadPoolExecutor默认提供了4种拒绝策略. AbortPolicy 默认实现，拒绝时直接抛出异常 CallerRunsPolicy 拒绝时让调用方的线程执行这个任务，这是一个反馈型的控制策略，可以让提交任务的速度慢下来 DiscardPolicy　不能执行的任务直接丢弃掉. DiscardOldestPolicy 拒绝时，丢弃掉最老的任务，也就是等待队列的第一个节点. 实际上根据需要，可以自己实现一些策略，这里简单列举两个: 让调用方等待 public static class WaitPolicy implements RejectedExecutionHandler { public WaitPolicy() { } public void rejectedExecution(Runnable r, ThreadPoolExecutor executor) { try { // 调用阻塞方法put,向等待队列中添加任务 executor.getQueue().put(r); } catch (InterruptedException var4) { } } } 上面的示例，调用阻塞方法put，在线程池中有一个任务完成，等待队列中空出一个位置时，该方法得以继续向下运行. 如果每个任务运行时间足够长，这个策略会导致提交任务的线程长时间阻塞，比较浪费. 添加日志等 private static class MyRejectPolicy implements RejectedExecutionHandler { @Override public void rejectedExecution(Runnable r, ThreadPoolExecutor executor) { System.out.println(\"reject me,555\"); // send email ... } } 当一些重要程序中，发生异常，导致异常拒绝，需要打印日志，并发送邮件等通知开发者. 强行新建线程运行 private static final class NewThreadRunsPolicy implements RejectedExecutionHandler { NewThreadRunsPolicy() { super(); } public void rejectedExecution(Runnable r, ThreadPoolExecutor executor) { try { final Thread t = new Thread(r, \"Temporary task executor\"); t.start(); } catch (Throwable e) { throw new RejectedExecutionException( \"Failed to start a new thread\", e); } } } 有时，我们宁愿服务器累死，也不想拒绝任务，可以使用这个. 不管任何强行，强行创建一个不受线程池管理的线程，去运行这个任务. 线程池工厂 19年介绍过Executors提供的4个工厂方法，这里不重复了. Java中executors提供的的4种线程池 完. 完。 联系我 最后，欢迎关注我的个人公众号【 呼延十 】，会不定期更新很多后端工程师的学习笔记。 也欢迎直接公众号私信或者邮箱联系我，一定知无不言，言无不尽。 以上皆为个人所思所得，如有错误欢迎评论区指正。 欢迎转载，烦请署名并保留原文链接。 联系邮箱：huyanshi2580@gmail.com 更多学习笔记见个人博客或关注微信公众号 ------>呼延十 版权所有，盗版必究 all right reserved，powered by GitbookLast Modified On： 2021-10-17 02:51:51 "},"java/juc/2019-03-29-(juc系列)用线程池执行定时任务.html":{"url":"java/juc/2019-03-29-(juc系列)用线程池执行定时任务.html","title":"(juc系列)用线程池执行定时任务","keywords":"","body":"背景介绍 还是年轻啊,知识储备严重不足. 今天大佬让我实现以下XXX. 每次用户请求都会判断当前值在不在集合里面,集合数据来自于数据库,不用做缓存,每隔几分钟从数据库load一下数据放到内存就行. 我一脸懵逼,操作内存?我不会啊. 而且没有用spring框架,我也不会定时任务啊...Timer什么的记不住要现场查一下吗? 然后大佬帮我写了一下.....我现在来复习一下. 场景模拟如下: 每隔X段时间,随机生成一些随机数放到内存中.会有用户请求接口来查看某个值是否在其中. 具体实现了: 每隔5s,随机生成3个随机数替换掉原来的,然后启动一个死循环不断判断2是否在这次的list中. `` 其实比较简单,当时一脸懵逼没想起来,也是对已有知识掌握的不够熟悉. 放进内存问题. 这个其实直接new个list就好,就在内存里面啊.... 定时任务,用Java的定时线程池来解决. 实现代码 package daily; import java.util.ArrayList; import java.util.List; import java.util.Random; import java.util.concurrent.ScheduledThreadPoolExecutor; import java.util.concurrent.TimeUnit; import java.util.concurrent.atomic.AtomicReference; /** * Created by pfliu on 2019/03/29. */ public class ScheduleThreadTest { private static final AtomicReference> list = new AtomicReference<>(new ArrayList<>()); public static void main(String[] args) throws InterruptedException { // 线程池执行定时任务 ScheduledThreadPoolExecutor schedule = new ScheduledThreadPoolExecutor(1); schedule.scheduleWithFixedDelay(() -> { // 每隔5秒生成3个1-10的数字,放进list里面 List integers = new ArrayList<>(); for (int i = 0; i 要活学活用啊亲. 完. ChangeLog 2019-01-28 以上皆为个人所思所得，如有错误欢迎评论区指正。 欢迎转载，烦请署名并保留原文链接。 联系邮箱：huyanshi2580@gmail.com 更多学习笔记见个人博客------>呼延十 版权所有，盗版必究 all right reserved，powered by GitbookLast Modified On： 2021-10-17 17:42:12 "},"java/juc/2021-10-13-(juc系列)Executors类的工厂方法.html":{"url":"java/juc/2021-10-13-(juc系列)Executors类的工厂方法.html","title":"(juc系列)Executors类的工厂方法","keywords":"","body":"简介 提供一些工厂方法和工具类方法. 给Executor,ExecutorService,ScheduledExecutorService和ThreadFacotry使用. Callable类在这里定义. 这个类提供以下几种方法: 用一些常用的参数设置，创建一个新的ExecutorService返回. 约等于ExecutorService的几个工厂方法. ScheduledExecutorSerivce的工厂方法，用一些常用的参数创建. 创建并返回一些ExecutorService的包装类, 关闭掉了重新设置参数的功能。 创建ThreadFactory的一些方法. 创建并返回Callable的一些方法. 源码 ExecutorService的工厂方法 newFixedThreadPool 创建一个固定大小的ThreadPoolExecutor. newSingleThreadExecutor 创建一个单个线程的FinalizableDelegatedExecutorService. newCachedThreadPool newCachedThreadPool创建一个无界的ThreadPoolExecutor.没有核心线程，也没有最大线程数量的限制. newWorkStealingPool 创建一个ForkJoinPool. newSingleThreadScheduledExecutor 创建一个具有单个线程的，周期定时执行的线程池.DelegatedScheduledExecutorService newScheduledThreadPool 创建多个线程的线程池，可以周期性的执行任务. unconfigurableExecutorService 将给定的ExecutorService进行封装，不再允许修改相关的配置. unconfigurableScheduledExecutorService 将给定的周期性线程池进行封装，不再允许修改配置. ThreadFactory 线程工厂 defaultThreadFactory 返回DefaultThreadFactory类的一个实例，是默认的线程工厂，简单的创建一个非守护线程. privilegedThreadFactory 返回PrivilegedThreadFactory的一个实例，使得创建的线程拥有高级的访问权限和相同的类加载器. 代码如下. private static class PrivilegedThreadFactory extends DefaultThreadFactory { final AccessControlContext acc; final ClassLoader ccl; PrivilegedThreadFactory() { super(); SecurityManager sm = System.getSecurityManager(); if (sm != null) { // Calls to getContextClassLoader from this class // never trigger a security check, but we check // whether our callers have this permission anyways. sm.checkPermission(SecurityConstants.GET_CLASSLOADER_PERMISSION); // Fail fast sm.checkPermission(new RuntimePermission(\"setContextClassLoader\")); } this.acc = AccessController.getContext(); this.ccl = Thread.currentThread().getContextClassLoader(); } public Thread newThread(final Runnable r) { return super.newThread(new Runnable() { public void run() { AccessController.doPrivileged(new PrivilegedAction<>() { public Void run() { Thread.currentThread().setContextClassLoader(ccl); r.run(); return null; } }, acc); } }); } } 封装Callable callable(Runnable task, T result) 将给定的任务封装成Callable.但是不需要返回结果. callable(Runnable task) 给定的任务封装成Callable. 结束就返回null. 以上两个方法,通过RunnableAdapter实现. // 一个run任务的装饰器 private static final class RunnableAdapter implements Callable { private final Runnable task; private final T result; RunnableAdapter(Runnable task, T result) { this.task = task; this.result = result; } // 调用call时返回给定的结果 public T call() { task.run(); return result; } public String toString() { return super.toString() + \"[Wrapped task = \" + task + \"]\"; } } callable(final PrivilegedAction action) 封装Callable.调用时执行action. callable(final PrivilegedExceptionAction action) 同上 privilegedCallable 具有特权的callable. 简单的ExecutorService实现 DelegatedExecutorService 一个ExecutorService的简单实现，同时对另外一个ExecutorService进行包装,使得传入的ExecutorService， 对外只能暴露ExecutorService接口的相关方法，所有的动态修改配置方法不可用. 可以起到强制不允许修改线程池参数的作用。 private static class DelegatedExecutorService implements ExecutorService { private final ExecutorService e; DelegatedExecutorService(ExecutorService executor) { e = executor; } public void execute(Runnable command) { try { e.execute(command); } finally { reachabilityFence(this); } } public void shutdown() { e.shutdown(); } public List shutdownNow() { try { return e.shutdownNow(); } finally { reachabilityFence(this); } } public boolean isShutdown() { try { return e.isShutdown(); } finally { reachabilityFence(this); } } public boolean isTerminated() { try { return e.isTerminated(); } finally { reachabilityFence(this); } } public boolean awaitTermination(long timeout, TimeUnit unit) throws InterruptedException { try { return e.awaitTermination(timeout, unit); } finally { reachabilityFence(this); } } public Future submit(Runnable task) { try { return e.submit(task); } finally { reachabilityFence(this); } } public Future submit(Callable task) { try { return e.submit(task); } finally { reachabilityFence(this); } } public Future submit(Runnable task, T result) { try { return e.submit(task, result); } finally { reachabilityFence(this); } } public List> invokeAll(Collection> tasks) throws InterruptedException { try { return e.invokeAll(tasks); } finally { reachabilityFence(this); } } public List> invokeAll(Collection> tasks, long timeout, TimeUnit unit) throws InterruptedException { try { return e.invokeAll(tasks, timeout, unit); } finally { reachabilityFence(this); } } public T invokeAny(Collection> tasks) throws InterruptedException, ExecutionException { try { return e.invokeAny(tasks); } finally { reachabilityFence(this); } } public T invokeAny(Collection> tasks, long timeout, TimeUnit unit) throws InterruptedException, ExecutionException, TimeoutException { try { return e.invokeAny(tasks, timeout, unit); } finally { reachabilityFence(this); } } } 可以看到，所有实现自ExecutorService的方法，都只是简单的做了委托，交给传入的ExecutorService去执行。 DelegatedScheduledExecutorService 周期性调度的线程池的委托者 private static class DelegatedScheduledExecutorService extends DelegatedExecutorService implements ScheduledExecutorService { private final ScheduledExecutorService e; DelegatedScheduledExecutorService(ScheduledExecutorService executor) { super(executor); e = executor; } public ScheduledFuture schedule(Runnable command, long delay, TimeUnit unit) { return e.schedule(command, delay, unit); } public ScheduledFuture schedule(Callable callable, long delay, TimeUnit unit) { return e.schedule(callable, delay, unit); } public ScheduledFuture scheduleAtFixedRate(Runnable command, long initialDelay, long period, TimeUnit unit) { return e.scheduleAtFixedRate(command, initialDelay, period, unit); } public ScheduledFuture scheduleWithFixedDelay(Runnable command, long initialDelay, long delay, TimeUnit unit) { return e.scheduleWithFixedDelay(command, initialDelay, delay, unit); } } 类似与DelegatedExecutorService,对所有ScheduledExecutorService定义的方法进行实现，只做简单的委托，转发请求而已. 完。 联系我 最后，欢迎关注我的个人公众号【 呼延十 】，会不定期更新很多后端工程师的学习笔记。 也欢迎直接公众号私信或者邮箱联系我，一定知无不言，言无不尽。 以上皆为个人所思所得，如有错误欢迎评论区指正。 欢迎转载，烦请署名并保留原文链接。 联系邮箱：huyanshi2580@gmail.com 更多学习笔记见个人博客或关注微信公众号 ------>呼延十 版权所有，盗版必究 all right reserved，powered by GitbookLast Modified On： 2021-10-17 02:51:51 "},"java/juc/2021-09-28-(juc系列)AQS源码学习笔记.html":{"url":"java/juc/2021-09-28-(juc系列)AQS源码学习笔记.html","title":"(juc系列)AQS源码学习笔记","keywords":"","body":"前言 本文源码基于: JDK13 JUC是Java提供的一个并发工具包，提供了很多并发工具. 本文主要将AQS. java.util.concurrent.locks.AbstractQueuedSynchronizer. 是一个基类，也可以理解为一个框架. 它提供了对于同步状态的控制，以前线程等待时的FIFO队列. Fields AQS的属性. state /** * The synchronization state. */ private volatile int state; 核心属性，同步状态. 使用volatile修饰. 与之对应的三个方法: /** * Returns the current value of synchronization state. * This operation has memory semantics of a {@code volatile} read. * @return current state value */ protected final int getState(){ return state; } /** * Sets the value of synchronization state. * This operation has memory semantics of a {@code volatile} write. * @param newState the new state value */ protected final void setState(int newState){ state=newState; } /** * Atomically sets synchronization state to the given updated * value if the current state value equals the expected value. * This operation has memory semantics of a {@code volatile} read * and write. * * @param expect the expected value * @param update the new value * @return {@code true} if successful. False return indicates that the actual * value was not equal to the expected value. */ protected final boolean compareAndSetState(int expect,int update){ return STATE.compareAndSet(this,expect,update); } 分别提供了get/set方法及CAS的赋值方法. head 等待队列队头. tail 等待队列队尾. head 和 tail 是java.util.concurrent.locks.AbstractQueuedSynchronizer.Node 的实例， 构成了一个双向链表. Node Node是为了表达一个等待线程而抽象的数据结构，主要有以下几个属性. // Node节点所在的等待状态 volatile int waitStatus; //前置节点 volatile Node prev; // 后置节点 volatile Node next; // 在这个节点上的线程 volatile Thread thread; // 下一个等待的节点 Node nextWaiter; 他有两种模式，分别为共享模式及独占模式. 对应不同的操作. 其中waitStatus为枚举值，有以下几个值. /** waitStatus value to indicate thread has cancelled. */ static final int CANCELLED=1; /** waitStatus value to indicate successor's thread needs unparking. */ static final int SIGNAL=-1; /** waitStatus value to indicate thread is waiting on condition. */ static final int CONDITION=-2; /** * waitStatus value to indicate the next acquireShared should * unconditionally propagate. */ static final int PROPAGATE=-3; Public-Methods AQS的方法可太多了. 先看一下对外提供的API方法. 众所周知，AQS是为了同步(加锁)而设计的. 那么一定是有获取锁,释放锁的方法的.先从这里切入. acquire(int arg) 独占式应用，典型的就是ReentrantLock. ReentrantLock源码学习ReentrantLock%E6%BA%90%E7%A0%81%E5%AD%A6%E4%B9%A0/) 独占模式的加锁代码. /** * Acquires in exclusive mode, ignoring interrupts. Implemented * by invoking at least once {@link #tryAcquire}, * returning on success. Otherwise the thread is queued, possibly * repeatedly blocking and unblocking, invoking {@link * #tryAcquire} until success. This method can be used * to implement method {@link Lock#lock}. * * @param arg the acquire argument. This value is conveyed to * {@link #tryAcquire} but is otherwise uninterpreted and * can represent anything you like. */ public final void acquire(int arg){ if(!tryAcquire(arg)&& acquireQueued(addWaiter(Node.EXCLUSIVE),arg)) selfInterrupt(); } 独占模式的获取锁, 并且忽略中断. 至少调用一次tryAcquire.如果成功了就返回. 否则的话将线程加入等待队列，重复的进行tryAcquire. 直到成功为止. traAcquire(int arg) 这个方法在AQS中是抽象的, protected修饰. 由子类具体进行实现. 它定义的: 独占模式的获取锁, 如果可以获取到，返回成功，如果获取失败，线程应该被放入等待队列. 如果线程已经在等待队列中, 应该是被其他线程唤醒了. 总之: 这个方法是非阻塞的，立即返回的，要么成功加锁，返回true. 要么加锁失败,返回flase. ，之后的操作就不归这个方法管了. addWaiter(Node node) private方法,给当前线程创建一个Node并且放入等待队列. /** * Creates and enqueues node for current thread and given mode. * * @param mode Node.EXCLUSIVE for exclusive, Node.SHARED for shared * @return the new node */ private Node addWaiter(Node mode){ Node node=new Node(mode); for(;;){ Node oldTail=tail; if(oldTail!=null){ node.setPrevRelaxed(oldTail); if(compareAndSetTail(oldTail,node)){ oldTail.next=node; return node; } }else{ initializeSyncQueue(); } } } 创建一个Node. 如果队尾为空，说明等待队列没有初始化,进行初始化. 将当前节点设置为新的队尾. acquireQueued(Node node, int arg) 一个final方法，子类无法重写. 将等待队列中的所有线程，进行获取锁的行为. /** * Acquires in exclusive uninterruptible mode for thread already in * queue. Used by condition wait methods as well as acquire. * * @param node the node * @param arg the acquire argument * @return {@code true} if interrupted while waiting */ final boolean acquireQueued(final Node node,int arg){ boolean interrupted=false; try{ for(;;){ final Node p=node.predecessor(); if(p==head&&tryAcquire(arg)){ setHead(node); p.next=null; // help GC return interrupted; } if(shouldParkAfterFailedAcquire(p,node)) interrupted|=parkAndCheckInterrupt(); } }catch(Throwable t){ cancelAcquire(node); if(interrupted) selfInterrupt(); throw t; } } 如果当前节点的前置节点是头结点，说明当前节点是优先级最高的那个.尝试获取锁. 如果当前节点不是优先级最高的，或者获取锁失败了. 调用shouldParkAfterFailedAcquire. shouldParkAfterFailedAcquire /** * Checks and updates status for a node that failed to acquire. * Returns true if thread should block. This is the main signal * control in all acquire loops. Requires that pred == node.prev. * * @param pred node's predecessor holding status * @param node the node * @return {@code true} if thread should block */ private static boolean shouldParkAfterFailedAcquire(Node pred,Node node){ int ws=pred.waitStatus; if(ws==Node.SIGNAL) /* * This node has already set status asking a release * to signal it, so it can safely park. */ return true; if(ws>0){ /* * Predecessor was cancelled. Skip over predecessors and * indicate retry. */ do{ node.prev=pred=pred.prev; }while(pred.waitStatus>0); pred.next=node; }else{ /* * waitStatus must be 0 or PROPAGATE. Indicate that we * need a signal, but don't park yet. Caller will need to * retry to make sure it cannot acquire before parking. */ pred.compareAndSetWaitStatus(ws,Node.SIGNAL); } return false; } 如果前置节点是SIGNAL.说明前置节点优先级更高，当前线程应该park. 如果前置节点被取消了，扔掉中间的取消节点. 不park. 如果前置节点是其他状态，设置为SIGNAL. 优先级最高. 不park. 不park的原因是再来一次. 检测一遍. 如果当前线程需要被park.则park且检查下是否中断了. parkAndCheckInterrupt /** * Convenience method to park and then check if interrupted. * * @return {@code true} if interrupted */ private final boolean parkAndCheckInterrupt(){ LockSupport.park(this); return Thread.interrupted(); } 如果发生异常，则取消掉这次获取锁. cancelAcquire(Node node) /** * Cancels an ongoing attempt to acquire. * * @param node the node */ private void cancelAcquire(Node node){ // Ignore if node doesn't exist if(node==null) return; node.thread=null; // Skip cancelled predecessors Node pred=node.prev; while(pred.waitStatus>0) node.prev=pred=pred.prev; // predNext is the apparent node to unsplice. CASes below will // fail if not, in which case, we lost race vs another cancel // or signal, so no further action is necessary, although with // a possibility that a cancelled node may transiently remain // reachable. Node predNext=pred.next; // Can use unconditional write instead of CAS here. // After this atomic step, other Nodes can skip past us. // Before, we are free of interference from other threads. node.waitStatus=Node.CANCELLED; // If we are the tail, remove ourselves. if(node==tail&&compareAndSetTail(node,pred)){ pred.compareAndSetNext(predNext,null); }else{ // If successor needs signal, try to set pred's next-link // so it will get one. Otherwise wake it up to propagate. int ws; if(pred!=head&& ((ws=pred.waitStatus)==Node.SIGNAL|| (ws 当前node的thread设置为null. 扔掉当前节点之前的所有被取消了的节点. 取消掉当前节点。 设置尾节点为前一个节点. release(int arg) 独占式的解锁. /** * Releases in exclusive mode. Implemented by unblocking one or * more threads if {@link #tryRelease} returns true. * This method can be used to implement method {@link Lock#unlock}. * * @param arg the release argument. This value is conveyed to * {@link #tryRelease} but is otherwise uninterpreted and * can represent anything you like. * @return the value returned from {@link #tryRelease} */ public final boolean release(int arg){ if(tryRelease(arg)){ Node h=head; if(h!=null&&h.waitStatus!=0) unparkSuccessor(h); return true; } return false; } 调用tryRelease(int arg). 如果解锁成功，唤醒头结点的后继节点. 如果解锁失败， 返回false. tryRelease(int arg) 解锁操作，由子类负责具体实现，可以后期针对ReentrantLock学习. 这个方法，非阻塞式， 即时返回true/false. 代表是否释放成功. unparkSuccessor(Node node) /** * Wakes up node's successor, if one exists. * * @param node the node */ private void unparkSuccessor(Node node){ /* * If status is negative (i.e., possibly needing signal) try * to clear in anticipation of signalling. It is OK if this * fails or if status is changed by waiting thread. */ int ws=node.waitStatus; if(ws0){ s=null; for(Node p=tail;p!=node&&p!=null;p=p.prev) if(p.waitStatus 在等待队列中，从后向前找到正序的第一个需要唤醒的Node. 执行unpark操作. acquireShared(int arg) 共享锁的相关实现，可以查看CountDownLatch的相关代码. CountDownLatch源码解析CountDownLatch%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB/) 共享模式的获取锁.忽略中断. 至少调用一次TryAcquireShared, 如果成功就返回，失败就将线程加入等待队列. 重复调用TryAcquireShared知道成功. /** * Acquires in shared mode, ignoring interrupts. Implemented by * first invoking at least once {@link #tryAcquireShared}, * returning on success. Otherwise the thread is queued, possibly * repeatedly blocking and unblocking, invoking {@link * #tryAcquireShared} until success. * * @param arg the acquire argument. This value is conveyed to * {@link #tryAcquireShared} but is otherwise uninterpreted * and can represent anything you like. */ public final void acquireShared(int arg){ if(tryAcquireShared(arg) tryAcquireShared(int arg) 抽象方法，由子类负责实现. 如果获取锁成功，直接返回. 如果获取失败，线程加入等待队列，如果线程已经加入，等待被其他人释放锁的动作唤醒. doAcquireShared(int arg) /** * Acquires in shared uninterruptible mode. * @param arg the acquire argument */ private void doAcquireShared(int arg){ final Node node=addWaiter(Node.SHARED); boolean interrupted=false; try{ for(;;){ final Node p=node.predecessor(); if(p==head){ int r=tryAcquireShared(arg); if(r>=0){ setHeadAndPropagate(node,r); p.next=null; // help GC return; } } if(shouldParkAfterFailedAcquire(p,node)) interrupted|=parkAndCheckInterrupt(); } }catch(Throwable t){ cancelAcquire(node); throw t; }finally{ if(interrupted) selfInterrupt(); } } 首先添加一个SHARED模式的节点到等待队列. 如果当前节点的前置节点是head. 说明当前节点的优先级最高，尝试获取锁. 如果成功，则返回. 如果当前节点不是优先级最高的，或者获取锁失败了，调用shouldParkAfterFailedAcquire判断是否需要进行park. 如果需要,则park当前线程并检查中断. 如果不需要park.则自旋. 进行下一次判断，是否需要获取锁. 如果catch异常，则取消这次获取锁，流程同上面独占模式取消. releaseShared(int arg) 共享模式的释放锁. /** * Releases in shared mode. Implemented by unblocking one or more * threads if {@link #tryReleaseShared} returns true. * * @param arg the release argument. This value is conveyed to * {@link #tryReleaseShared} but is otherwise uninterpreted * and can represent anything you like. * @return the value returned from {@link #tryReleaseShared} */ public final boolean releaseShared(int arg){ if(tryReleaseShared(arg)){ doReleaseShared(); return true; } return false; } 非阻塞式的释放锁.调用tryReleaseShared. 如果释放成功，调用doReleaseShared.如果失败，返回false. tryReleaseShared(int arg) 抽象方法，具体由子类进行实现. 非阻塞式的，返回释放的结果. doReleaseShared() /** * Release action for shared mode -- signals successor and ensures * propagation. (Note: For exclusive mode, release just amounts * to calling unparkSuccessor of head if it needs signal.) */ private void doReleaseShared(){ /* * Ensure that a release propagates, even if there are other * in-progress acquires/releases. This proceeds in the usual * way of trying to unparkSuccessor of head if it needs * signal. But if it does not, status is set to PROPAGATE to * ensure that upon release, propagation continues. * Additionally, we must loop in case a new node is added * while we are doing this. Also, unlike other uses of * unparkSuccessor, we need to know if CAS to reset status * fails, if so rechecking. */ for(;;){ Node h=head; if(h!=null&&h!=tail){ int ws=h.waitStatus; if(ws==Node.SIGNAL){ if(!h.compareAndSetWaitStatus(Node.SIGNAL,0)) continue; // loop to recheck cases unparkSuccessor(h); } else if(ws==0&& !h.compareAndSetWaitStatus(0,Node.PROPAGATE)) continue; // loop on failed CAS } if(h==head) // loop if head changed break; } } 共享模式的释放锁操作. 通知后继者并且确保传播. 独占式的解锁，只需要唤醒下一个即可。而共享式的解锁，需要广播解锁消息. 遍历等待队列，将SIGNAL的节点继任者全部唤醒. 完. 参考文章 完。 联系我 最后，欢迎关注我的个人公众号【 呼延十 】，会不定期更新很多后端工程师的学习笔记。 也欢迎直接公众号私信或者邮箱联系我，一定知无不言，言无不尽。 以上皆为个人所思所得，如有错误欢迎评论区指正。 欢迎转载，烦请署名并保留原文链接。 联系邮箱：huyanshi2580@gmail.com 更多学习笔记见个人博客或关注微信公众号 ------>呼延十 版权所有，盗版必究 all right reserved，powered by GitbookLast Modified On： 2021-10-05 17:45:13 "},"java/juc/2021-09-30-(juc系列)CountDownLatch源码阅读.html":{"url":"java/juc/2021-09-30-(juc系列)CountDownLatch源码阅读.html","title":"(juc系列)CountDownLatch源码阅读","keywords":"","body":"前言 本文源码基于: JDK13 为了巩固AQS.　看一下CountDownLatch的源码. 简介 大部分都是直接翻译的官方代码注释，嘻嘻 一个同步器, 允许一个或者多个线程等待, 知道其他线程完成一系列操作. 初始化时提供一个数字. await方法将阻塞，直到别的线程通过调用countDown,达到给定的数字. 这个类是一个一次性，count数字不能被重新设置. 如果你需要一个可复用的版本，可以考虑使用CyclicBarrier. CountDownLatch 可以用于以下目的: 初始化为N. 所有线程调用await等待，直到门被一个线程调用countDown来打开． 初始化为N, 一个线程等待，直到N个线程完成了一些动作，或者某个动作被完成了N次. CountDownLatch的一个很有用的特性是: 所有调用countDown的线程不需要等待计数到达0. 他只是在await方法上阻塞所有想要通过的线程. 使用实例(来自官方文档): 两个类，使用两个CountDownLatch来完成以下功能. 第一个CountDownLatch, 是一个开始信号，告诉所有工作线程，驱动已经就绪，可以开始工作了。 第二个CountDownLatch, 是一个结束信号，允许驱动等待所有工作线程完成，之后进行其他工作. class Driver { void main() throws InterruptedException { CountDownLatch startSignal = new CountDownLatch(1); CountDownLatch doneSignal = new CountDownLatch(N); for (int i = 0; i 另外一个典型应用是，将一个任务分割成N部分，每一个部分封装成一个任务，交给线程池。 然后一个协调线程，调用`await｀等到所有的子部分完成. 再通过. class Driver2 { void main() throws InterruptedException { CountDownLatch doneSignal = new CountDownLatch(N); Executor e = null; // some Executor for (int i = 0; i 源码探究 最核心的实现，依然是继承自AQS的一个子类同步器Sync. Sync /** * Synchronization control For CountDownLatch. * Uses AQS state to represent count. */ private static final class Sync extends AbstractQueuedSynchronizer { private static final long serialVersionUID = 4982264981922014374L; Sync(int count) { setState(count); } int getCount() { return getState(); } protected int tryAcquireShared(int acquires) { return (getState() == 0) ? 1 : -1; } protected boolean tryReleaseShared(int releases) { // Decrement count; signal when transition to zero for (;;) { int c = getState(); if (c == 0) return false; int nextc = c - 1; if (compareAndSetState(c, nextc)) return nextc == 0; } } } 首先，初始化时传递的Count值，复用AQS中的状态State. 实现了AQS的共享模式加锁及共享模式解锁. tryAcquireShared(int acquires) 共享模式的加锁，锁空闲就返回1. 锁非空闲就返回-1. tryReleaseShared(int releases) 共享模式的解锁. protected boolean tryReleaseShared(int releases) { // Decrement count; signal when transition to zero for (;;) { int c = getState(); if (c == 0) return false; int nextc = c - 1; if (compareAndSetState(c, nextc)) return nextc == 0; } } 递减Count. 如果减1之后为0，就认为解锁成功. 通知. 如果减去1之后不为0. 返回false. 意味着解锁了，但是没有完全解锁成功. 构造方法 没啥说的，　将传入的Count值传入Sync.复用AQS的状态值来实现Count的控制. countDown() 调用Sync同步器的释放共享锁方法，进行一次解锁操作. await() 调用Sync同步器的获取共享锁方法，进行加锁操作. 总结 CountDownLatch是对AQS的共享模式的比较精巧的应用. 首先初始化时传入Count值. 设置AQS的State值. 由于自定义了共享锁的获取逻辑，当State值>0时，此锁不可再被获取. countDown操作，即释放一次锁操作. 每次释放State值减1. await操作，即加锁操作. 阻塞式加锁，在初始化之后，加锁会一直阻塞，直到调用N次的countDown之后，将锁完全释放. 此时获取锁成功，继续下一步，也就是await方法成功返回，成功通过CountDownLatch了. 为什么CountDownLatch是一次性的? CountDownLatch中的同步器实现，并不是传统意义上的可以不断加锁或解锁。 只有在初始化时进行了设置State的操作，之后只可以进行读取/递减. 他的加锁操作，不会设置State的值，只是判断State是否大于1. 当解锁完成，State为0. 此时没有渠道去进行更新State的值. 如果重复的调用加锁，会不断的拿到\"加锁成功\". 但是State数值并不会改变. 因此此时的\"加锁成功\",其实意味着\"门已经打开，可以无限进入\". 每一次的\"加锁操作\", 约等于判断\"门是否开着\"的操作. 完. 完。 联系我 最后，欢迎关注我的个人公众号【 呼延十 】，会不定期更新很多后端工程师的学习笔记。 也欢迎直接公众号私信或者邮箱联系我，一定知无不言，言无不尽。 以上皆为个人所思所得，如有错误欢迎评论区指正。 欢迎转载，烦请署名并保留原文链接。 联系邮箱：huyanshi2580@gmail.com 更多学习笔记见个人博客或关注微信公众号 ------>呼延十 版权所有，盗版必究 all right reserved，powered by GitbookLast Modified On： 2021-10-10 00:37:17 "},"java/juc/2021-09-30-(juc系列)CyclicBarrier源码阅读.html":{"url":"java/juc/2021-09-30-(juc系列)CyclicBarrier源码阅读.html","title":"(juc系列)CyclicBarrier源码阅读","keywords":"","body":"前言 本文源码基于: JDK13 为了巩固AQS.　看一下CyclicBarrier的源码. 简介 大部分都是直接翻译的官方代码注释，嘻嘻 一个允许一系列线程互相等待，到达一个公共屏障点的同步辅助器. CyclicBarrier在一个固定大小的线程集合，必须互相等待时很有用. 之所以叫做循环(Cyclic), 是因为CyclicBarrier在线程全部释放后可以重复利用. CyclicBarrier支持一个可选的Runnable命令，　它将在每个屏障点运行一次(所有线程到达后，运行一次)。　在最后一个线程到达之后，但是在任何一个线程被释放之前. 这个操作对于在任何一个线程继续之前更新共享状态很有用. 使用实例: 示例展示了一个分解任务的设计. 将一份任务分解为N份，交给N个线程去做. 当N个线程全部完成工作后，触发Merge操作.收取结果. class Solver { final int N; final float[][] data; final CyclicBarrier barrier; class Worker implements Runnable { int myRow; Worker(int row) { myRow = row; } public void run() { while (!done()) { processRow(myRow); try { barrier.await(); } catch (InterruptedException ex) { return; } catch (BrokenBarrierException ex) { return; } } } } public Solver(float[][] matrix) { data = matrix; N = matrix.length; Runnable barrierAction = () -> mergeRows(); barrier = new CyclicBarrier(N, barrierAction); List threads = new ArrayList<>(N); for (int i = 0; i CyclicBarrier采用all-or-none的异常策略. 如果一个线程异常退出了. 所有其他在屏障点等待的线程也会异常退出. 源码探究 构造方法 /** * Creates a new {@code CyclicBarrier} that will trip when the * given number of parties (threads) are waiting upon it, and which * will execute the given barrier action when the barrier is tripped, * performed by the last thread entering the barrier. * * @param parties the number of threads that must invoke {@link #await} * before the barrier is tripped * @param barrierAction the command to execute when the barrier is * tripped, or {@code null} if there is no action * @throws IllegalArgumentException if {@code parties} is less than 1 */ public CyclicBarrier(int parties, Runnable barrierAction) { if (parties 两个构造方法，一个指定数量, 一个可以指定数量+屏障点行为的. 基本上只有赋值操作，不多说. 核心方法　await() public int await() throws InterruptedException, BrokenBarrierException { try { return dowait(false, 0L); } catch (TimeoutException toe) { throw new Error(toe); // cannot happen } } 可以看到直接调用了dowait. 这也是整个类的核心代码. /** * Main barrier code, covering the various policies. */ private int dowait(boolean timed, long nanos) throws InterruptedException, BrokenBarrierException, TimeoutException { // 加锁 final ReentrantLock lock = this.lock; lock.lock(); try { final Generation g = generation; // if (g.broken) throw new BrokenBarrierException(); if (Thread.interrupted()) { breakBarrier(); throw new InterruptedException(); } int index = --count; if (index == 0) { // tripped Runnable command = barrierCommand; if (command != null) { try { command.run(); } catch (Throwable ex) { breakBarrier(); throw ex; } } nextGeneration(); return 0; } // loop until tripped, broken, interrupted, or timed out for (;;) { try { if (!timed) trip.await(); else if (nanos > 0L) nanos = trip.awaitNanos(nanos); } catch (InterruptedException ie) { if (g == generation && ! g.broken) { breakBarrier(); throw ie; } else { // We're about to finish waiting even if we had not // been interrupted, so this interrupt is deemed to // \"belong\" to subsequent execution. Thread.currentThread().interrupt(); } } if (g.broken) throw new BrokenBarrierException(); if (g != generation) return index; if (timed && nanos １．首先获取内部唯一的ReentrantLock. 进行加锁操作. 判断当前CyclicBarrier是否已经残破，如果是的话抛出异常. 判断当前线程是否被中断了，如果是中断的话，根据之前说的，有一个线程中断，整个屏障中所有等待线程异常退出. 等待线程递减，如果递减完为0.说明是最后一个线程，那么如果屏障行为不为空，就执行该Runnalbe. 并重置整个屏障(这就是可复用了). 并通知所有等待的线程. 如果递减后不为0. 开始休眠等待唤醒. 在等待过程中，如果发生异常或者线程被中断，则将当前屏障标记为破碎，同时唤醒其他等待的线程，异常退出. 解锁. reset() /** * Resets the barrier to its initial state. If any parties are * currently waiting at the barrier, they will return with a * {@link BrokenBarrierException}. Note that resets after * a breakage has occurred for other reasons can be complicated to * carry out; threads need to re-synchronize in some other way, * and choose one to perform the reset. It may be preferable to * instead create a new barrier for subsequent use. */ public void reset() { final ReentrantLock lock = this.lock; lock.lock(); try { breakBarrier(); // break the current generation nextGeneration(); // start a new generation } finally { lock.unlock(); } } 重置这个屏障，首先加锁，然后将当前屏障的所有等待线程唤醒，重置屏障完成. 解锁. 总结 CountDownLatch是一个一次性，用于一个线程等待多个线程，或者多个线程等待一个线程的同步器。 CyclicBarrier是一个可复用的，多个线程互相等待的同步器. 实现原理也不一致. CountDownLatch基于AQS实现，自定义了同步器，之后对外提供API. CyclicBarrier内部使用ReentrantLock来实现同步. 对内部的count等属性的操作，也依赖于ReentrantLock的同步功能. 完. 参考文章 完。 联系我 最后，欢迎关注我的个人公众号【 呼延十 】，会不定期更新很多后端工程师的学习笔记。 也欢迎直接公众号私信或者邮箱联系我，一定知无不言，言无不尽。 以上皆为个人所思所得，如有错误欢迎评论区指正。 欢迎转载，烦请署名并保留原文链接。 联系邮箱：huyanshi2580@gmail.com 更多学习笔记见个人博客或关注微信公众号 ------>呼延十 版权所有，盗版必究 all right reserved，powered by GitbookLast Modified On： 2021-10-10 00:37:17 "},"java/juc/2021-09-28-(juc系列)ReentrantLock源码学习.html":{"url":"java/juc/2021-09-28-(juc系列)ReentrantLock源码学习.html","title":"(juc系列)ReentrantLock源码学习","keywords":"","body":"本文源码基于: JDK13 前言 上一篇文章讲了AQS的基本原理，其中两个关键的操作: 获取/释放. 依赖于子类的实现，本文就借着学习ReentrantLock的同时，继续巩固一下AQS. ReentrantLock支持公平锁以及非公平锁，实现源于内部不同的AQS子类同步器. 公平锁: 加锁时候按照线程申请顺序. 公平一点. 非公平锁: 不保证按照顺序. 性能好一点. Sync同步器 既然ReentrantLock是基于AQS实现的，那么肯定是继承了AQS来实现了一个同步器，首先就来看Sync的代码。 Sync继承自AQS,主要实现了两个方法: nonfairTryAcquire(int acquires) 为非公平锁开发的一个获取锁方法: /** * Performs non-fair tryLock. tryAcquire is implemented in * subclasses, but both need nonfair try for trylock method. */ @ReservedStackAccess final boolean nonfairTryAcquire(int acquires) { final Thread current = Thread.currentThread(); int c = getState(); if (c == 0) { if (compareAndSetState(0, acquires)) { setExclusiveOwnerThread(current); return true; } } else if (current == getExclusiveOwnerThread()) { int nextc = c + acquires; if (nextc 首先拿到当前的state值. 如果state值为0.说明锁当前空闲，那么通过cas进行更改state的值.同时将锁的占用线程改成当前线程. 如果state不等于0. 且当前线程是锁的占用线程，那就将state值加上此次申请的值. 之后设置state值. 这个步骤也就是ReentrantLock是可重入锁的关键， 当发现锁的占用线程，就是当前线程时，不是加锁失败，而是叠加的加锁. 当然释放时也需要释放对应多的次数. 不满足以上两个条件，加锁失败，返回false. tryRelease(int release) 解锁操作就不用区分公平还是非公平锁了. @ReservedStackAccess protected final boolean tryRelease(int releases) { int c = getState() - releases; if (Thread.currentThread() != getExclusiveOwnerThread()) throw new IllegalMonitorStateException(); boolean free = false; if (c == 0) { free = true; setExclusiveOwnerThread(null); } setState(c); return free; } . 如果当前线程不是持有锁的线程，抛出异常. 如果获取当年的state.减去此次要释放的后. 为0. 说明成功的释放锁了, 将锁的state置为0. 持有线程置为空。 如果不为0.设置新的状态，不修改持有线程，同时返回false.因为还没有完全释放锁. FairSync 公平锁，实现了公平锁的获取操作. /** * Fair version of tryAcquire. Don't grant access unless * recursive call or no waiters or is first. */ @ReservedStackAccess protected final boolean tryAcquire(int acquires) { final Thread current = Thread.currentThread(); int c = getState(); if (c == 0) { if (!hasQueuedPredecessors() && compareAndSetState(0, acquires)) { setExclusiveOwnerThread(current); return true; } } else if (current == getExclusiveOwnerThread()) { int nextc = c + acquires; if (nextc 获取当前state 如果state=0,说明锁空闲, 如果等待队列中也没有节点，同时获取锁成功，就将当前线程设置为锁的持有节点. 返回true. 如果锁不空闲，但是当前线程就是锁的持有线程，对state进行累加操作. 如果以上都不符合，加锁失败. 返回false. NonFairSync 非公平锁，他的获取操作，调用Sync类中的nonfairTryAcquire. ReentrantLock构造器 /** * Creates an instance of {@code ReentrantLock}. * This is equivalent to using {@code ReentrantLock(false)}. */ public ReentrantLock() { sync = new NonfairSync(); } /** * Creates an instance of {@code ReentrantLock} with the * given fairness policy. * * @param fair {@code true} if this lock should use a fair ordering policy */ public ReentrantLock(boolean fair) { sync = fair ? new FairSync() : new NonfairSync(); } 两个构造器，默认是非公平锁，可以指定创建一个公平锁. lock 加锁 加锁操作，调用链如下: 完全等同于AQS的acquire操作，只是在tryAcquire调用了ReentrantLock自己实现的方法. tryLock() 调用同步器NonFairSync的nonfairTryAcquire. 做一次获取的尝试，成功就返回true.否则返回false. tryLock(long timeout, TimeUnit unit) 带有自动超时的tryLock. unlock() 完全等同于AQS的release操作，只是在tryRelease调用了ReentrantLock自己实现的方法. 其他方法都是非核心方法，提供一些对于属性的读取，不再赘述. 总结 ReentrantLock基本上完全基于AQS的独占式加锁/解锁. 走的流程也是AQS的加锁/解锁流程， 只是在最核心的操作状态(State)上，依赖于ReentrantLock的实现而已. ReentrantLock定义了State状态的具体值，+1/-1分别代表什么操作， 也因为对State可以执行累加操作，而获得了可重入特性. 完. 完。 联系我 最后，欢迎关注我的个人公众号【 呼延十 】，会不定期更新很多后端工程师的学习笔记。 也欢迎直接公众号私信或者邮箱联系我，一定知无不言，言无不尽。 以上皆为个人所思所得，如有错误欢迎评论区指正。 欢迎转载，烦请署名并保留原文链接。 联系邮箱：huyanshi2580@gmail.com 更多学习笔记见个人博客或关注微信公众号 ------>呼延十 版权所有，盗版必究 all right reserved，powered by GitbookLast Modified On： 2021-10-10 00:37:17 "},"java/juc/2021-10-06-(juc系列)StampedLock源码学习.html":{"url":"java/juc/2021-10-06-(juc系列)StampedLock源码学习.html","title":"(juc系列)StampedLock源码学习","keywords":"","body":"本文源码基于: JDK13 简介 约等于翻译官方注释 一个有三种模式,来控制读/写访问的锁. StampedLock的状态由一个版本和模式来组成. 锁的申请方法返回一个stamp,释放锁的时候需要这个参数,如果传入的stamp和锁的状态不匹配,则释放失败. 三个模式分别是: 写 writeLock将以独占模式加锁,返回一个stamp可以用来调用unlockWrite以解锁.提供了超时版本和不超时的版本.如果锁被以写模式持有,没有读锁可以被获取,所有的乐观读锁的申请将会失败. 读 readLock提供非独占式的加锁,返回一个stamp可以用来调用unlockRead以解锁. 也提供了超时和不超时的版本. 乐观读 tryOptimisticRead返回一个非零的stamp,如果锁没有被写模式持有. 如果锁已经被写模式获取,validate返回true. 这个模式可以被认为是一个极其软性的读锁,可以在任何时候被一个写锁打断. 乐观读模式在很短的只读代码段中使用,经常能够减少争抢以提升吞吐量. 然后它是天生脆弱的. 乐观读部分应该值用来读取属性,然后只在局部变量中持有锁. 乐观读的属性读取可能会不一致,所以只在你足够熟悉数据结构可以检查一致性的时候使用它. 这个类还支持三种模式之间的转换. 比如: tryConvertToWriteLock尝试去升级模式,当以下任意一个条件符合时,返回一个可用的写stamp. 已经在写模式. 在读模式,但是没有其他读取者 在乐观读模式且锁可用. 这些形式设计来减少代码膨胀. StampedLocks设计,是实现一些内部的线程安全组件的工具. 他的使用依赖于对数据结构,对象,方法的熟悉. 这个锁是不可重入的,因此锁住的部分应该不要调用不知道的方法,可能会导致重复的申请锁.(如果你把stamp传递给其他方法,那你可以使用或者升级锁). 读模式的锁使用依赖于使用的代码片段是无副作用的. 未经验证的乐观读模式不要调用不熟悉的方法,可能会导致不一致. stamps表述能力有限,且没有加密. stamp的值可能会在一系列操作后被回收. 一个stamp不要持有太长时间,因为可能会验证失败. StampedLock是可序列化的,但是会反序列化成最初的未加锁状态,因此不能用来做远程加锁. 像Semaphore,但是和大多数锁的实现不一样,StampedLock没有持有者的概念,一个线程申请的锁可能会被其他线程释放掉. StampedLock锁的调度策略不一致,更加喜欢读锁而不是写锁.所有的try方法都是尽力而不是一定会遵从调度策略. 获取锁的try相关方法返回0,不表达更多信息,随后的申请锁可能会成功. 因为支持多种模式的协调使用,这个类不直接实现Lock或者ReadWriteLock接口. 然而,一个StampedLock可以当做一个读锁,写锁,或者读写锁. 简单的使用案例: 一个类维护简单的二维点. class Point { private double x, y; private final StampedLock sl = new StampedLock(); // an exclusively locked method void move(double deltaX, double deltaY) { long stamp = sl.writeLock(); try { x += deltaX; y += deltaY; } finally { sl.unlockWrite(stamp); } } // a read-only method // upgrade from optimistic read to read lock double distanceFromOrigin() { long stamp = sl.tryOptimisticRead(); try { retryHoldingLock: for (;; stamp = sl.readLock()) { if (stamp == 0L) continue retryHoldingLock; // possibly racy reads double currentX = x; double currentY = y; if (!sl.validate(stamp)) continue retryHoldingLock; return Math.hypot(currentX, currentY); } } finally { if (StampedLock.isReadLockStamp(stamp)) sl.unlockRead(stamp); } } // upgrade from optimistic read to write lock void moveIfAtOrigin(double newX, double newY) { long stamp = sl.tryOptimisticRead(); try { retryHoldingLock: for (;; stamp = sl.writeLock()) { if (stamp == 0L) continue retryHoldingLock; // possibly racy reads double currentX = x; double currentY = y; if (!sl.validate(stamp)) continue retryHoldingLock; if (currentX != 0.0 || currentY != 0.0) break; stamp = sl.tryConvertToWriteLock(stamp); if (stamp == 0L) continue retryHoldingLock; // exclusive access x = newX; y = newY; return; } } finally { if (StampedLock.isWriteLockStamp(stamp)) sl.unlockWrite(stamp); } } // Upgrade read lock to write lock void moveIfAtOrigin(double newX, double newY) { long stamp = sl.readLock(); try { while (x == 0.0 && y == 0.0) { long ws = sl.tryConvertToWriteLock(stamp); if (ws != 0L) { stamp = ws; x = newX; y = newY; break; } else { sl.unlockRead(stamp); stamp = sl.writeLock(); } } } finally { sl.unlock(stamp); } } } 这个类管理了一个二维的点.提供了以下几个方法: move 独占式加锁,加个写锁,然后把当前点移到给定位置. distanceFromOrigin 只读方法,从乐观读升级到读锁.首先申请一个乐观读锁,如果乐观读锁不合法,将申请读锁.之后计算当前点到原点的距离. moveIfAtOrigin 从乐观读锁升级到写锁,首先申请乐观读, 如果合法且当前点再原地,就升级到写锁,将当前点移动到给定位置. 如果不合法,就升级写锁,移动点. moveIfAtOrigin2 从读锁升级到写锁,先申请个读锁,如果当前点在原地,就申请个写锁,将当前点移动到给定位置. 如果升级失败,就直接申请个写锁,移动点. 有一说一,没太懂会在什么场景使用这个类. 源码学习 主要的属性 // 一堆常量 // 读线程的个数占有低7位 private static final int LG_READERS = 7; // 读线程个数每次增加的单位 private static final long RUNIT = 1L; // 写线程个数所在的位置 private static final long WBIT = 1L 一堆常量和状态,队列. 这个类没有使用AQS实现,而是自己维护了相似的结构,一个state变量和内部的队列. 而且根据常量可以看出来,内部状态使用bit来维护相关的信息. 构造方法 public StampedLock() { state = ORIGIN; } 将状态设置为初始的,未加锁状态. state=256. 写模式 writeLock 获取写锁 @ReservedStackAccess public long writeLock() { long next; return ((next = tryWriteLock()) != 0L) ? next : acquireWrite(false, 0L); } 首先调用trWriteLock,如果获取成功,则返回stamp.否则调用acquireWrite. trWriteLock 尝试拿一下写锁 // 共用的方法 @ReservedStackAccess public long tryWriteLock() { long s; return (((s = state) & ABITS) == 0L) ? tryWriteLock(s) : 0L; } // 内部真实实现 private long tryWriteLock(long s) { // assert (s & ABITS) == 0L; long next; if (casState(s, next = s | WBIT)) { VarHandle.storeStoreFence(); return next; } return 0L; } tryWriteLock()方法中,首先判断((s = state) & ABITS) == 0L). 如果不等于0意味着什么呢? 不等于0,意味着当前状态值小于255,也就是低7位有1.意味着当前锁已经被持有,直接返回0. 否则的话调用tryWriteLock(s). tryWriteLock(s)方法中,首先使用CAS将state值的第7位置为1. 因为WBIT=1. 如果成功, 返回加锁后的state值. 如果失败,返回0. acquireWrite 阻塞/自旋获取写锁 写锁申请时,首先尝试加锁,如果成功了,就返回加锁后的状态,如果没有成功,就会调用这个方法了. private long acquireWrite(boolean interruptible, long deadline) { WNode node = null, p; // 自旋 for (int spins = -1;;) { // spin while enqueuing long m, s, ns; // 没有写锁/读锁,尝试加写锁,成功就返回 if ((m = (s = state) & ABITS) == 0L) { if ((ns = tryWriteLock(s)) != 0L) return ns; } else if (spins 0) { --spins; Thread.onSpinWait(); } else if ((p = wtail) == null) { // initialize queue WNode hd = new WNode(WMODE, null); if (WHEAD.weakCompareAndSet(this, null, hd)) wtail = hd; } else if (node == null) node = new WNode(WMODE, p); else if (node.prev != p) node.prev = p; else if (WTAIL.weakCompareAndSet(this, p, node)) { p.next = node; break; } } boolean wasInterrupted = false; for (int spins = -1;;) { WNode h, np, pp; int ps; if ((h = whead) == p) { if (spins 0; --k) { // spin at head long s, ns; if (((s = state) & ABITS) == 0L) { if ((ns = tryWriteLock(s)) != 0L) { whead = node; node.prev = null; if (wasInterrupted) Thread.currentThread().interrupt(); return ns; } } else Thread.onSpinWait(); } } else if (h != null) { // help release stale waiters WNode c; Thread w; while ((c = h.cowait) != null) { if (WCOWAIT.weakCompareAndSet(h, c, c.cowait) && (w = c.thread) != null) LockSupport.unpark(w); } } if (whead == h) { if ((np = node.prev) != p) { if (np != null) (p = np).next = node; // stale } else if ((ps = p.status) == 0) WSTATUS.compareAndSet(p, 0, WAITING); else if (ps == CANCELLED) { if ((pp = p.prev) != null) { node.prev = pp; pp.next = node; } } else { long time; // 0 argument to park means no timeout if (deadline == 0L) time = 0L; else if ((time = deadline - System.nanoTime()) 这是个支持中断及超时的一个申请获取写锁的方法,虽然刚才的方法调用时,不支持中断,不超时.但是我们直接看下完整体的代码是怎么写的. 首先涉及到的是WNode内部类,他是一个类似于AQS中的队列节点的类,不展开了. 首先是入队的一次自旋: 如果当前没有读锁/写锁,尝试加写锁,成功就返回. 如果旋转次数小于0,就算一个旋转次数, (如果当前锁是写锁并且队列为空,代表快轮到自己了. 就根据cpu计算一个次数,否则旋转0次. 如果旋转次数大于0,就稍等一会.选择次数减一. 如果等待队列的尾巴为空, 说明没有初始化, 将当前线程搞成尾巴放入队列. 如果还没有为当前线程创建节点,创建个节点. 如果将当前节点连接在等待队列的尾巴成功,就退出这个循环. 第二个自旋的循环来了,目的是阻塞且等待唤醒: 如果队列的头和尾相同,说明队列中只有当前节点的前置节点在等待,快轮到自己了. 初始化旋转次数, 旋转次数小于0,根据cpu计算一个旋转次数.否则将旋转次数扩大一倍. 开始自旋, 判断是否有读锁/写锁,没有就尝试加写锁,成功就返回. 如果队列头和尾不同,且队头不为空. 循环将所有等待者唤醒. 如果队头还是原来的队头,说明什么都还没变 如果尾节点有变化, 更新变化, 当前节点放在队尾 如果队尾的状态是0,改成等待中. 如果队尾的状态是取消了,往前挪一个. 如果超时了,取消等待 阻塞当前线程,等待唤醒. 好复杂啊.... 简单总结一下: 第一次自旋, 如果队列为空,就算一个自旋次数,开始尝试获取锁,否则直接入队开始第二段自旋. 第二段自旋, 如果队列只有一个元素,说明快到自己了,算一个自旋次数开始自旋.也就是第三次自旋. 否则的话, 就休眠等待唤醒. unlockWrite 释放写锁 public void unlockWrite(long stamp) { if (state != stamp || (stamp & WBIT) == 0L) throw new IllegalMonitorStateException(); unlockWriteInternal(stamp); } 检查stamp的合法性,必须和锁的状态一致,且是写锁,即第7位必须为1. 之后调用unlockWriteInternal. // 内部的释放写锁 private long unlockWriteInternal(long s) { long next; WNode h; STATE.setVolatile(this, next = unlockWriteState(s)); if ((h = whead) != null && h.status != 0) release(h); return next; } // 计算释放后的状态 private static long unlockWriteState(long s) { return ((s += WBIT) == 0L) ? ORIGIN : s; } // 真正的释放写锁 private void release(WNode h) { if (h != null) { WNode q; Thread w; WSTATUS.compareAndSet(h, WAITING, 0); if ((q = h.next) == null || q.status == CANCELLED) { for (WNode t = wtail; t != null && t != h; t = t.prev) if (t.status 这段逻辑里,涉及到3个方法,一个一个说. unlockWriteInternal 计算释放后的状态. 如果头结点不为空且头结点的状态不为0, 就调用release. 之后返回释放后的状态. unlockWriteState 计算下解锁后的状态,返回即可. 注意解锁的操作是: 对原有的值+WBIT. 由于加锁就是第7位为1.再加1导致进位,相当于将第7位置为0了. 解锁成功. release(WNode) 找到头结点的下一个, 唤醒它. 读模式 readLock() 读模式加锁 public long readLock() { long s, next; // bypass acquireRead on common uncontended case return (whead == wtail && ((s = state) & ABITS) 队头等于队尾,等待队列为空. 当前读锁的个数小于最大值126. cas更新状态, 给已有的数字+1,代表多了一个读锁. 成功. 以上三个状态全部满足,返回更新后的状态,代表获取了一个读锁. 如果有一个不满足,走acquireRead. acquireRead 阻塞式获取读锁 private long acquireRead(boolean interruptible, long deadline) { boolean wasInterrupted = false; WNode node = null, p; for (int spins = -1;;) { WNode h; if ((h = whead) == (p = wtail)) { for (long m, s, ns;;) { if ((m = (s = state) & ABITS) = WBIT) { if (spins > 0) { --spins; Thread.onSpinWait(); } else { if (spins == 0) { WNode nh = whead, np = wtail; if ((nh == h && np == p) || (h = nh) != (p = np)) break; } spins = SPINS; } } } } if (p == null) { // initialize queue WNode hd = new WNode(WMODE, null); if (WHEAD.weakCompareAndSet(this, null, hd)) wtail = hd; } else if (node == null) node = new WNode(RMODE, p); else if (h == p || p.mode != RMODE) { if (node.prev != p) node.prev = p; else if (WTAIL.weakCompareAndSet(this, p, node)) { p.next = node; break; } } else if (!WCOWAIT.compareAndSet(p, node.cowait = p.cowait, node)) node.cowait = null; else { for (;;) { WNode pp, c; Thread w; if ((h = whead) != null && (c = h.cowait) != null && WCOWAIT.compareAndSet(h, c, c.cowait) && (w = c.thread) != null) // help release LockSupport.unpark(w); if (Thread.interrupted()) { if (interruptible) return cancelWaiter(node, p, true); wasInterrupted = true; } if (h == (pp = p.prev) || h == p || pp == null) { long m, s, ns; do { if ((m = (s = state) & ABITS) 0) { node = null; // throw away break; } if (deadline == 0L) time = 0L; else if ((time = deadline - System.nanoTime()) = WBIT && --k 又是超级一大串代码.....不过有了之前的经验, 可能会轻松一点. 首先是第一次自旋: 队头等于队尾, 说明等待队列为空,很快就可以到自己. 如果申请读锁成功, 则直接返回. 如果当前有写锁,就递减自旋次数,等待. 如果自旋次数为0了,看看是再自旋一会还是退出循环. 如果队列没有初始化, 则初始化队列,将当前节点置为尾节点. 如果当前节点没有初始化, 初始化当前节点. 如果头点击发生了变化, 更新下相关信息. 进入嵌套的第二次自旋: 如果头结点不为空且有等待节点,帮助唤醒等待节点. 如果头结点就是当前节点的前置节点,或者头结点是当前节点, 说明快要轮到自己了. 进入嵌套的第三次自旋,不断的尝试获取读锁,成功就返回. 如果头结点没有变化,当前节点的前置节点也没变, 就安心的阻塞等待一会,这里是支持超时机制的. 进入第二个大的循环体: 和第一段很像, 但是是单独给第一个读线程设计的. 如果头结点等于为节点,说明快到自己了.初始化自选次数然后不断尝试获取锁.期间如果发现锁被别的写锁获取了,就退出循环. 如果头结点不为空,帮助其唤醒他的等待者. 如果头结点有变化, 更新相关的信息. 如果尾节点状态为0, 改成waiting. 如果尾节点是取消状态, 跳过该节点. 之后计算超时时间,让当前线程休眠等待唤醒. tryIncReaderOverflow 尝试递增一个读锁 private long tryIncReaderOverflow(long s) { // assert (s & ABITS) >= RFULL; if ((s & ABITS) == RFULL) { if (casState(s, s | RBITS)) { ++readerOverflow; STATE.setVolatile(this, s); return s; } } else if ((LockSupport.nextSecondarySeed() & OVERFLOW_YIELD_RATE) == 0) Thread.yield(); else Thread.onSpinWait(); return 0L; } 如果读锁满了.更新状态,计数. unlockRead 读锁解锁 public void unlockRead(long stamp) { long s, m; WNode h; while (((s = state) & SBITS) == (stamp & SBITS) && (stamp & RBITS) > 0L && ((m = s & RBITS) > 0L)) { if (m 首先对stamped进行检查,如果OK.进行递减,更新状态. 然后唤醒下一个节点. 如果超过最大可获取读锁数,尝试递减,成功返回. 其他情况抛出异常. tryDecReaderOverFlow private long tryDecReaderOverflow(long s) { // assert (s & ABITS) >= RFULL; if ((s & ABITS) == RFULL) { if (casState(s, s | RBITS)) { int r; long next; if ((r = readerOverflow) > 0) { readerOverflow = r - 1; next = s; } else next = s - RUNIT; STATE.setVolatile(this, next); return next; } } else if ((LockSupport.nextSecondarySeed() & OVERFLOW_YIELD_RATE) == 0) Thread.yield(); else Thread.onSpinWait(); return 0L; } 尝试递减读锁,如果溢出的话,溢出数量减1. 如果没有溢出,返回状态值. 乐观读模式 tryOptimisticRead 尝试获取乐观读锁 public long tryOptimisticRead() { long s; return (((s = state) & WBIT) == 0L) ? (s & SBITS) : 0L; } 返回一个stamp,稍后用来验证, 如果当前已经是写锁了,返回0. validate 验证stamp的正确性 public boolean validate(long stamp) { VarHandle.acquireFence(); return (stamp & SBITS) == (state & SBITS); } 约等于直接验证相等性.区别不大. tryConvertToWriteLock public long tryConvertToWriteLock(long stamp) { long a = stamp & ABITS, m, s, next; while (((s = state) & SBITS) == (stamp & SBITS)) { if ((m = s & ABITS) == 0L) { if (a != 0L) break; if ((next = tryWriteLock(s)) != 0L) return next; } else if (m == WBIT) { if (a != m) break; return stamp; } else if (m == RUNIT && a != 0L) { if (casState(s, next = s - RUNIT + WBIT)) { VarHandle.storeStoreFence(); return next; } } else break; } return 0L; } 尝试转换成一个写锁. 如果状态等于给定的stamp. 则原子性的进行以下操作: 如果stamp表示持有一个写锁. 直接返回. 如果持有读锁,且写锁是可用的,释放读锁然后申请写锁进行返回. 如果是一个乐观的读锁, 如果锁立即可用,就返回一个写锁. 这个方法永远返回0. tryConvertToReadLock 尝试转换成一个读锁 public long tryConvertToReadLock(long stamp) { long a, s, next; WNode h; while (((s = state) & SBITS) == (stamp & SBITS)) { if ((a = stamp & ABITS) >= WBIT) { // write stamp if (s != stamp) break; STATE.setVolatile(this, next = unlockWriteState(s) + RUNIT); if ((h = whead) != null && h.status != 0) release(h); return next; } else if (a == 0L) { // optimistic read stamp if ((s & ABITS) 如果锁状态和给定stamp相同,执行以下操作: 如果stamp表示持有的是一个写锁, 释放写锁,申请一个读锁进行返回. 如果持有的是一个读锁.直接返回. 如果持有的是一个乐观读锁, 如果锁立即可用的情况下, 申请一个读锁返回. 这个方法永远返回0. tryConvertToOptimisticRead 尝试转换成乐观读锁 public long tryConvertToOptimisticRead(long stamp) { long a, m, s, next; WNode h; VarHandle.acquireFence(); while (((s = state) & SBITS) == (stamp & SBITS)) { if ((a = stamp & ABITS) >= WBIT) { // write stamp if (s != stamp) break; return unlockWriteInternal(s); } else if (a == 0L) // already an optimistic read stamp return stamp; else if ((m = s & ABITS) == 0L) // invalid read stamp break; else if (m 如果锁状态和给定stamp相同,执行以下操作: 如果stamp表示正在持有一个锁, 释放他, 返回一个乐观的stamp 如果当前持有的就是乐观读锁,直接返回. 其他方法 除此之外,还提供了一些用于判断当前锁状态,以及给定的stamp状态的方法. 比如: 方法 作用 isWriteLocked 是否是写锁 isReadLocked 是否是读锁 isWriteLockStamp 是否是写锁的stamp isReadLockStamp 是否是读锁的stamp isLockStamp 是否是个锁的stamp isOptimisticReadStamp 是否是乐观读的stamp isOptimisticReadStamp 获取读锁的数量 总结 StampedLock是一个支持多种模式的,性能更好的读写锁. 他不是由AQS实现,而是自己实现的内部状态及等待队列的管理. 对内部状态的定义也是自己完成的. 内部的state值. 按位进行管理. 低位第7位代表写锁,低位的6位数字代表读锁以及读锁的个数. 由于第八位只有一个bit位来表示是否获取了写锁,因此是不可重入的. 代码中采用了大量的自旋操作,因此在竞争较小的时候性能会好一些,竞争太大的时候,会比较浪费cpu. 完。 联系我 最后，欢迎关注我的个人公众号【 呼延十 】，会不定期更新很多后端工程师的学习笔记。 也欢迎直接公众号私信或者邮箱联系我，一定知无不言，言无不尽。 以上皆为个人所思所得，如有错误欢迎评论区指正。 欢迎转载，烦请署名并保留原文链接。 联系邮箱：huyanshi2580@gmail.com 更多学习笔记见个人博客或关注微信公众号 ------>呼延十 版权所有，盗版必究 all right reserved，powered by GitbookLast Modified On： 2021-10-17 02:51:50 "},"java/juc/2021-10-12-(juc系列)Exchanger源码阅读.html":{"url":"java/juc/2021-10-12-(juc系列)Exchanger源码阅读.html","title":"(juc系列)Exchanger源码阅读","keywords":"","body":"简介 一个用于让线程之间配对和交换元素的同步点. 每个线程拿出一个元素，匹配另外一个伙伴线程, 互相交换. Exchanger可以看做是一个双向的SynchronousQueue. 这个类在遗传算法和流水线设计时很有用. 示例 这个类使用Exchanger来在线程之间交换缓冲区. class FillAndEmpty { Exchanger exchanger = new Exchanger<>(); DataBuffer initialEmptyBuffer = ... a made-up type DataBuffer initialFullBuffer = ... class FillingLoop implements Runnable { public void run() { DataBuffer currentBuffer = initialEmptyBuffer; try { while (currentBuffer != null) { addToBuffer(currentBuffer); if (currentBuffer.isFull()) currentBuffer = exchanger.exchange(currentBuffer); } } catch (InterruptedException ex) { ... handle ... } } } class EmptyingLoop implements Runnable { public void run() { DataBuffer currentBuffer = initialFullBuffer; try { while (currentBuffer != null) { takeFromBuffer(currentBuffer); if (currentBuffer.isEmpty()) currentBuffer = exchanger.exchange(currentBuffer); } } catch (InterruptedException ex) { ... handle ...} } } void start() { new Thread(new FillingLoop()).start(); new Thread(new EmptyingLoop()).start(); } } 一个生产者和一个消费者通过Exchanger来交换缓冲区，以确保消费者可以不断拿到满的缓冲区，生产者不断拿到空的缓冲区. 源码阅读 构造方法 public Exchanger() { participant = new Participant(); } 初始化一个Participant. 这个类是一个ThreadLocal的子类.负责为每个线程存储一个对应的Node. static final class Participant extends ThreadLocal { public Node initialValue() { return new Node(); } } Node节点的定义: @jdk.internal.vm.annotation.Contended static final class Node { int index; // Arena index 在数组中的下标 int bound; // Last recorded value of Exchanger.bound // 上一个Exchanger.bound值 int collides; // Number of CAS failures at current bound CAS失败次数 int hash; // Pseudo-random for spins // 自旋随机次数 Object item; // This thread's current item // 线程对应的item volatile Object match; // Item provided by releasing thread // 匹配上的值 volatile Thread parked; // Set to this thread when parked, else null // 阻塞线程 } 可以看到，一个线程绑定一个节点，记录了他在数组中的下标，自身携带的item.以及最终匹配给他的item等等. exchange(V v) 这个方法还有另外一个带有超时时间的版本，就不多说那个了. public V exchange(V x) throws InterruptedException { Object v; Node[] a; Object item = (x == null) ? NULL_ITEM : x; // translate null args if (((a = arena) != null || (v = slotExchange(item, false, 0L)) == null) && (Thread.interrupted() || // disambiguates null return (v = arenaExchange(item, false, 0L)) == null)) throw new InterruptedException(); return (v == NULL_ITEM) ? null : (V)v; } 这个交换方法的逻辑比较清晰. 如果当前的竞技场(就是交换场所，数组版本的)为空，那就在slot交换，调用slotExchange. 否则调用arenaExchange. 在数组中进行匹配，交换. slotExchange 如果目前只有一个等待交换的线程，也就是没有产生竞争，单个slot即可以完成交换操作. private final Object slotExchange(Object item, boolean timed, long ns) { // 当前线程的节点 Node p = participant.get(); // 当前线程 Thread t = Thread.currentThread(); // 被中断了直接返回null if (t.isInterrupted()) // preserve interrupt status so caller can recheck return null; for (Node q;;) { // 已有slot在等待交换了 if ((q = slot) != null) { // 置空SLOT, 拿到交换后的值，并唤醒对应的线程 if (SLOT.compareAndSet(this, q, null)) { Object v = q.item; q.match = item; Thread w = q.parked; if (w != null) LockSupport.unpark(w); return v; } // create arena on contention, but continue until slot null // 有竞争了，创建一个数组 if (NCPU > 1 && bound == 0 && BOUND.compareAndSet(this, 0, SEQ)) arena = new Node[(FULL + 2) 1) ? SPINS : 1; Object v; while ((v = p.match) == null) { if (spins > 0) { h ^= h >> 3; h ^= h >> 1) - 1)) == 0) Thread.yield(); } else if (slot != p) spins = SPINS; else if (!t.isInterrupted() && arena == null && (!timed || (ns = end - System.nanoTime()) > 0L)) { p.parked = t; if (slot == p) { if (ns == 0L) LockSupport.park(this); else LockSupport.parkNanos(this, ns); } p.parked = null; } else if (SLOT.compareAndSet(this, p, null)) { v = timed && ns 当一个线程调用exchange,如果当前没有什么竞争，通过slot来进行交换时，可能面对两种可能: 当前Exchanger内部为空的，直接将当前线程放在slot，阻塞等待匹配 当前slot不为空，直接与slot交换元素，返回值. arenaExchange 通过数组进行交换，用于当前竞争很严重的时候. private final Object arenaExchange(Object item, boolean timed, long ns) { Node[] a = arena; int alen = a.length; // 当前线程的节点 Node p = participant.get(); for (int i = p.index;;) { // access slot at i int b, m, c; int j = (i = alen) j = alen - 1; // 从对应的下标取一个slot出来 Node q = (Node)AA.getAcquire(a, j); if (q != null && AA.compareAndSet(a, j, q, null)) { // 对应的slot有值，尝试交换成功.返回交换后的值 Object v = q.item; // release q.match = item; Thread w = q.parked; if (w != null) LockSupport.unpark(w); return v; } // 对应的slot没有值，且下标符合要求，就将当前节点放在slot上, 自选等待匹配唤醒. else if (i 0) { h ^= h >> 3; h ^= h >> 1) - 1)) == 0) Thread.yield(); // two yields per wait } else if (AA.getAcquire(a, j) != p) spins = SPINS; // releaser hasn't set match yet else if (!t.isInterrupted() && m == 0 && (!timed || (ns = end - System.nanoTime()) > 0L)) { p.parked = t; // minimize window if (AA.getAcquire(a, j) == p) { if (ns == 0L) LockSupport.park(this); else LockSupport.parkNanos(this, ns); } p.parked = null; } else if (AA.getAcquire(a, j) == p && AA.compareAndSet(a, j, p, null)) { if (m != 0) // try to shrink BOUND.compareAndSet(this, b, b + SEQ - 1); p.item = null; p.hash = h; i = p.index >>>= 1; // descend if (Thread.interrupted()) return null; if (timed && m == 0 && ns 根据计算的下标，从数组中取一个位置， 如果该位置有值，就将当前节点和该位置交换. 该位置没有值，且下标合理，就将当前节点放到该位置上 该位置没有值，下标不合理，就重新计算下标 总结 Exchanger的作用，原理都比较明了，就是代码细节比较难懂. 完。 联系我 最后，欢迎关注我的个人公众号【 呼延十 】，会不定期更新很多后端工程师的学习笔记。 也欢迎直接公众号私信或者邮箱联系我，一定知无不言，言无不尽。 以上皆为个人所思所得，如有错误欢迎评论区指正。 欢迎转载，烦请署名并保留原文链接。 联系邮箱：huyanshi2580@gmail.com 更多学习笔记见个人博客或关注微信公众号 ------>呼延十 版权所有，盗版必究 all right reserved，powered by GitbookLast Modified On： 2021-10-17 02:51:50 "},"java/juc/2021-09-30-(juc系列)Semaphore源码阅读.html":{"url":"java/juc/2021-09-30-(juc系列)Semaphore源码阅读.html","title":"(juc系列)Semaphore源码阅读","keywords":"","body":"本文源码基于: JDK13 前言 为了巩固AQS.　看一下Semaphore的源码. 简介 大部分都是直接翻译的官方代码注释，嘻嘻 一个计数的信号量. 概念上讲，信号量维护了一个许可证的集合. 每一个获取操作可能会阻塞，直到有许可证可用. 每一个释放操作，会添加一个许可证. 相当于隐式的释放一个阻塞的获取者. 信号量经常用于，　严格数量的线程访问资源. 比如下面是一个例子: 使用信号量来控制对一个对象池的访问. (个人感觉，更像是使用信号量来实现一个对象池) class Pool { private static final int MAX_AVAILABLE = 100; private final Semaphore available = new Semaphore(MAX_AVAILABLE, true); public Object getItem() throws InterruptedException { available.acquire(); return getNextAvailableItem(); } public void putItem(Object x) { if (markAsUnused(x)) available.release(); } // Not a particularly efficient data structure; just for demo protected Object[] items = ... whatever kinds of items being managed protected boolean[] used = new boolean[MAX_AVAILABLE]; protected synchronized Object getNextAvailableItem() { for (int i = 0; i 在获取每一个Item之前，必须先从信号量获取一个许可证，保证有一个对象是可用的。 当线程使用完该对象，将其返回给对象池时，　同时返回给信号量一个许可证. 允许其他线程申请该对象. 注意: 如果没有acquire的线程，那么将阻止一个对象返还给对象池. 信号量封装了对对象吃的访问同步控制，但是池子本身的同步需要自己实现. 如果将一个信号量初始化为只有1个. 因为只有一个可用的许可证，所以信号量使用起来就像一个独占式的锁.　就是经常说的binary semaphore. 因为他只有两种状态: 一个许可证可用，　没有许可证可用. 当使用binary semaphore时, 他有以下的特性: \"锁\"可以被除了锁的持有者之外的线程释放.(因为信号量没有拥有者的概念) 这在某些特殊的上下文中是有用的，　比如死锁的恢复. 构造方法可以接受一个fairness的参数，如果设置为false. 这个类不保证线程申请许可证的公平性. 一个线程申请许可证，可能比已经在等待的线程拿到的早. 当公平性设置为true. 线程获取许可证的顺序与他们调用acquire的顺序一致. 一般来讲，　信号量用来控制资源方法时，　应该被初始化为公平的。以保证没有线程饿死. 当使用信号量做其他类型的同步控制时，非公平顺序的吞吐量优势经常是比公平性更加重要的。 这个类还提供了一些方便的方法，比如一次性申请多个许可证的acquire和release方法. 这些方法比使用循环获取有更好的性能. 然而，他们不保证任何偏好顺序，比如，如果线程A调用了acquire(3), 线程B调用了acquire(2). 即将有两个许可证变得可用，没有保证说线程B会获取这两个许可证。除非线程B是首先进行申请的，且当前信号量是公平模式. 源码 Sync同步器 首先当前是最核心的同步器的实现了. /** * Synchronization implementation for semaphore. Uses AQS state * to represent permits. Subclassed into fair and nonfair * versions. */ abstract static class Sync extends AbstractQueuedSynchronizer { private static final long serialVersionUID = 1192457210091910933L; Sync(int permits) { setState(permits); } final int getPermits() { return getState(); } // 非公平模式的获取 final int nonfairTryAcquireShared(int acquires) { for (;;) { // 剩余 int available = getState(); // 减去此次获取的值 int remaining = available - acquires; // 没有剩余了. 或者获取成功，返回剩余数量. // 这里的两个条件，一个是成功，一个是失败. if (remaining current) // underflow throw new Error(\"Permit count underflow\"); if (compareAndSetState(current, next)) return; } } final int drainPermits() { for (;;) { int current = getState(); if (current == 0 || compareAndSetState(current, 0)) return current; } } } 构造方法 初始化时提供一个许可证的数量. 将其设置为AQS的State. nonfaireTryAcquireShared(int acquire) 非公平模式的获取许可证. 首先获取当前剩余数量，减去此次申请的值后， 如果小于0.　获取失败，返回缺少的数量. 如果大于0. 尝试更改状态，成功即返回. tryReleaseShared(int release) 首先获取当前剩余数量，加上此次释放的数量. 如果溢出，报错. 之后进行CAS的设置状态操作. 其他两个非公用API用到的时候再看. NonfaireSync 同步器 非公平模式的同步器. /** * NonFair version */ static final class NonfairSync extends Sync { private static final long serialVersionUID = -2694183684443567898L; NonfairSync(int permits) { super(permits); } protected int tryAcquireShared(int acquires) { return nonfairTryAcquireShared(acquires); } } 只是将AQS的tryAcquireShared申请共享锁指向了在Sync中实现的非公平模式获取. FairSync 公平模式同步器 /** * Fair version */ static final class FairSync extends Sync { private static final long serialVersionUID = 2014338818796000944L; FairSync(int permits) { super(permits); } protected int tryAcquireShared(int acquires) { for (;;) { if (hasQueuedPredecessors()) return -1; int available = getState(); int remaining = available - acquires; if (remaining 公平模式的同步器，实现了公平模式的获取许可证. 如果已经有队列中的节点，直接返回获取失败. 其他和非公平模式一样，这样可以确保获取许可证的顺序和申请顺序是一致的. 构造方法 有点像ReentrantLock的构造方法，可以指定公平或者非公平模式. 此外传入一个许可证的数量. acquire系列. acquire() 获取许可证，调用AQS的acquireSharedInterruptibly. acquireUninterruptibly(). 忽略中断的获取许可证. tryAcquire(). 尝试获取一次许可证 tryAcquire(long timeout, TimeUnit unit). 带有超时的尝试获取许可证 acquire(int permits). 一次性获取多个许可证. ...上面方法的多个许可证版本 release系列 release() 释放一个许可证. 调用AQS的releaseShared. release(int permits). 一次性释放多个许可证. 总结 这是对AQS的又一个直接应用. 那么他是怎么定义State的呢? 初始化State为许可证的数量. 加锁，递减State. 只要State仍然大于0. 加锁即视为成功. 解锁, 递增State. 除了溢出肯定会成功. 完。 联系我 最后，欢迎关注我的个人公众号【 呼延十 】，会不定期更新很多后端工程师的学习笔记。 也欢迎直接公众号私信或者邮箱联系我，一定知无不言，言无不尽。 以上皆为个人所思所得，如有错误欢迎评论区指正。 欢迎转载，烦请署名并保留原文链接。 联系邮箱：huyanshi2580@gmail.com 更多学习笔记见个人博客或关注微信公众号 ------>呼延十 版权所有，盗版必究 all right reserved，powered by GitbookLast Modified On： 2021-10-10 00:37:17 "},"java/juc/2021-10-08-(juc系列)ReentrantReadWriteLock源码学习.html":{"url":"java/juc/2021-10-08-(juc系列)ReentrantReadWriteLock源码学习.html","title":"(juc系列)ReentrantReadWriteLock源码学习","keywords":"","body":"本文源码基于: JDK13 简介 这个类是一个ReadWriteLock的实现类，实现了类似于ReentrantLock的语义. 这个类有以下特性: 获取顺序 这个类没有给读写者强加获取锁的顺序，但是他实现了一个可选的公平策略。 非公平模式(默认模式 当创建一个非公平的锁，获取读锁，写锁的顺序是没有指定的. 满足可重入性的约束. 一个非公平锁，可能会因为不断的争执，而无限期的推迟一个或者多个读锁/写锁的获取线程，但是通常来讲拥有更好的吞吐量. 公平模式 当创建一个公平所，线程竞争使用一个到达序的策略. 当前持有锁的线程释放锁，等待时间最长的单个写入线程就拿到写锁，　或者如果有一组读线程， 等待的时间比所有的写线程都长，那么这组读线程将拿到读锁. 如果当前锁正在被写锁持有，或者有一个等待的写线程，公平模式下的获取读锁的请求将会被阻塞. 直到等待时间最长的写线程拿到锁并释放. 当然，如果一个等待中的写线程放弃了，让一个或者多少读线程成为了队列中等待最久的，　这些读线程将拿到读锁. 如果一个写线程尝试获取锁，除非当前所有的读锁和写锁都是空闲的，　才能拿到锁，意味着当前不能有任何的等待线程. 可重入性 这个锁允许所有的读线程和写线程重复的申请对应的锁，就像ReentrantLock一样. 不是重入的读线程将被正在持有锁的写线程阻塞. 一个写线程可以获取读锁. 在很多应用中，可重入性很有用，当写线程持有写锁，在某些调用或者回调方法中执行读操作。如果一个读线程尝试去申请写锁，永远不会成功. 锁降级 支持从写锁降级到读锁，但是从读锁升级到写锁是不允许的. 支持Condition 写锁提供了一个Condition的实现，他的行为模式和写锁一样. 就像ReentrantLock中的Condition一样.读锁不支持Condition. 仪表盘 这个类支持查看锁被持有还是竞争中，这些方法用于监视系统状态，而不是用于同步控制. 这个锁的序列化和内置锁的行为方式相同，反序列化的锁处于解锁状态，无论序列化时状态如何. 简单的使用案例. 代码片段简单的展示了在更新cache之后如何进行锁的降级. class CachedData { Object data; boolean cacheValid; final ReentrantReadWriteLock rwl = new ReentrantReadWriteLock(); void processCachedData() { // 读锁 rwl.readLock().lock(); if (!cacheValid) { // Must release read lock before acquiring write lock // 释放读锁 rwl.readLock().unlock(); // 申请写锁 rwl.writeLock().lock(); try { // Recheck state because another thread might have // acquired write lock and changed state before we did. if (!cacheValid) { // 新数据的赋值 data = ... cacheValid = true; } // Downgrade by acquiring read lock before releasing write lock // 降级成读锁 rwl.readLock().lock(); } finally { // 释放写锁，还持有读锁 rwl.writeLock().unlock(); // Unlock write, still hold read } } try { use(data); } finally { rwl.readLock().unlock(); } } } 首先获取读锁. 释放读锁，同时申请写锁. 完成写操作后，申请读锁. 释放写锁，持有读锁 完全使用完成后，释放读锁。 ReentrantReadWriteLock可以用在一些集合类中，用来提升并发性. 只有当集合预期很大，且被很多歌读线程访问，数量远多余写线程时是值得的. 下面是一个使用TreeMap的类，预期很大且会有并发的访问. class RWDictionary { private final Map m = new TreeMap<>(); private final ReentrantReadWriteLock rwl = new ReentrantReadWriteLock(); private final Lock r = rwl.readLock(); private final Lock w = rwl.writeLock(); public Data get(String key) { r.lock(); try { return m.get(key); } finally { r.unlock(); } } public List allKeys() { r.lock(); try { return new ArrayList<>(m.keySet()); } finally { r.unlock(); } } public Data put(String key, Data value) { w.lock(); try { return m.put(key, value); } finally { w.unlock(); } } public void clear() { w.lock(); try { m.clear(); } finally { w.unlock(); } } } 这个类对TreeMap进行了封装，使用TreeMap+ReentrantReadWriteLock实现了一个线程安全的TreeMap. 这个类支持最大65535个重入的写入所和65535个读锁.超过这个限制，会返回Error. 源码阅读 这个类使用AQS框架实现，先来看一下AQS的子类Sync. Sync 变量 首先是几个属性. /* * Read vs write count extraction constants and functions. * Lock state is logically divided into two unsigned shorts: * The lower one representing the exclusive (writer) lock hold count, * and the upper the shared (reader) hold count. */ // 共享锁的位数 static final int SHARED_SHIFT = 16; // 共享锁unit static final int SHARED_UNIT = (1 { public HoldCounter initialValue() { return new HoldCounter(); } } /** * The number of reentrant read locks held by current thread. * Initialized only in constructor and readObject. * Removed whenever a thread's read hold count drops to 0. */ // 当前线程的读锁持有数量 private transient ThreadLocalHoldCounter readHolds; /** * The hold count of the last thread to successfully acquire * readLock. This saves ThreadLocal lookup in the common case * where the next thread to release is the last one to * acquire. This is non-volatile since it is just used * as a heuristic, and would be great for threads to cache. * * Can outlive the Thread for which it is caching the read * hold count, but avoids garbage retention by not retaining a * reference to the Thread. * * Accessed via a benign data race; relies on the memory * model's final field and out-of-thin-air guarantees. */ // 上一个成功获取读锁的线程持有的数量 private transient HoldCounter cachedHoldCounter; /** * firstReader is the first thread to have acquired the read lock. * firstReaderHoldCount is firstReader's hold count. * * More precisely, firstReader is the unique thread that last * changed the shared count from 0 to 1, and has not released the * read lock since then; null if there is no such thread. * * Cannot cause garbage retention unless the thread terminated * without relinquishing its read locks, since tryReleaseShared * sets it to null. * * Accessed via a benign data race; relies on the memory * model's out-of-thin-air guarantees for references. * * This allows tracking of read holds for uncontended read * locks to be very cheap. */ // 第一个申请读锁的线程 // 第一个申请读锁的线程，现在持有的读锁数量. private transient Thread firstReader; private transient int firstReaderHoldCount; 首先定义了一些常量，用来指示在State状态的定义中，读写锁的表示方法等. 以及内部的读锁计数的保存》 构造方法 Sync() { readHolds = new ThreadLocalHoldCounter(); setState(getState()); // ensures visibility of readHolds } 比较简单，初始化了一个当前线程的计数器，然后检查了一下初始状态. tryRelease 这是AQS中释放独占锁的方法： /* * Note that tryRelease and tryAcquire can be called by * Conditions. So it is possible that their arguments contain * both read and write holds that are all released during a * condition wait and re-established in tryAcquire. */ @ReservedStackAccess protected final boolean tryRelease(int releases) { if (!isHeldExclusively()) throw new IllegalMonitorStateException(); int nextc = getState() - releases; boolean free = exclusiveCount(nextc) == 0; if (free) setExclusiveOwnerThread(null); setState(nextc); return free; } 首先判断是否独占锁，不是的话抛出异常. 用当前State减去要释放的数量. 如果释放后，独占锁的数量为0. 则锁释放成功.将锁的当前线程设置为null. 如果独占锁的数量仍不为0(可重入锁),则释放返回仍未释放. tryAcquire 这是AQS中获取独占锁的方法: @ReservedStackAccess protected final boolean tryAcquire(int acquires) { /* * Walkthrough: * 1. If read count nonzero or write count nonzero * and owner is a different thread, fail. * 2. If count would saturate, fail. (This can only * happen if count is already nonzero.) * 3. Otherwise, this thread is eligible for lock if * it is either a reentrant acquire or * queue policy allows it. If so, update state * and set owner. */ Thread current = Thread.currentThread(); int c = getState(); int w = exclusiveCount(c); if (c != 0) { // (Note: if c != 0 and w == 0 then shared count != 0) if (w == 0 || current != getExclusiveOwnerThread()) return false; if (w + exclusiveCount(acquires) > MAX_COUNT) throw new Error(\"Maximum lock count exceeded\"); // Reentrant acquire setState(c + acquires); return true; } if (writerShouldBlock() || !compareAndSetState(c, c + acquires)) return false; setExclusiveOwnerThread(current); return true; } 首先拿到当前的线程以及当前锁的State. 如果锁的状态不为0, 意味着当前有锁被持有. 但是独占锁的数量为0. 意味着当前锁在被shared模式持有. 直接返回加锁失败. 对锁的状态递增此次申请的数量. 如果超过最大数量，抛出异常. 未超过，设置状态. 加锁成功. 如果锁的状态为0. 且当前写锁应该被阻塞，或者设置状态尝试获取锁失败，都返回加锁失败. 否则加锁成功，设置当前持有锁的线程. tryReleaseShared 释放共享锁 @ReservedStackAccess protected final boolean tryReleaseShared(int unused) { Thread current = Thread.currentThread(); // 当前线程是第一个读线程 if (firstReader == current) { // assert firstReaderHoldCount > 0; if (firstReaderHoldCount == 1) firstReader = null; else firstReaderHoldCount--; } else { // 拿到缓存的holder.或者当前线程的holder. HoldCounter rh = cachedHoldCounter; if (rh == null || rh.tid != LockSupport.getThreadId(current)) rh = readHolds.get(); int count = rh.count; if (count 这是AQS中释放共享锁的操作: 如果当前线程是第一个获取读锁的线程: 将当前类持有的firstReader和firstReaderHoldCount进行相应的赋值.递减/置为null. 拿到上一个持有共享锁的读线程，如果当前线程不是上一个线程. 就拿到当前线程的holder. 对拿到的线程持有数量的holder进行递减. 对共享锁进行递减，注意: 共享锁使用的是State的高位部分, 因此每次减去的值是: SHARED_UNIT. 设置状态成功，返回释放后的state是否为0. tryAcquireShared 获取共享锁 @ReservedStackAccess protected final int tryAcquireShared(int unused) { /* * Walkthrough: * 1. If write lock held by another thread, fail. * 2. Otherwise, this thread is eligible for * lock wrt state, so ask if it should block * because of queue policy. If not, try * to grant by CASing state and updating count. * Note that step does not check for reentrant * acquires, which is postponed to full version * to avoid having to check hold count in * the more typical non-reentrant case. * 3. If step 2 fails either because thread * apparently not eligible or CAS fails or count * saturated, chain to version with full retry loop. */ Thread current = Thread.currentThread(); // 当前状态 int c = getState(); // 独占锁被持有，并且独占的线程不是当前线程，直接获取失败失败 if (exclusiveCount(c) != 0 && getExclusiveOwnerThread() != current) return -1; // 当前持有的共享锁的数量 int r = sharedCount(c); // 获取共享锁是否应该被阻塞&&共享锁数量小于最大值&&递增状态State成功. // 意味着加锁成功了. if (!readerShouldBlock() && r 获取共享锁:整体的流程如备注中所述，上面的方法处理了: 当前获取不阻塞. 共享锁数量未超过最大值 CAS能成功. 这三个条件均满足的情况，如果不满足，调用了fullTryAcquireShared来处理. /** * Full version of acquire for reads, that handles CAS misses * and reentrant reads not dealt with in tryAcquireShared. */ final int fullTryAcquireShared(Thread current) { /* * This code is in part redundant with that in * tryAcquireShared but is simpler overall by not * complicating tryAcquireShared with interactions between * retries and lazily reading hold counts. */ HoldCounter rh = null; for (;;) { // 当前状态 int c = getState(); // 有独占锁，直接失败 if (exclusiveCount(c) != 0) { if (getExclusiveOwnerThread() != current) return -1; // else we hold the exclusive lock; blocking here // would cause deadlock. } else if (readerShouldBlock()) { // 当前应该被阻塞. // Make sure we're not acquiring read lock reentrantly // 第一个读线程，不干啥 if (firstReader == current) { // assert firstReaderHoldCount > 0; } else { // 读取缓存的线程持有锁数量. if (rh == null) { rh = cachedHoldCounter; if (rh == null || rh.tid != LockSupport.getThreadId(current)) { // 缓存的不是当前线程，取当前线程的. rh = readHolds.get(); // 持有锁数量为0. 删掉 if (rh.count == 0) readHolds.remove(); } } // 没看懂，为啥缓存的或者当前的为0. 要返回-1 if (rh.count == 0) return -1; } } // 当前读锁数量到达最大了，抛出异常 if (sharedCount(c) == MAX_COUNT) throw new Error(\"Maximum lock count exceeded\"); // 如果设置+1个读锁成功 if (compareAndSetState(c, c + SHARED_UNIT)) { // 如果读锁为0.那么当前线程就是第一个读锁 if (sharedCount(c) == 0) { firstReader = current; firstReaderHoldCount = 1; // 第一个读锁重入 } else if (firstReader == current) { firstReaderHoldCount++; } else { // 缓存上一个获取读锁的线程 if (rh == null) rh = cachedHoldCounter; if (rh == null || rh.tid != LockSupport.getThreadId(current)) rh = readHolds.get(); else if (rh.count == 0) readHolds.set(rh); rh.count++; cachedHoldCounter = rh; // cache for release } // 成功 return 1; } // 如果CAS设置状态失败，继续自旋 } } 其实和tryAcquireShared很像，只是通过分离代码处理了额外的几种情况. tryWriteLock 获取写锁 /** * Performs tryLock for write, enabling barging in both modes. * This is identical in effect to tryAcquire except for lack * of calls to writerShouldBlock. */ @ReservedStackAccess final boolean tryWriteLock() { Thread current = Thread.currentThread(); int c = getState(); if (c != 0) { int w = exclusiveCount(c); if (w == 0 || current != getExclusiveOwnerThread()) return false; if (w == MAX_COUNT) throw new Error(\"Maximum lock count exceeded\"); } if (!compareAndSetState(c, c + 1)) return false; setExclusiveOwnerThread(current); return true; } 和tryAcquire效果一样，只是不考虑writerShouldBlock. tryReadLock /** * Performs tryLock for read, enabling barging in both modes. * This is identical in effect to tryAcquireShared except for * lack of calls to readerShouldBlock. */ @ReservedStackAccess final boolean tryReadLock() { Thread current = Thread.currentThread(); for (;;) { int c = getState(); if (exclusiveCount(c) != 0 && getExclusiveOwnerThread() != current) return false; int r = sharedCount(c); if (r == MAX_COUNT) throw new Error(\"Maximum lock count exceeded\"); if (compareAndSetState(c, c + SHARED_UNIT)) { if (r == 0) { firstReader = current; firstReaderHoldCount = 1; } else if (firstReader == current) { firstReaderHoldCount++; } else { HoldCounter rh = cachedHoldCounter; if (rh == null || rh.tid != LockSupport.getThreadId(current)) cachedHoldCounter = rh = readHolds.get(); else if (rh.count == 0) readHolds.set(rh); rh.count++; } return true; } } } 和tryAcquireShared效果一样，只是不考虑readerShouldBlock. NonfairSync 非公平状态下的Sync /** * Nonfair version of Sync */ static final class NonfairSync extends Sync { private static final long serialVersionUID = -8159625535654395037L; final boolean writerShouldBlock() { return false; // writers can always barge } final boolean readerShouldBlock() { /* As a heuristic to avoid indefinite writer starvation, * block if the thread that momentarily appears to be head * of queue, if one exists, is a waiting writer. This is * only a probabilistic effect since a new reader will not * block if there is a waiting writer behind other enabled * readers that have not yet drained from the queue. */ return apparentlyFirstQueuedIsExclusive(); } } 主要是定义了父类中的两个抽象方法. writerShouldBlock. 写锁的请求，任何时候都可以申请. readerShouldBlock . 读锁的请求，能不能申请，要看情况咯. /** * Returns {@code true} if the apparent first queued thread, if one * exists, is waiting in exclusive mode. If this method returns * {@code true}, and the current thread is attempting to acquire in * shared mode (that is, this method is invoked from {@link * #tryAcquireShared}) then it is guaranteed that the current thread * is not the first queued thread. Used only as a heuristic in * ReentrantReadWriteLock. */ final boolean apparentlyFirstQueuedIsExclusive() { Node h, s; return (h = head) != null && (s = h.next) != null && !s.isShared() && s.thread != null; } 这是为了避免因为非公平的竞争，而把写锁饿死的情况实现的一个方法: 如果当前等待队列中有两个节点，且第二个还是独占的写锁等待，当前的读锁请求就不允许提交了. 这是一个概率上的问题，如果等待队列里面已经有一个写锁排在读锁后面了，害怕把写锁饿死，就在这里不让别的读锁来竞争，知道前面的锁走完. FairSync 公平模式 /** * Fair version of Sync */ static final class FairSync extends Sync { private static final long serialVersionUID = -2274990926593161451L; final boolean writerShouldBlock() { return hasQueuedPredecessors(); } final boolean readerShouldBlock() { return hasQueuedPredecessors(); } } 公平锁，对于读写锁是公平的，都是看队列中有没有已经在等待的节点了.(这部分是在AQS实现的) public final boolean hasQueuedPredecessors() { Node h, s; if ((h = head) != null) { if ((s = h.next) == null || s.waitStatus > 0) { s = null; // traverse in case of concurrent cancellation for (Node p = tail; p != h && p != null; p = p.prev) { if (p.waitStatus ReadLock read是一个实现了Lock接口的子类. 持有一个Sync同步器. lock public void lock() { sync.acquireShared(1); } 读锁的加锁，调用了AQS的申请一个共享锁. tryLock public boolean tryLock() { return sync.tryReadLock(); } 读锁的尝试加锁. 调用的是同步器的tryReadLock，也就是不考虑readerShouldBlock,而强行进行的一次加锁行为. unlock public void unlock() { sync.releaseShared(1); } 读锁的解锁，是调用AQS的释放一次共享锁. WriteLock 写锁的实现，也是实现Lock接口的一个实现类. lock public void lock() { sync.acquire(1); } 写锁的加锁，是调用AQS的获取一个独占锁实现. tryLock public boolean tryLock() { return sync.tryWriteLock(); } 写锁的tryLock.调用sync.tryWriteLock.不考虑writerShoulBlock进行的一次强行尝试. unlock public void unlock() { sync.release(1); } 写锁的解锁，调用AQS的释放独占锁一次. 其他 其他还有一些对于类内部属性的查询方法，主要用于对当前锁状态的监控，这里就不展开了. 都是比较简单的属性查询. 总结 ReentrantReadWriteLock, 继承自AQS框架, 实现了读写锁，可重入特性. 既然是继承自AQS框架. 那么主要工作仍然是对State的定义. State的低16位，保存独占锁的加锁信息及重入次数. State的高16位，保存共享锁的加锁信息，及加锁数量. 共享锁的重入次数，由单独的属性进行保存. 读写锁 读写锁功能由两个子类ReadLock和WriteLock实现，负责调用AQS的独占锁加解锁和共享锁的加解锁. 公平锁/非公平锁 由AQS的子类Sync及NonfairSync``FairSync实现，主要是控制新加入的加锁请求是否要排队来实现的. 可重入性 可重入锁，需要记录锁的持有线程，对当前线程持有的数量进行递增递减，而不是简单的是否为某个特定值. 写锁的重入数量保存在State的低16位. 读锁的重入数量保存在readHolds中. 由一个类似于ThreadLocal的结构进行保存线程->重入数量的对应关系. 为什么需要单独保存第一个读锁的线程? firstReader 和 firstReaderHoldCount. 总的说是为了减少ThreadLocal的数量，减少内存占用。详细分析看这里: https://www.mdnice.com/writing/f2beb7d9c58f43afbdeec9ce708d4582 参考文章 关于ReentrantReadWriteLock，第一个获取读锁的线程单独记录问题讨论（firstReader和firstReaderHoldCount） 完。 联系我 最后，欢迎关注我的个人公众号【 呼延十 】，会不定期更新很多后端工程师的学习笔记。 也欢迎直接公众号私信或者邮箱联系我，一定知无不言，言无不尽。 以上皆为个人所思所得，如有错误欢迎评论区指正。 欢迎转载，烦请署名并保留原文链接。 联系邮箱：huyanshi2580@gmail.com 更多学习笔记见个人博客或关注微信公众号 ------>呼延十 版权所有，盗版必究 all right reserved，powered by GitbookLast Modified On： 2021-10-17 02:51:50 "},"java/juc/2021-10-09-(juc系列)Phaser源码学习.html":{"url":"java/juc/2021-10-09-(juc系列)Phaser源码学习.html","title":"(juc系列)Phaser源码学习","keywords":"","body":"简介 老规矩,下面是官方注释的简单翻译版本,追求速度,都不一定通顺. 谨慎阅读. 一个可复用的同步屏障，功能上类似于CyclicBarrier和CountDownLatch，但是支持更多灵活的用法. 登记 与其他同步屏障不同的是，Phaser的数量是可以各自不同的. 使用方应该使用register或者bulkRegister来进行注册.或者以构造方法的形式初始化数量。 然后在一些节点到达后可以进行取消注册. 与大多数基本的同步器构造方法一样，注册和取消注册仅影响内部计数. 他们不记录任何内部的名单，　任务无法查询他们是否已经登记了. CountDownLatch和CyclicBarrier,Semaphore等等都是指定数量后不能变化的，而Phaser的注册数量是可以随时变化的，因此更加灵活. 同步 和CyclicBarrier一样，Phaser支持重复调用awaited. arriveAndAwaitAdvance和CyclicBarrier.await的作用类似. Phaser的每一代拥有一个关联的编号. Phaser的阶段编号从零开始，所有的参与者到达后，阶段编号增加。到达int的最大值后，回归为0. 阶段编号可以独立的控制到达行为和等待行为，任何注册方可以调用以下两种方法: arrival arrive和arriveAndDeregister两个方法记录到达. 这两个方法不阻塞，但是返回关联的到达阶段编号. 指定阶段编号的最后一个参与者到达，一个可选的行为会被执行，然后Phaser进行升级. 这两个操作由触发阶段升级的最后一个参与者触发，并由重写的onAdvance方法负责控制. 这个方法也负责控制终止， 重写这个方法和CyclicBarrier的屏障行为很相似，但是更加灵活一些. waiting 等待 awaitAdvance要求一个参数，表示到达阶段的编号，或者当一个阶段升级到另一个不同的阶段时返回. 和CyclicBarrier的方法不一样,awaitAdvance方法继续等待,直到等待线程被中断. 可中断和带有超时的版本也是支持的. 但是超时或者中断了并不会影响Phaser的状态. 如果必要,你可以自己执行相关的恢复操作, 在调用forceTermination之后. 阶段还被用来执行ForkJoinPool. 终止 一个phaser可以进入终止状态, 使用isTerminated方法来检查. 如果终止了,所有的同步方法立即返回,不再等待. 返回一个负数值来表名这点. 相似的,在终止后尝试进行注册,也不会有反应. 当调用onAdvance返回true时, 终止被触发. 如果一个取消注册的行为,让注册数量为0了, 将会终止. 分层 Phasers可以分层以减少竞争(比如以树状结构初始化). 设置有较大数量的Phasers将会有比较严重的同步竞争,可以使用一组子Phaser共享一个公共的父节点, 来避免这种情况. 这将大大的提升吞吐量即使会导致每一个操作的浪费变大. 在一个分层phaser的树中, 子节点的注册和取消注册是自动管理的, 如果注册的数量变为非零值,子节点将注册至其父节点, 如果注册数量变为0. 子节点将从其父节点取消注册. 可以查看下方分层的示例来了解. 因为支持分层，因此一个Phaser有三种形态. 非树形，单个节点 这是最简单的形态，只要自身的注册数等于到达数，就升级一次阶段编号即可. 树形，叶子节点 只要自身的注册数量等于到达数量，就代表自己这个节点“到达”了，向父节点的到达数+1. 树形，非叶子节点 自身到达数等于注册数，这里的到达数不是参与的任务数，而是自己的子节点的数量，自己的所有子节点全部到达，自己才算到达，向自己的父节点进行\"到达\"操作。 如果这个节点是根节点，那么整个Phaser树才算是全部到达，进行升级操作. monitoring 监控 即使同步方法只能由注册方进行调用,一个phaser的当前状态可以被任何调用方监控. 在一个给定的时间,getRegisteredParties返回总数, getArriveParties返回到达的数量. getUnarrivedParties返回没有到达的数量. 这些方法返回值都是瞬态的,因此可能在同步控制中不是特别有用. toString方法返回这些状态的一个快照. 简单示例 代替CountDownLatch Phaser可以用来替换掉CountDownLatch. 控制一个行为, 服务于一些部分. 通常的操作是, 设置当前线程为第一个注册者, 然后启动所有的行为,之后取消注册当前线程. void runTasks(List tasks) { // 此时注册数量为1 Phaser startingGate = new Phaser(1); // \"1\" to register self // create and start threads for (Runnable task : tasks) { startingGate.register(); new Thread(() -> { startingGate.arriveAndAwaitAdvance(); task.run(); }).start(); } // deregister self to allow threads to proceed startingGate.arriveAndDeregister(); } 注册当前线程(此时注册数量为1) 启动所有线程,首先注册一次(全部完成后，此时注册数量为tasks.size() + 1) ，之后让他们arriveAndAwaitAdvance. 到达并且等待升级(此时到达数量为tasks.size()`. 取消注册当前线程(注册数量变成tasks.size()), Phaser的注册数量等于到达数量。因此进行升级，所有等待的线程唤醒，继续执行任务. 重复执行一组任务指定次数 让一组线程,重复执行某些行为一定的次数,可以重写onAdvance. void startTasks(List tasks, int iterations) { Phaser phaser = new Phaser() { // 终止条件, 阶段编号大于等于给定循环次数减1. 其实就是只能循环给定次数 protected boolean onAdvance(int phase, int registeredParties) { return phase >= iterations - 1 || registeredParties == 0; } }; // 注册一个 phaser.register(); for (Runnable task : tasks) { // 注册`tasks.size()`个 phaser.register(); new Thread(() -> { do { task.run(); // 等待升级 phaser.arriveAndAwaitAdvance(); } while (!phaser.isTerminated()); }).start(); } // allow threads to proceed; don't wait for them // 取消注册，开始所有任务 phaser.arriveAndDeregister(); } 初始化一个Phaser,并重写onAdvance. 让阶段编号大于给定次数时，Phaser进行终止. 当前线程注册. (此时注册数量为1) 每个任务线程，注册一次. (此时注册数量为tasks.size() + 1) 如果Phaser没有终止,其他所有线程执行任务, 然后等待 (此时到达数量为tasks.size(). 当前线程取消注册,让注册数等于等待数，其他线程等待结束，进行升级或者终止. 让所有任务互相等待，以完成一组任务，整体完成给定次数后，Phaser终止，程序结束. 等待终止 如果主任务必须在终止后发生,他可以注册然后执行一个相似的循环. // ... phaser.register(); while (!phaser.isTerminated()) phaser.arriveAndAwaitAdvance(); 首先进行注册，然后在Phaser没有终止前，不断的到达，等待升级.知道Phaser终止了，再进行主任务的执行. 等待特定的阶段编号 如果你确定在你的上下文中,Phaser的数量不会超过int的最大值,你可以使用这些相关的构造器来等待特定的某个阶段编号. void awaitPhase(Phaser phaser, int phase) { // 注册一次 int p = phaser.register(); // assumes caller not already registered // 不断等待 while (p 分层的示例 上面讲到Phaser支持分层以获得更好的并发性,这是一个简单的例子. 创建一组任务，使用一个树形的Phasers. 假设一个Task的类，他的构造参数接受一个Phaser. 在调用下方代码的build之后，这些任务会开始. void build(Task[] tasks, int lo, int hi, Phaser ph) { // 如果任务数量大于单个Phaser最大的任务数，说明需要拆分 if (hi - lo > TASKS_PER_PHASER) { for (int i = lo; i TASKS_PER_PHASER 的最佳值取决于你期望的同步效率. 越小的值，会让每个阶段的执行块变小，因此速率高. 如果需要更大的执行快，可以设置为高达几百. 注意事项 实现控制最大的参与者数量为65535.　如果尝试去注册更多，会导致错误. 但是你可以通过使用树形的Phasers来实现更多的参与者. 源码阅读 构造方法 /** * Creates a new phaser with no initially registered parties, no * parent, and initial phase number 0. Any thread using this * phaser will need to first register for it. */ public Phaser() { this(null, 0); } /** * Creates a new phaser with the given number of registered * unarrived parties, no parent, and initial phase number 0. * * @param parties the number of parties required to advance to the * next phase * @throws IllegalArgumentException if parties less than zero * or greater than the maximum number of parties supported */ public Phaser(int parties) { this(null, parties); } /** * Equivalent to {@link #Phaser(Phaser, int) Phaser(parent, 0)}. * * @param parent the parent phaser */ public Phaser(Phaser parent) { this(parent, 0); } /** * Creates a new phaser with the given parent and number of * registered unarrived parties. When the given parent is non-null * and the given number of parties is greater than zero, this * child phaser is registered with its parent. * * @param parent the parent phaser * @param parties the number of parties required to advance to the * next phase * @throws IllegalArgumentException if parties less than zero * or greater than the maximum number of parties supported */ public Phaser(Phaser parent, int parties) { // 高16位有值,异常,初始化时不可以已有参与者 if (parties >>> PARTIES_SHIFT != 0) throw new IllegalArgumentException(\"Illegal number of parties\"); // 当前阶段置为0.初始值 int phase = 0; this.parent = parent; // 给定的父节点不为空, 是一个树形的Phaser. if (parent != null) { // 共享同一个root节点,还有所有节点共享队列 final Phaser root = parent.root; this.root = root; this.evenQ = root.evenQ; this.oddQ = root.oddQ; // 如果参与者不为0,当前节点是一个有效的节点，向当前节点的父节点,注册一个参与者,代表(当前节点需要父节点等待) if (parties != 0) phase = parent.doRegister(1); } else { // 父节点为空,当前是孤立的,非树形的Phaser. // 赋值一些属性 this.root = this; this.evenQ = new AtomicReference(); this.oddQ = new AtomicReference(); } // 初始化状态,如果没有参与者,赋值为EMPTY=1 // 如果有, state=高32位记录阶段号,16-32位记录参与者数量,低16记录没有到达的数量. 初始化的时候，参与者数量和没有到达的数量是一致的 this.state = (parties == 0) ? (long)EMPTY : ((long)phase 共提供了4个构造方法,本质上都是调用最后一个. 详情看注释. 主要是区分是否是树形,然后对State，父节点，等待队列等进行初始化赋值. 变量 // 内部的状态定义, 核心属性 private volatile long state; // 一些常量 private static final int MAX_PARTIES = 0xffff; // 最大参与者数量 private static final int MAX_PHASE = Integer.MAX_VALUE; // 最大阶段数量 private static final int PARTIES_SHIFT = 16; // 参与者占用的位数 private static final int PHASE_SHIFT = 32; // 阶段占用的位数 private static final int UNARRIVED_MASK = 0xffff; // to mask ints // 掩码,计算没有到达的数量 private static final long PARTIES_MASK = 0xffff0000L; // to mask longs // 掩码,计算参与者的数量 private static final long COUNTS_MASK = 0xffffffffL; // 掩码,计数 private static final long TERMINATION_BIT = 1L evenQ; private final AtomicReference oddQ; 这是一些变量和常量. State 状态定义 parent 父节点 root 根节点 evenQ 等待线程栈的偶数版本 addQ 等待线程栈的奇数版本 其他还有一些常量,主要是用来辅助对于State的定义的,比较常见的一些shift,one等等,不再介绍. QNode 内部的等待节点. 定义结构比较简单, 主要是保存了当前的Phaser信息和对应的线程信息,以及一个指向下一个节点的next指针. 提供了两个方法. isReleasable 是否可释放 如果内部的信息有一些不对劲, 比如线程为空,或者被中断了, 或者Phaser被别人改了,等等, 都返回true. 否则返回false. 支持中断和超时. block 阻塞等待 根据是否超时, 阻塞当前线程一段时间. static final class QNode implements ForkJoinPool.ManagedBlocker { // 等待的阶段 final Phaser phaser; final int phase; final boolean interruptible; final boolean timed; boolean wasInterrupted; long nanos; final long deadline; volatile Thread thread; // nulled to cancel wait QNode next; QNode(Phaser phaser, int phase, boolean interruptible, boolean timed, long nanos) { this.phaser = phaser; this.phase = phase; this.interruptible = interruptible; this.nanos = nanos; this.timed = timed; this.deadline = timed ? System.nanoTime() + nanos : 0L; thread = Thread.currentThread(); } public boolean isReleasable() { if (thread == null) return true; if (phaser.getPhase() != phase) { thread = null; return true; } if (Thread.interrupted()) wasInterrupted = true; if (wasInterrupted && interruptible) { thread = null; return true; } if (timed && (nanos register系列 用于向Phaser注册参与者. register系列提供了两个方法,register和bulkRegister两个方法,本质上都是调用doRegister方法. private int doRegister(int registrations) { // adjustment to state // 注册后的State值. long adjust = ((long)registrations >> PARTIES_SHIFT; // 没到达的数量 int unarrived = counts & UNARRIVED_MASK; // 注册后,参与者数量超出最大值, 报错 if (registrations > MAX_PARTIES - parties) throw new IllegalStateException(badRegister(s)); // 当前所在的阶段编号 phase = (int)(s >>> PHASE_SHIFT); // >> PHASE_SHIFT); // assert (int)s == EMPTY; } break; } } } } return phase; } 这是核心的注册方法，主要有三个分支 没有父节点，且第一次注册. 这是最简单的，直接将注册后的State更新进去即可. 有父节点，但是不是第一次注册 检查下注册后，当前节点是否全部到达了，如果是, 当前节点升级，并且告诉父节点. 有父节点，是第一次注册. 首先将当前节点注册到父节点，之后更新当前节点的参与者信息等. arrive系列 arrive 和 arriveAndDeregister 到达,不等待其他参与者 这两个方法都实现到达相关逻辑, 调用doArrive来实现. /** * Arrives at this phaser, without waiting for others to arrive. * * It is a usage error for an unregistered party to invoke this * method. However, this error may result in an {@code * IllegalStateException} only upon some subsequent operation on * this phaser, if ever. * * @return the arrival phase number, or a negative value if terminated * @throws IllegalStateException if not terminated and the number * of unarrived parties would become negative */ public int arrive() { return doArrive(ONE_ARRIVAL); } /** * Arrives at this phaser and deregisters from it without waiting * for others to arrive. Deregistration reduces the number of * parties required to advance in future phases. If this phaser * has a parent, and deregistration causes this phaser to have * zero parties, this phaser is also deregistered from its parent. * * It is a usage error for an unregistered party to invoke this * method. However, this error may result in an {@code * IllegalStateException} only upon some subsequent operation on * this phaser, if ever. * * @return the arrival phase number, or a negative value if terminated * @throws IllegalStateException if not terminated and the number * of registered or unarrived parties would become negative */ public int arriveAndDeregister() { return doArrive(ONE_DEREGISTER); } doArrive /** * Main implementation for methods arrive and arriveAndDeregister. * Manually tuned to speed up and minimize race windows for the * common case of just decrementing unarrived field. * * @param adjust value to subtract from state; * ONE_ARRIVAL for arrive, * ONE_DEREGISTER for arriveAndDeregister */ // arrive和arriveAAndDeregister两个方法的主要实现. private int doArrive(int adjust) { final Phaser root = this.root; for (;;) { // 如果不是树形结构,拿到State,如果是,进行一次状态同步后拿到State. long s = (root == this) ? state : reconcileState(); // 当前阶段 int phase = (int)(s >>> PHASE_SHIFT); if (phase >> PARTIES_SHIFT; // 不是树形结构 if (root == this) { // 如果需要终止, 就终止 if (onAdvance(phase, nextUnarrived)) n |= TERMINATION_BIT; // 如果没有参与者，也没有到达的，Phaser置为空. else if (nextUnarrived == 0) n |= EMPTY; else //　升级后应该的n n |= nextUnarrived; // 下一个阶段编号 int nextPhase = (phase + 1) & MAX_PHASE; // 计算新的State并写入 n |= (long)nextPhase 主要作用是对State中的未到达数量进行递减, 如果递减完，还有未到达的参与者，直接返回当前阶段，如果递减完，当前所有参与者都到达了. 有三个分支: 非树形结构 直接计算下一个状态，进行写入. 树形结构，且因为注销，没有参与者了. 向父节点注销当前节点，　当前节点置为空. 树形结构，且还有参与者 向父节点传递当前节点完全到达的消息. arriveAndAwaitAdvance 到达然后等待其他参与者 /** * Arrives at this phaser and awaits others. Equivalent in effect * to {@code awaitAdvance(arrive())}. If you need to await with * interruption or timeout, you can arrange this with an analogous * construction using one of the other forms of the {@code * awaitAdvance} method. If instead you need to deregister upon * arrival, use {@code awaitAdvance(arriveAndDeregister())}. * * It is a usage error for an unregistered party to invoke this * method. However, this error may result in an {@code * IllegalStateException} only upon some subsequent operation on * this phaser, if ever. * * @return the arrival phase number, or the (negative) * {@linkplain #getPhase() current phase} if terminated * @throws IllegalStateException if not terminated and the number * of unarrived parties would become negative */ // 到达并等待其他参与者,等价于调用`awaitAdvance(arrive())`. public int arriveAndAwaitAdvance() { // Specialization of doArrive+awaitAdvance eliminating some reads/paths final Phaser root = this.root; for (;;) { // 这块和之前逻辑一样 long s = (root == this) ? state : reconcileState(); int phase = (int)(s >>> PHASE_SHIFT); if (phase 1) return root.internalAwaitAdvance(phase, null); // 如果当前节点是最后一个到达的参与者，向父节点进行“到达且等待”操作 if (root != this) return parent.arriveAndAwaitAdvance(); // 这里是，当前节点是最后一个到达的参与者，且当前节点不是树形结构 // 计算新的State并设置State long n = s & PARTIES_MASK; // base of next state int nextUnarrived = (int)n >>> PARTIES_SHIFT; if (onAdvance(phase, nextUnarrived)) n |= TERMINATION_BIT; else if (nextUnarrived == 0) n |= EMPTY; else n |= nextUnarrived; int nextPhase = (phase + 1) & MAX_PHASE; n |= (long)nextPhase >> PHASE_SHIFT); // terminated // 唤醒等待者 releaseWaiters(phase); return nextPhase; } } } 到达一个参与者，且阻塞等待Phaser的升级行为. 首先将当前Phaser的状态进行递减，之后主要有三个分支: 不是最后一个到达的. 从跟进点进行等待升级 是最后一个到达的，且有父节点 调用父节点的arriveAndAwaitAdvance,向父节点报告当前节点已经完全到达，开始等待升级. 是最后一个到达的，且是根节点 计算新的状态，设置状态然后唤醒等待者. await系列 awaitAdvance, awaitAdvanceInterruptibly, awaitAdvanceInterruptibly 三个await系列的方法,本质上都是调用的 父节点的internalAwaitAdvance. 只是支持了中断和超时而已. /** * Awaits the phase of this phaser to advance from the given phase * value, returning immediately if the current phase is not equal * to the given phase value or this phaser is terminated. * * @param phase an arrival phase number, or negative value if * terminated; this argument is normally the value returned by a * previous call to {@code arrive} or {@code arriveAndDeregister}. * @return the next arrival phase number, or the argument if it is * negative, or the (negative) {@linkplain #getPhase() current phase} * if terminated */ // 等待阶段升级 // 如果给定的阶段和当前不一致,或者当前Phaser终止了,直接返回. public int awaitAdvance(int phase) { final Phaser root = this.root; // 拿到Staate. long s = (root == this) ? state : reconcileState(); // 当前的阶段 int p = (int)(s >>> PHASE_SHIFT); if (phase >> PHASE_SHIFT)) == phase) { // 节点为空, if (node == null) { // spinning in noninterruptible mode // 计算自旋次数 int unarrived = (int)s & UNARRIVED_MASK; if (unarrived != lastUnarrived && (lastUnarrived = unarrived) head = (phase & 1) == 0 ? evenQ : oddQ; QNode q = node.next = head.get(); if ((q == null || q.phase == phase) && (int)(state >>> PHASE_SHIFT) == phase) // avoid stale enq queued = head.compareAndSet(q, node); } else { try { ForkJoinPool.managedBlock(node); } catch (InterruptedException cantHappen) { node.wasInterrupted = true; } } } if (node != null) { if (node.thread != null) node.thread = null; // avoid need for unpark() if (node.wasInterrupted && !node.interruptible) Thread.currentThread().interrupt(); if (p == phase && (p = (int)(state >>> PHASE_SHIFT)) == phase) return abortWait(phase); // possibly clean up on abort } releaseWaiters(phase); return p; } 让当前线程自旋或者进入队列等待Phaser的升级，也就是等待其他所有参与者的到达. 强行终止 /** * Forces this phaser to enter termination state. Counts of * registered parties are unaffected. If this phaser is a member * of a tiered set of phasers, then all of the phasers in the set * are terminated. If this phaser is already terminated, this * method has no effect. This method may be useful for * coordinating recovery after one or more tasks encounter * unexpected exceptions. */ public void forceTermination() { // Only need to change root state final Phaser root = this.root; long s; while ((s = root.state) >= 0) { if (STATE.compareAndSet(root, s, s | TERMINATION_BIT)) { // signal all threads releaseWaiters(0); // Waiters on evenQ releaseWaiters(1); // Waiters on oddQ return; } } } 比较简单, 只要根节点的状态不为0,就强行设置为终止了. 释放所有的等待节点. onAdvance 这是预留给子类的一个方法, 可以定义Phaser升级时执行的动作,还可以定义锁是否要升级. 默认实现是注册的参与者为0, 就终止整个Phaser. 监控方法 还有很多负责监控当前Phaser状态 的方法,这里简单记录一下 . getPhase 拿到阶段编号 getRegisteredParites 拿到当前的参与者数量 getArrivedParties 拿到当前到达的参与者数量 getUnarrivedParties 未到达的参与者数量 getParent 返回当前节点的父节点 getRoot 获取根节点 isTerminated 是否被终止 总结 Phaser是一个用于多阶段任务的同步器，没有使用AQS框架来实现，而是自己实现的。 内部的核心还是State的定义. 高32位记录当前的阶段编号,16-32为记录共有多少个参与者, 低16位记录还有多少个参与者没有到达. 提供三类方法: 注册 修改16-32位，与其他同步器相比，提供了更多的灵活性，可以修改参与者的数量 到达 修改低16位，当全部到达后，进行升级，升级通过修改高32位来记录阶段编号 等待 让先到达的线程，阻塞等待所有参与者的到达，也就是升级行为完成后，被唤醒. 为了支持更大的并发度，Phaser支持以树结构创建，叶子节点接受所有参与者的到达，控制所有注册到自己的参与者. 父节点控制自己的子节点. 根节点控制所有是否进行放行，唤醒所有等待线程. 完. 完。 联系我 最后，欢迎关注我的个人公众号【 呼延十 】，会不定期更新很多后端工程师的学习笔记。 也欢迎直接公众号私信或者邮箱联系我，一定知无不言，言无不尽。 以上皆为个人所思所得，如有错误欢迎评论区指正。 欢迎转载，烦请署名并保留原文链接。 联系邮箱：huyanshi2580@gmail.com 更多学习笔记见个人博客或关注微信公众号 ------>呼延十 版权所有，盗版必究 all right reserved，powered by GitbookLast Modified On： 2021-10-17 02:51:50 "},"java/JVM/2019-08-15-JVM性能监控工具<深入了解JVM读书笔记>.html":{"url":"java/JVM/2019-08-15-JVM性能监控工具<深入了解JVM读书笔记>.html","title":"JVM性能监控工具<深入了解JVM读书笔记>","keywords":"","body":"目录 前言 了解了部分JVM运行的原理之后,就要进入实战环节啦.在实际工作中,我们既不需要去实现虚拟机,也不需要对垃圾收集或者内存分配过程进行DEBUG.但是我们经常需要对某个应用程序进行JVM层面的调优. 可能是因为我们的代码和JVM配合不够好,也可能是我们的代码直接就有问题,但是需要在JVM上找到错误的具体表现. 这时候需要对很多数据进行查看和处理,比如程序运行日志,GC日志,堆转储文件等等,为了更快更方便的理解这些信息,我们需要借助一些工具.这篇文章大概讲一下工具的使用. 工具包括JDK自带的命令行工具(重点),以及几个可视化分析工具,因为可视化的使用起来比较简单,所以可视化工具介绍的简单一点. JDK自带的命令行工具 JDK中自带了几个查看虚拟机运行状况的命令,包括jps,jinfo,jhat,jstat,jstack,jmap等.我们逐一看一下他们的作用. jps jps的功能比较简单,可以列出正在运行中的虚拟机,并且列出主类以及对应的进程ID. 虽然功能比较简单,但是却是最常用的一个命令,因为其他命令基本上依赖于此命令查询到的进程ID. jstat jstat是查看虚拟机各种运行状态信息的一个命令.它可以查看虚拟机中类加载,内存,GC,JIT编译等信息.在只有文本终端的服务器上,它是我们分析虚拟机运行情况的首选工具. jstat的命令格式为:jatat option vmid interval count. 其中: option: 选择相应查看的虚拟机信息.可选的参数有下表中的: . vimid: 想要查看的虚拟机进程ID. interval: 查询间隔. count: 总查询次数. 例如我们想要查看一个虚拟机的gc信息,每个1s查看一次,共查看10次.可以使用如下的命令. 其中s0,s1表示两个survivor的使用比例,E=Eden区使用了77.43%. O=老年代使用了0.58%. M=方法区使用了98%. 后面的分别表示YoungGC的次数和总占用时间,以及FullGc的次数以及总占用时间.以及所有GC的占用时间. jinfo jinfo的作用是实施的查看和调整虚拟机的各个参数. 可以使用jinfo -flags pid来查看所有的已配置参数. 也可以使用单独的参数名称进行查询. jmap jmap用来生成堆转储快照以及查看java堆以及永久代的详细信息.命令格式为: jmap [option] pid. 在下图中,我们可以拿到类以及他的实例数据: 下图中可以看到堆中各个区域的使用量: jhat jhat用于分析jmap生成的堆转储文件,但是一般不推荐使用,当需要分析堆转储文件的时候,我们一般会copy到本地进行,那时候有更强大的工具. jstack jstack用于生成当前虚拟机的线程快照. 线程快照是当前虚拟机内每一条线程正在执行方法的堆栈的集合. 我们可以根据线程快照分析线程停顿的原因,如分析死锁.死循环等等. 命令格式:jstack [option] pid. 由于线程的堆栈太多,我们这里打出前20行可以看到一个堆栈: 可以看到当前线程正在等待,且没有锁. 此外,在1.5之后,Thread类中添加了getAllStackTraces方法,我们可以用这个方法来实现类似于jstack的功能.所以在项目中我们可以用简单的几十行代码实现一个管理员界面来跟踪线程堆栈. JDK的可视化工具 在本地启动JVM,可以在JDK/bin目录下启动jconsole,或者VisualVM.可以打开图形界面,按照其中的引导,连接虚拟机,点击内存,线程等按钮即可查看当前虚拟机状态.这里就不展开了. 完。 ChangeLog 2019-08-16 完成 以上皆为个人所思所得，如有错误欢迎评论区指正。 欢迎转载，烦请署名并保留原文链接。 联系邮箱：huyanshi2580@gmail.com 更多学习笔记见个人博客------>呼延十 版权所有，盗版必究 all right reserved，powered by GitbookLast Modified On： 2019-08-16 14:30:54 "},"java/JVM/2019-07-30-JVM数据区域与垃圾收集<深入了解JVM读书笔记>.html":{"url":"java/JVM/2019-07-30-JVM数据区域与垃圾收集<深入了解JVM读书笔记>.html","title":"JVM数据区域与垃圾收集<深入了解JVM读书笔记>","keywords":"","body":"目录 目录 前言 自动内存管理机制 运行时数据区域 内存分配 虚拟机上对象的创建过程 创建的对象都包括了哪些信息? 对象内存的分配机制 垃圾收集 对哪些内存进行回收? 引用计数法 可达性算法 什么时候进行回收? 怎么进行回收呢? 标记清除 复制算法 标记-整理算法(Mark-Compact) 分代收集算法 垃圾收集器 参考文章 前言 周志明老师所著的《深入了解JAVA虚拟机》(后文简称\"书中\")可谓是java工程师进阶的必读书籍了.最近读了书中的第一二部分,也就是前五章,有很多收获.因此想要写一篇文章.来用自己理解到的知识来总结一下前五章. 虽然说是总结,但是仍然强烈推荐大家去看原著.原著并没有\"多出什么东西导致需要我进行总结\",而是每个小节都让我有所收获.但是我并不能全部记住书中所写,只能按照自己的思路记录,串联起来. 再次推荐一下大家阅读原著 自动内存管理机制 书中多次提到: Java和C++之间有一堵由内存动态分配和垃圾收集所围成的高墙,墙外的人想进去,墙里的人想出来. C/C++程序员对每一个对象的内存分配拥有绝对的控制权,但是这样就会很繁琐.Java程序员不用处理内存的分配,有JVM动态进行,在 出现内存泄漏的时候却比较难以排查. 根据所new的对象动态的进行内存分配,以及在合适的时间回收/释放掉不需要的对象,这就是JVM的自动内存管理机制. 运行时数据区域 JVM在执行java代码的时候,会将系统分配给他的内存划分为几个区域,来方便管理.比较经典的运行时数据区域图如下: 程序计数器: 程序计数器是一块比较小的线程独立的内存空间,它可以看成是当前线程执行的字节码的行号指示器. 虚拟机栈 虚拟机栈也是线程私有内存.每个方法在执行的时候都会创建一个\"栈帧\",里面存储了局部变量表,操作数栈,动态链接,方法出口等信息.可以理解为虚拟机栈存储了方法运行时需要的一些额外信息,一个\"栈帧\"的入栈出栈对应了一个方法的执行开始与结束. 本地方法栈 如果我们将上面的虚拟机栈理解为\"为了java方法的执行而记录一些内容\",那么本地方法栈就是为了Native方法二记录的.其他方面基本一致.虚拟机规范中对这一块的规定不严格,因此各个虚拟机的实现不同.著名的\"HotSpot\"把虚拟机栈和本地方法栈进行了合并. 堆 堆(Heap)是JVM内存中最大的一块,也是垃圾收集的主要工作区域.这块区域唯一的目的就是存放类的实例.堆中根据虚拟机的不同还有不同的区域划分,以便垃圾收集进行工作. 其中的详细区域划分在后面垃圾收集的地方会详细说明. 方法区 方法区也是一块线程共享区域,用于存储已经加载了的类信息,常量,静态变量,即时编译器编译后的代码等等. 他有一个更加响亮的名字\"永久代\",HotSpot虚拟机将方法区实现成了永久代,来避免单独为方法区实现垃圾收集.这一举动的利弊不是我个小菜鸡可以分析的,但是我们要理解为什么叫做永久代?因为这一区域存放的内容,垃圾收集的效率是比较低的(常量,静态变量等较少需要被回收),所以当数据进入此区域,就好像永久存在了一下. 这一区域里面还有一个单独的区域,运行时常量池,当类加载后,各种字面量和符号引用会进入此区域. 在程序运行期间,也是可以将新的常量放入常量池的,比如string.intern()方法. 直接内存 直接内存并没有在上图的JVM运行时数据区域中体现,而是一块额外的内存区域.在JDK1.4中引入的NIO中,可以直接通过Native方法在堆外分配内存.这样可以提高性能. 这块区域的大小不受到给虚拟机分配的内存大小的限制,但是总归也是受到物理机的内存限制的,因此,当出现OutOfMemoryError,且代码中有大量使用到NIO的时候,可以考虑到是这一块内存产生了溢出. 内存分配 虚拟机上对象的创建过程 说到对象的创建过程,也许我们都会想到那个很经典的题目:一个父类一个子类,几个静态方法几个普通方法,几个构造方法,问这些方法中的打印顺序. 但是不要误会,那些东西在现在并不重要了,需要机创建对象的过程要远比这复杂的多.简单概括如下: 当遇到new关键字的时候,首先检查常量池中是否可以找到,并且检查该类是否已经加载.如果没有,先加载类. 按照确定的大小去获取内存,获取的方法分为指针碰撞和 \b空闲列表. 指针碰撞:如果内存是整齐的,左边是使用过的,右边是空闲的,那么在分配空间的时候只需要移动一下指针即可. 空闲列表:如果内存是不规整的,使用过的和未使用的相互交错,那么JVM必须维护一个列表来记录哪些空间是可用的. 具体使用哪种方法来分配内存取决于使用的垃圾收集器,因为有些垃圾收集器带有整理内存的功能.那么就可以使用指针碰撞了. 拿到分配的空间之后,要将内存全部初始化为零值.(不包括对象头) 虚拟机设置对象信息,比如对象属于的类的信息,类的元数据信息,哈希码.GC分代信息等. 现在才是执行构造方法,依次设置各个字段的值. 在第二步其实还有一个问题,那就是并发问题,如果只有一个指针指在已经使用和未使用的内存之间,那么在频繁的创建过程中,一定有并发问题.虚拟机解决这个问题的办法主要有两种: CAS加上失败重试机制. TLAB. 本地线程分配缓冲,每个线程先从堆中申请一小块内存,然后在这一块内存上进行分配,这样只需要在申请TLAB的时候才需要进行同步,增大了处理并发的能力. 创建的对象都包括了哪些信息? 在HotSpot中, 对象信息包括: 对象头,实例数据和对齐填充. 对象头: 对象头中包括两部分信息,对象的运行数据(hash码,GC年龄等),类型指针(指明它是哪个类的实例). 实例数据: 这块的数据就是我们在代码中定义的那些字段等等. 对齐填充: 这块数据并不是必然存在的,当对象实例数据不是8字节的整数倍的时候,用空白字符对齐一下. 对象内存的分配机制 对象内存分配其实与选择的垃圾收集器,虚拟机启动参数等有很大的关系,因此并不能确定的说:XXX在XXX上分配.但是总归是有一些普适性的规则的. 优先在Eden分配 大多数的情况下,对象首先在Eden区域分配,当Eden区域空间不足的时候,虚拟机将会进行一次Minor GC(新生代GC). 大对象直接进入老年代 大对象(虚拟机提供了参数:-XX:PretenureSizeThreshold来调整大对象的阈值)会直接分配在老年代.由于新生代使用复制的垃圾收集算法,如果将大对象分配到新生代,可能会造成在两个Survivor区域之间发生大量的内存复制.影响垃圾收集的效率. 长期存活的对象进入老年代 每个对象都有一个年龄的计数器,当对象在eden出生并且经过一次minor GC还在新生代的话,年龄就加1. 当年龄到了15(默认值)时,会晋升到老年代中. 动态的年龄判断 上面到达年龄之后晋升到老年代并不是唯一的规则, 当Survivor空间中的相同年龄的对象的总大小的综合大于Survivor空间的一半,虚拟机会认为这个年龄是一个更加合适的阈值,会将年龄大于或者等于这个值的对象全部移到老年代中去. 分配担保 当minor GC即将发生时,虚拟机会检查老年代是否可以作为此次的分配担保(老年代中的连续内存大于新生代中存活所有对象的总和),如果成立,那么说明可以作为担保,进行minorGC. 如果不成立,那就检查虚拟机设置里面HandlePromotionFailure是否允许进行冒险,如果允许的话,则进行minorGC,否则则进行FullGC. 如果冒险失败了,那就进行一次FullGC来在老年代腾出足够的空间. 垃圾收集 说起垃圾收集,我们总是可以零碎的说上一些,因为JVM的应用太广泛了,除了Java开发者还有许多其他基于JVM的开发者也需要了解这些. 但是我们有没有系统的整理过这里呢? 垃圾收集,即将无用的内存释放掉,以提供给后续的程序使用.那么就有三个问题: 对哪些内存进行回收? 什么时候进行回收? 怎么进行回收? 我们一个一个问题的来看. 对哪些内存进行回收? 当然是对死掉的,即再也不会用到的对象进行回收. 怎么判断一个对象再也不会被用到了呢? 引用计数法 首先就是引用计数法,它的思想是给每个对象设置一个计数器,每当有一个别的地方引用到了这个对象,计加器就加1.当其他地方释放掉对它的引用时,就减1.那么计数器等于0的对象,就是不可能再被引用的对象了. 这个算法其实还可以,实现简单,判断速度快,但是主流的JVM实现里面没有使用这个方法的,因为它有一个比较致命的问题,就是无法解决循环引用的问题. 当两个对象互相引用,除此之外没有其他引用的时候,他们应该被回收,但是此时他们的计数器都为1.导致他们没有办法被回收. 我们用以下代码进行一下测试: public class ReferenceCountTest { public static final byte[] MB1 = new byte[1024 * 1024]; public ReferenceCountTest reference; public static void main(String[] args) { ReferenceCountTest a = new ReferenceCountTest(); ReferenceCountTest b = new ReferenceCountTest(); a.reference = b; b.reference = a; a = null; b = null; System.gc(); } } 运行参数为:+XX:PrintGC,输出结果[GC (System.gc()) 7057K->2294K(125952K), 0.0024641 secs],可以看到,内存被回收掉了,说明我使用的HotSpot虚拟机使用的不是引用计数法来判断对象存活与否. 可达性算法 这个算法的基本思想就是,通过一系列的GC ROOT来作为起点,从这些节点开始沿着引用链进行搜索,当一个对象到GCROOTS没有任何的可达路径,就认为此对象是可被回收的. 在上图中,object5,6,7虽然互相之间还有引用,但是由于从GCROOTS不可达,也是死掉的对象. 在Java中GCROOTS一般包括以下几种: 虚拟机栈中的栈帧中的本地变量表 常量引用 静态属性的引用 本地方法栈中Native方法的引用 什么时候进行回收? 这个问题其实比较复杂,且很多JVM的实现并不相同,我们粗略的以HotSpot为例说明一下. 首先我们要知道,垃圾收集是需要\"Stop The World\"的,因为如果整个JVM不暂停,那么就无法在某一瞬间确定哪些内存需要回收.就好像你妈妈给你打扫房间的时候会把你赶出去,因为如果你不断制造垃圾,是没有办法打扫干净的. 目前所有的JVM实现,在进行根节点的枚举(也就是确定哪些内存是需要回收的)这一步骤的时候都需要停顿,大家在做的只是尽可能的减少GC停顿来降低对系统的影响. 既然GC需要\"Stop The World\",但是一个运行中的先生并不是可以在随时随地停下来配合GC的. 所以当需要GC停顿的时候,需要给出一点时间,让所有线程运行到最近的\"安全点\"上.此外,为了解决在GC时有些线程处在挂起状态,安全点概念还有一个扩展的概念,安全区域,当线程进入到安全区域,就会挂起一个牌子,告诉别人在我摘下牌子之前,GC不用问我.而当线程想离开安全区域的时候,需要检查是否自己可以安全离开的标识. 怎么进行回收呢? 不同虚拟机的实现不一样,同一个虚拟机在堆上不同的区域执行的可能也不一样,不过总的来说,算法思想都是下面这几种. 标记清除 最基础的就是标记-清除(Mark-Sweep)了,该算法的过程和名字一样,首先标记所有需要回收的对象,之后对他们统一进行回收.如下图所示. 他的优点是: 思路简单且实现方便 缺点主要有两个: 1.效率不太高2.在图中回收后的状态里,由于是直接的清除,所以可用内存不连续,全是碎片化的,这样当后续需要分配大对象而无法找到连续足够的空间,就会提前触发下一次GC 后续的算法主要就是对 标记-清除算法的改进. 复制算法 为了解决上面的问题,出现了\"复制\"算法,复制算法将内存分为容量相等的两块,每次只使用其中的一块,当用完了,将其中存活的对象copy到另外一块内存上,然后对已经使用的这一块内存进行整体的回收. 这样可以使得回收和分配时不用考虑碎片问题,效率极大的提升了,但是,代价是永远只能使用一半的内存,这个代价太过于高昂了. 复制算法的执行过程如下图: 现代的商业虚拟机基本上都采用这个算法来回收新生代.因为新生代的垃圾回收比较的频繁,对于效率的要求更加高一些. 同时对复制算法进行了一些改良.经过统计,新生代的对象98%都是朝生夕死的,所以复制算法中的内存不需要按照1:1进行划分,而是划分为Eden:Survivor1:Survivor2=8:1:1(比例可调整)三块空间,每次使用Eden和一个 Survivor区域,当需要垃圾回收时,将其中存活的对象copy到另一个survivor中.然后对eden和已经使用survivor进行统一回收.这样相比于普通的复制算法,每次可以使用到90%的空间,浪费较小. 但是,survivor的内存大小是我们进行估算得到的,我们没有办法确保每次垃圾回收时存活的对象都小于10%,所以需要老年代进行分配担保.分配担保是指,如果survivor的空间不够用,可以在老年代里申请空间存放对象. 标记-整理算法(Mark-Compact) 复制算法在对象存活率较低是一种可靠的算法,但是当对象存活率较高,极端情况下,一次gc的时候,100%的对象都存活,那么复制算法的效率就不高了.因此在HotSpot的老年代中使用另外一种算法.即标记-整理算法. 标记-整理算法,首先仍然是和标记-清除算法一样的标记过程,但是之后并不进行直接的清除,而是将存活的对象整理的整齐一点,然后以边界为限,回收掉边界以外的内存.示意图如下: 分代收集算法 在上面的垃圾收集算法中也提到了新生代,老年代等概念,这就是由于现在的虚拟机都使用分代收集的算法. 分代的主要目的是:根据对象的存活周期不同,把内存区域分为几块,存放不同生命周期的对象,以方便根据特点使用不同的垃圾收集算法来提高内存回收效率. 比如新生代中对象存活率低,那么可以使用复制算法,每次copy少量的对象即可,且效率较高. 而老年代中的对象存活率高,并且没有人能为他做分配担保,因此必须使用标记-整理或者标记-清除算法. 所以在 HotSpot中,整个Java堆大致是如下的样子(新生代和老年代的比例默认为1:2): 垃圾收集器 Serial收集器 这是最基本也是最古老的的垃圾收集器,是一个单线程收集的过程,目前仍然是Client模式下的JVM的默认新生代收集器. 下图是他的收集过程: ParNew ParNew收集器是Serial收集器的多线程版本,除了使用多条线程进行垃圾收集之外,其余行为和Serial收集器一模一样.下图是他的收集过程: Parallel Scavenge收集器 这个收集器在定义上和ParNew非常相似,但是它主要关注的是提高系统的吞吐量.他的收集过程和ParNew相似. Serial Old Serial Old收集器是Serial收集器的老年代版本,使用了标记-整理算法.他的收集过程和Serial一样. Parallel Old 这是Parallel Scaevnge收集器的老年代版本,使用多线程进行标记-整理算法进行收集. 他的收集过程和Parallel Scavenge收集器一样. CMS收集器 Concurrent Mark Sweep 是一个以最短停顿时间为目的的收集器,他的收集过程更加复杂一点,分为四个步骤: 初始标记 并发标记 重新标记 并发清除 他的收集过程如下所示: G1收集器 G1收集器是发展的比较好的收集器,他的收集步骤大概有以下几个部分: 初始标记 并发标记 最终标记 筛选回收 他的收集过程图如下: 总结 垃圾收集器并不是可以无限搭配的,下面是他们的搭配图: 这里对垃圾收集器的介绍比较简略,主要是垃圾收集器实际上是一个很复杂的东西,但是是一个封装的很好的东西,里面的复杂不太需要知道,大部分时间我们用稳定的最新的研究成果即可.... 但是,我们应该了解一下,在感觉瓶颈出在了垃圾收集器的时候,有可以去详细研究的能力以及基础知识即可. 参考文章 完。 ChangeLog 2019-05-19 完成 以上皆为个人所思所得，如有错误欢迎评论区指正。 欢迎转载，烦请署名并保留原文链接。 联系邮箱：huyanshi2580@gmail.com 更多学习笔记见个人博客------>呼延十 版权所有，盗版必究 all right reserved，powered by GitbookLast Modified On： 2019-10-24 14:39:07 "},"java/2019-01-28-Java类加载的顺序.html":{"url":"java/2019-01-28-Java类加载的顺序.html","title":"Java类加载的顺序","keywords":"","body":"前言 那一年,呼延十又回想起被加载顺序支配的恐惧,笔试题上,好几个类,几个方法,几个输出语句,让你按照顺序写出输出.我真的是有一句.... 但是呢,我们还是有了解一下的必要的,在编码过程中有许多的应用. 正文 经常用来比较顺序的,无非就是静态代码块,普通代码块,静态方法和普通方法. 这里直接说一下结论: 先静态后普通最后构造方法,先父类后子类. 看一下实际的例子: package daily; /** * created by huyanshi on 2019/1/28 */ public class ClassLoadOrder { public static void main(String[] args) { B b = new B(); } } class A { private int i = aFunc(); static { System.out.println(\"A-----static\"); } public int aFunc() { System.out.println(\"A----- default\"); return 1; } public A() { System.out.println(\"A----- constructor\"); } } class B extends A { private static int i1 = staticFunc(); public B() { System.out.println(\"B----- constructor\"); } static { System.out.println(\"B----- static\"); } private int i = bFunc(); private static int staticFunc(){ System.out.println(\"B----- static func\"); return 111; } public int bFunc() { System.out.println(\"B----- default\"); return 2; } } 他的输出是什么呢? A-----static B----- static func B----- static A----- default A----- constructor B----- default B----- constructor 我们来跟随顺序一步一步来一下: 首先在main方法中,调用了B类的构造方法. 由于B类有父类,因此先加载A类. 加载A类的静态代码块,输出A-----static. 加载B类的静态变量,调用了方法,输出B----- static func. 加载B类的静态代码块,输出B----- static. 加载A类的普通变量,private int i = aFunc();由于调用了方法,因此输出A----- default. 加载A类的构造方法,输出A----- constructor. 加载B类的普通变量,调用了方法,输出B----- default. 加载B类的构造方法,输出了B----- constructor. 这些其实是一些记忆内容啦. 在这期间,发现一些小的知识点,也记录一下. 静态变量,静态代码块的加载顺序只和代码编写的顺序有关. 普通变量及构造方法,顺序一定是先普通变量,再构造方法的. 说好的应用呢 其实我目前对这个知识点应用最多的就是静态代码块. 经常在编码过程中需要给常量的List,Map赋值,这个时候我们希望程序启动赋值一次即可,而程序中的其他方法可能就需要使用这些常量了,因此一般使用定义常量Map,并在静态代码块中给其赋值.这样可以保证后续的使用不会拿到空的Map,也保证了只加载这些默认值一次. 完. ChangeLog 2019-01-28 以上皆为个人所思所得，如有错误欢迎评论区指正。 欢迎转载，烦请署名并保留原文链接。 联系邮箱：huyanshi2580@gmail.com 更多学习笔记见个人博客------>呼延十 版权所有，盗版必究 all right reserved，powered by GitbookLast Modified On： 2019-03-26 11:07:51 "},"java/2019-01-20-使用自定义注解实现接口参数校验.html":{"url":"java/2019-01-20-使用自定义注解实现接口参数校验.html","title":"使用自定义注解实现接口参数校验","keywords":"","body":"1.前言 在接口的开发中,我们有时会想让某个接口只可以被特定的人(来源)请求,那么就需要在服务端对请求参数做校验. 这种情况我们可以使用interceptor来统一进行参数校验,但是如果很多个接口,有不同的的设定值,我们总不能写很多个interceptor,然后按照path逐一添加吧? 面对这种情况,我们可以选择自定义一个注解,由注解来告诉我们,这个接口允许的访问者是谁. 注:在本文的示例中,仅实现了对某一个字段的校验,安全性并不高,实际项目中,可以采用多字段加密的方式,来保证安全性,原理和文中是一样的. 2.java 注解介绍 Java Annotation是JDK5.0引入的一种注释机制。 Annotation是代码里的特殊标记，这些标记可以在编译、类加载、运行时被读取，并执行相应的处理。 通过使用Annotation，程序员可以在不改变原有逻辑的情况下，在源文件中嵌入一些补充信息。 Annotation可以像修饰符一样被使用，可以用于package、class、interface、constructor、method、member variable(成员变量)、parameter、local variable(局部变量)、annotation(注解)，jdk 1.8之后，只要出现类型(包括类、接口、注解、枚举)的地方都可以使用注解了。 我们可以使用JDK以及其它框架提供的Annotation，也可以自定义Annotation。 3.元注解(meta-annotation) 元注解是什么呢?在我的理解里,元注解是java官方提供的,用于修饰其他注解的几个属性. 因为开放了自定义注解,所以所有的注解必须有章可循,他们的一些属性必须要被定义.比如:这个注解用在什么地方?类上还是方法上还是字段上?这个注解的生命周期是什么?是保留在源码里供人阅读就好,还是会生成在class文件中,对程序产生实际的作用?这些都需要被提前定义好,因此就有了: 这四个元注解@Target、@Retation、@Inherited、@Documented. 接下来对四个元注解逐一说明 @Target 用于描述注解的使用范围（即：被描述的注解可以用在什么地方） 他的取值范围JDK定义了枚举类ElementType,他的值共有以下几种: CONSTRUCTOR:用于描述构造器 FIELD:用于描述域即类成员变量 LOCAL_VARIABLE:用于描述局部变量 METHOD:用于描述方法 PACKAGE:用于描述包 PARAMETER:用于描述参数 TYPE:用于描述类、接口(包括注解类型) 或enum声明 注:在JDK1.8,新加了两种类型, TYPE_PARAMETER:表示这个 Annotation 可以用在 Type 的声明式前， TYPE_USE 表示这个 Annotation 可以用在所有使用 Type 的地方 @Retention 表示需要在什么级别保存该注释信息，用于描述注解的生命周期（即：被描述的注解在什么范围内有效） 他的取值范围来自于枚举类RetentionPolicy,取值共以下几种: SOURCE:在源文件中有效（即源文件保留） CLASS:在class文件中有效（即class保留） RUNTIME:在运行时有效（即运行时保留） @Documented @Documented用于描述其它类型的annotation应该被作为被标注的程序成员的公共API，因此可以被例如javadoc此类的工具文档化。Documented是一个标记注解，没有成员。 @Inherited 　@Inherited 元注解是一个标记注解，@Inherited阐述了某个被标注的类型是被继承的。如果一个使用了@Inherited修饰的annotation类型被用于一个class，则这个annotation将被用于该class的子类。 4.常见注解 常用的第三方框架实现了非常多的注解,比如Mybatis的Param,Spring的Component,Service,fastjson的JSONfield等等. 具体的实现方法这里不多解释了,有兴趣的朋友可以去看一下fastjson的源码,该项目相比spring等框架,简单一些也更容易理解. 看到这种注解或简单或复杂的功能之后,我们是否也可以自己来动手实现一个呢? 5.自定义注解 5.1.定义注解 首先我们来定义注解: package com.huyan.demo.config; import java.lang.annotation.Documented; import java.lang.annotation.ElementType; import java.lang.annotation.Retention; import java.lang.annotation.RetentionPolicy; import java.lang.annotation.Target; /** * created by huyanshi on 2019/1/20 */ @Target(ElementType.METHOD) // 该注解使用在方法上 @Retention(RetentionPolicy.RUNTIME) //运行时注解 @Documented public @interface CheckSource { //该注解的参数,是一个string数组 String[] sources() default {\"all\"}; } 我们需要的注解用于校验参数,因此它的使用范围是方法,生命周期是运行时保留.此外,注解有一个类型为string数组的参数,用来表示当前方法允许的source列表. 5.2.编写注解解析器 其实一开始我在这里纠结了许久,因为我不能理解一个注解应该在哪里以什么方式调用. 按照我的思路,每个注解应该有一个字段(或者类似的东西),来指示应该去哪里调用这个注解的真正使用. 后来经过细细思考,发现这是不现实的,因为注解的作用完全没有规律可言,你可以实现任何你想要的功能,返回值可以使任意值,里面的逻辑也是任意的. 那么就意味着,你需要为你的注解负责,否则他没有任何作用.也就是说,你需要为自己的注解编写注解解析器,来定义什么时候用到这个注解,用它干什么? @纯个人观点,慎看经过在网上冲浪,我发现注解解析器的主要形式有三种: 1.interceptor 这种方式比较方便,可以直接拦截所有的请求,检查该请求进入的类及方法上有没有特定的注解,如果有怎么怎么操作一波. 但是局限性比较大,我们又不是只在controller里面会用到注解. 2.AOP 这种方式也比较方便,扩展性比较好,当你需要在新的地方用到该注解,新增一个切点就好. 3.封装成方法,随时调用 这种是大部分人喜闻乐见的(其实最喜闻乐见的是每次用到就写一遍呗),但是如果不经常重构一下代码,你会发现导出充满了你对某一个注解的使用代码,那就很崩溃了,你需要尽量将其封装一下,放在统一的工具类,每次需要的时候调用即可. @个人观点结束! 由于我们这次的需求是拦截不合法的请求,所以当然是第一种方式比较靠谱,因此我们写了一个拦截器: package com.huyan.demo.config; import javax.servlet.http.HttpServletRequest; import javax.servlet.http.HttpServletResponse; import org.slf4j.Logger; import org.slf4j.LoggerFactory; import org.springframework.web.method.HandlerMethod; import org.springframework.web.servlet.handler.HandlerInterceptorAdapter; /** * created by huyanshi on 2019/1/20 */ public class CheckSourceInterceptor extends HandlerInterceptorAdapter { private static Logger LOG = LoggerFactory.getLogger(CheckSourceInterceptor.class); @Override public boolean preHandle(HttpServletRequest request, HttpServletResponse response, Object handler) throws Exception { if (!(handler instanceof HandlerMethod)) { LOG.warn(\"UnSupport handler\"); throw new IllegalArgumentException(\"Interceptor only supports HandlerMethod handler\"); } //拿到请求参数里面的source参数 String source = request.getParameter(\"source\"); String errorMsg = null; //如果source为空,返回错误 if (null == source || \"\".equals(source)) { errorMsg = \"No source in params\"; } if (errorMsg != null) { response.setStatus(500); LOG.info(errorMsg); response.getWriter().write(errorMsg); return false; } //拿到该方法上的注解对象 CheckSource checkSource = getCheckSource((HandlerMethod) handler); //如果拿到的对象为空,说明没有此注解,直接放行 if (checkSource != null) { //拿到注解对象的属性,即允许通行的source列表 String[] sources = checkSource.sources(); if (sources.length == 0 || sources[0].equals(\"all\")) { //列表为空或者为默认值,放行 return true; } //遍历列表,如果传入的参数在其中,则放行 for (String s : sources) { if (s.equals(source)) { return true; } } //如果传入的source参数不在允许的参数列表中,则拦截请求,并返回错误信息 errorMsg = \"source is not support\"; response.getWriter().write(errorMsg); return false; } return true; } /** * 拿到该方法上的checksource注解对象 */ private CheckSource getCheckSource(HandlerMethod handlerMethod) { if (handlerMethod.getBeanType().isAnnotationPresent(CheckSource.class)) { return handlerMethod.getBeanType().getAnnotation(CheckSource.class); } else if (handlerMethod.getMethod().isAnnotationPresent(CheckSource.class)) { return handlerMethod.getMethod().getAnnotation(CheckSource.class); } return null; } } 代码中添加了比较详细的注释,这里只写一下大概的思路: 通过拦截器的机制,拿到该方法上的CheckSource对象,该对象可能为空,不为空的时候拿到它的sources属性,之后依次遍历,判断传入的source是否在允许的列表中. 在这个拦截器中,我们定义了: 1.何时使用这个注解? 在我们配置的,使用这个拦截器的时候,进入controller层的某一个方法时. 2.怎么使用这个注解? 拿传入的source参数和这个注解的属性sources列表一一匹配,有匹配上的则允许请求,无匹配值则返回错误信息. 5.3.实际使用注解 5.3.1.首先配置这个拦截器,拦截status接口 package com.huyan.demo.config; import org.springframework.context.annotation.Configuration; import org.springframework.web.servlet.config.annotation.InterceptorRegistry; import org.springframework.web.servlet.config.annotation.WebMvcConfigurer; /** * created by huyanshi on 2019/1/20 */ @Configuration public class WebMvcConfig implements WebMvcConfigurer { CheckSourceInterceptor checkSourceInterceptor = new CheckSourceInterceptor(); @Override public void addInterceptors(InterceptorRegistry registry) { registry.addInterceptor(checkSourceInterceptor).addPathPatterns(\"/status\"); } } 5.3.2.status接口 package com.huyan.demo.controller; import com.huyan.demo.config.CheckSource; import org.slf4j.Logger; import org.slf4j.LoggerFactory; import org.springframework.web.bind.annotation.GetMapping; import org.springframework.web.bind.annotation.RequestParam; import org.springframework.web.bind.annotation.RestController; /** * created by pfliu on 2018/9/2 */ @RestController public class StatusController { private Logger logger = LoggerFactory.getLogger(this.getClass()); @CheckSource(sources = {\"huyan\", \"huihui\"}) @GetMapping(value = \"/status\") public Object status(@RequestParam(\"source\") String source) { return \"哈哈哈\"; } } 好,编码全部完成了. 启动项目,看一下结果. 5.3.3.测试结果 不带source参数 错误的source参数 正确的source参数 6.总结 java的注解机制并不算太难理解,但是重点是,我们日常中很难想到去应用他,一来是因为我们对其不够熟悉,二来是我们的业务,没有那么通用的逻辑. 注解机制被大量的使用在各种框架中,足以证明他是一种优秀的机制,值得我们去学习并努力的应用在自己的工作中. 7.参考链接 https://josh-persistence.iteye.com/blog/2226493 https://www.ibm.com/developerworks/cn/java/j-lo-java8annotation/index.html 完。 ChangeLog 2019-01-20 完成 以上皆为个人所思所得，如有错误欢迎评论区指正。 欢迎转载，烦请署名并保留原文链接。 联系邮箱：huyanshi2580@gmail.com 更多学习笔记见个人博客------>呼延十 版权所有，盗版必究 all right reserved，powered by GitbookLast Modified On： 2019-05-01 17:15:59 "},"java/2018-09-09-String-StringBuilder-StringBuffer异同.html":{"url":"java/2018-09-09-String-StringBuilder-StringBuffer异同.html","title":"String-StringBuilder-StringBuffer异同","keywords":"","body":" 字符串在编程中使用的非常频繁，同时又是面试中的常见题型，那么我们的对字符串相关类String，StringBuilder，StringBuffer的理解真的正确吗？今天就通过对三个类源码的阅读，来进一步加强理解。 目录 String概述 StringBuilder 和StringBuffer 异同 性能比较 结论 扩展(详细源码阅读及方法解析) String概述 ![](http://img.couplecoders.tech/Fi_sBbtlLREpBuY49ajeMrLaildf.png) 打开String类的源码，可以发现String类是被final所修饰的，因此String类不可以被继承。 同样的，用来保存值得char数组 value也是被final修饰的，这就可以得出关于String的一个很重要的结论。 **String是字符串常量，值是不可改变，通常我们对String的操作都是通过new一个新的String对象来完成的** 如下图中的subString方法和replace方法。 ![substring](http://img.couplecoders.tech/markdown-img-paste-20180921000114583.png) ![replace](http://img.couplecoders.tech/markdown-img-paste-20180921000240260.png) StringBuilder和StringBuffer 既然已经有了String这个功能完备的嘞，那么为什么还需要StringBuilder和StringBuffer呢？ 让我们来看一下这两个类的源代码： 可以看出，这两个类共同继承于AbstractStringBuilder，那么打开这个类的源码看一下： 可以看到，这个抽象类中也是以char数组的形式来保存字符串，但是，这个数组是可变的，我们看一下append方法的代码： append()是最常用的方法，它有很多形式的重载。上面是其中一种，用于追加字符串。如果str是null,则会调用appendNull()方法。这个方法其实是追加了'n'、'u'、'l'、'l'这几个字符。如果不是null，则首先扩容，然后调用String的getChars()方法将str追加到value末尾。最后返回对象本身，所以append()可以连续调用。 那么StringBuffer、StringBuilder的区别在哪里呢？ 这是StringBuffer的length方法和capacity方法。 这是AbstractStringBuilder的length方法和capacity方法(Stringbuilder没有进行重写)。 很明显，Stringbuffer对大部分方法添加了 synchronized关键字，来保证线程安全。 异同 从上面的一些源码中可以简单分析出String，StringBuilder，StringBuffer的一些异同点，如下： String是常量，不可改变，StringBuffer、StringBuilder是变量，值是可变的 StringBuilder是线程不安全的，而StringBuffer线程安全。 String是常量，线程当然安全。 性能比较 说了这么多，在实际应用过程中，到底应该注意点什么呢？ 下面来实际测试一下： public Map> stringAnalytics() { Map> result = new HashMap<>(); Map time = new HashMap<>(); long pre = System.currentTimeMillis(); String s = \"\"; for (int i = 0; i 在上面的代码，分别使用String，StringBuilder，StringBuffer进行了50000的字符串拼接操作(String使用+方法，其他两个类使用append方法)，每次拼接的值为当前循环的数字。在该部分执行前后记录当前系统时间，最后算出消耗时间。 得到的结果如下图： String消耗16.153秒 StringBuilder消耗0.005秒 StringBuffer消耗0.013秒 结论 终于到了喜闻乐见的结论时候： PS:以下结论使用于大部分情况，实际编译编码过程中会有编译优化等原因稍微影响结论，但不能代表大多数。 1.当字符串改动较小的时候，使用String原因：方便且线程安全 2.当字符串需要频繁进行改动，且单线程使用StringBuilder原因：由5中可知，StringBuilder是效率最高的了。 3.当字符串需要频繁改动，且多线程调用。使用StringBuffer原因：StringBuffer中添加了对多线程应用时的保护，可以保证线程安全，且性能下降并不严重，在可接受范围内。 ChangeLog 2018-09-22 完成 以上皆为个人所思所得，如有错误欢迎评论区指正。 欢迎转载，烦请署名并保留原文链接。 联系邮箱：huyanshi2580@gmail.com 更多学习笔记见个人博客------>呼延十 版权所有，盗版必究 all right reserved，powered by GitbookLast Modified On： 2019-03-26 11:07:51 "},"java/2018-11-11-Java的键盘输入方法.html":{"url":"java/2018-11-11-Java的键盘输入方法.html","title":"Java的键盘输入方法","keywords":"","body":"在工作中其实很少用到java读取键盘输入的情况，但是在各种网站刷题时却经常碰到，同时，在日常写一些测试方法的时候，如果通过键盘读取输入也是十分方便的，因此简要的做一个总结，方便后续查看及使用。 System.in的read方法 public static void input1() throws IOException { int i = System.in.read(); System.out.println(i); } 这种方式及其简单，但是只能读入一个字符，且必须是字符类型，输出int类型的话比较麻烦。但是可以比较方便的获取该字符的ascall码。 InputStreamReader和BufferedReader方法 public static void input2() throws Exception{ InputStreamReader is = new InputStreamReader(System.in); BufferedReader br = new BufferedReader(is); String name = br.readLine(); System.out.println(\"ReadTest Output:\" + name); } 输出结果如下： 这种方式可以读取一个字符串，但是如果需要读取int，float等类型仍需要自己转换。 Scanner类 public static void input3() throws Exception { Scanner sc = new Scanner(System.in); int i = sc.nextInt();//读取int float f = sc.nextFloat();//读取float String s = sc.nextLine();//读取字符串 System.out.println(i); System.out.println(f); System.out.println(s); } 这种方式使用java5之后添加的Scanner类，Scanner类提供了读取int，float及字符串的方法，使用十分方便。 同时，Scanner不仅可以读取键盘输入值，也可以读取文件内容，只需要将构造方法中的数据来源切换成该文件即可。 参考链接 https://blog.csdn.net/u012249177/article/details/49586383 完。 ChangeLog 2018-11-11 完成 以上皆为个人所思所得，如有错误欢迎评论区指正。 欢迎转载，烦请署名并保留原文链接。 联系邮箱：huyanshi2580@gmail.com 更多学习笔记见个人博客------>呼延十 版权所有，盗版必究 all right reserved，powered by GitbookLast Modified On： 2019-05-13 22:49:14 "},"java/2019-04-28-使用nio来读写文件.html":{"url":"java/2019-04-28-使用nio来读写文件.html","title":"使用nio来读写文件","keywords":"","body":"Java读写文件在之前都是使用outputstream那一套,是在是有点烦.. 这次需要写个小功能,需要读取文件的每一行进行某个操作之后再写入到一个新文件中去,因此各种搜索之后使用了nio中对文件的一些操作,至少是美观且大方了起来,因此记录下来,防止后面再需要的时候找不到. import mian.AbstractMain; import java.io.IOException; import java.nio.file.FileSystems; import java.nio.file.Files; import java.nio.file.Path; import java.nio.file.StandardOpenOption; import java.util.Collections; /** * Created by pfliu on 2019/04/28. */ public class NioTest extends AbstractMain { public static void main(String[] args) { new NioTest().parseArgsAndRun(args); } @Override public void run() throws IOException { Path source = FileSystems.getDefault().getPath(\"/Users/pfliu/study/test/source\"); Path target = FileSystems.getDefault().getPath(\"/Users/pfliu/study/test/target\"); Files.lines(source).forEach(per -> { logger.info(\"line: {}\", per); try { Files.write(target, Collections.singleton(per), StandardOpenOption.APPEND); } catch (IOException e) { e.printStackTrace(); } }); } } 通过上面简单的操作,就实现了对文件1的按行读取并写入文件2,当然中间可以掺杂你想要的任何操作. 完。 ChangeLog 2019-04-28 完成 以上皆为个人所思所得，如有错误欢迎评论区指正。 欢迎转载，烦请署名并保留原文链接。 联系邮箱：huyanshi2580@gmail.com 更多学习笔记见个人博客------>呼延十 版权所有，盗版必究 all right reserved，powered by GitbookLast Modified On： 2019-04-28 22:54:54 "},"java/2018-03-10-java8-接口的静态方法和默认方法.html":{"url":"java/2018-03-10-java8-接口的静态方法和默认方法.html","title":"接口的静态方法和默认方法","keywords":"","body":"java8的接口中可以有default方法及static方法。普通的抽象方法不可以有实现，实现此接口的类必须实现所有抽象方法。默认方法必须有实现，实现此接口的类默认继承此方法，当然你也可以覆盖默认方法。（不实现此方法会默认继承，并不会报错）。静态方法必须有实现。但是实现此接口的类无法实现静态方法。 举一个小栗子： public class DefaultInterfaceTest { private static final LoggerSimpleFromPfliu log = new LoggerSimpleFromPfliu( DefaultInterfaceTest.class); public static void main(String args[]) { TestInterface.staticMethod(); DefaultInterfaceTest defaultInterfaceTest = new DefaultInterfaceTest(); defaultInterfaceTest.test(); } private void test() { TestClass testClass = new TestClass(); testClass.abstractmethod(); testClass.defaultMethod(); } private class TestClass implements TestInterface { @Override public void abstractmethod() { log.debug(\"abstract\"); } } public interface TestInterface { void abstractmethod(); default void defaultMethod() { log.debug(\"default\"); } static void staticMethod() { log.debug(\"static\"); } } } 程序执行结果是：staticabstractdefault 版权所有，盗版必究 all right reserved，powered by GitbookLast Modified On： 2019-03-26 11:07:51 "},"java/2019-05-11-用int来表示多个bool判断.html":{"url":"java/2019-05-11-用int来表示多个bool判断.html","title":"用int来表示多个bool判断","keywords":"","body":"背景介绍 位操作,想必大家在学习计算机基础知识的时候都有所接触过,但是日常却老是想不起来使用,今天就提供一个使用的思路. 我们经常需要表示多个bool变量,比如:当一个人秃头并且背着双肩包,穿着格子衬衫,我们就叫他程序员,羞辱一下他. 那么正常的情况下,我们需要些三个if/else来实现这个操作: if(tutou){ if(hasAshuangjianbao){ if(inTShirt){ System.out.println(\"this is a programer\"); } } } 当条件逐渐增多,这样的代码会越来越难看.因此我们考虑一下使用bit. int表示bool 一个int在java中是4个字节,也就是工32bits.每一个bit有0,1两种状态,那么就可以表示true/false两种状态. 那么我们设计一下: 第一位表示是否是秃头,为1的时候为真.换算成int就是0代表不秃头,1代表秃头. 第二位表示是否背着双肩包.为10,11的时候表示有,01,00表示没有. 第三位表示是否穿子格子衬衫,1表示有,对应的序列为110,111,101,100四种,0表示没有010,011,001,000表示没有. 发现规律了吧,当我们要表示三个布尔值时,总共有8中可能的序列,正好对应了三种状态的排列组合,2 * 2 * 2 = 8. 我们想表示一个人,没有秃头,穿着格子衬衫,背着双肩包使用的序列是110,对应int中的6. 或 | 通过或我们可以拿到多个状态的并集.比如 1,2,4进行或操作之后,拿到的是111也就是7,所以7可以代表三个状态全部为真. 与 & 通过 & 操作可以拿到给定结果(|操作拿到的)和给定状态(你选一个咯)的并集.比如上面拿到的7,你想验证是否满足秃头(1),那么执行7 & 1拿到的结果如果为1即满足. 即result & tag = = tag. 原理清楚了我们看一下代码实现. import mian.AbstractMain; /** * Created by pfliu on 2019/05/09. */ public class BitIntTest extends AbstractMain { public static void main(String[] args) { new BitIntTest().parseArgsAndRun(args); } @Override public void run() { int flag = 0; flag |= 1; System.out.println(Flag.isSet(flag, Flag.TU_TOU)); System.out.println(Flag.isSet(flag, Flag.INAPACKAGE)); flag |= 2; System.out.println(Flag.isSet(flag, Flag.INAPACKAGE)); System.out.println(Flag.isSet(flag, Flag.TU_TOU)); System.out.println(Flag.isAllSet(flag,Flag.TU_TOU,Flag.INAPACKAGE)); flag |= 3; System.out.println(Flag.isAllSet(flag, Flag.INAPACKAGE, Flag.TU_TOU, Flag.INTSHIRT)); } public static final class Flag { static int TU_TOU = 1; static int INAPACKAGE = 2; static int INTSHIRT = 4; public static boolean isSet(int flag, int tag) { return (flag & tag) == tag; } public static boolean isAllSet(int flag, int... tags) { int tag = 0; for (int i : tags) { tag |= i; } return (flag & tag) == tag; } } } 比较核心的就是Flag内部类,我们在其中实现了两个方法. isSet: 验证是否满足给定的tag.比如6 & 1,那就是不满足.5 & 1就是满足. isAllSet. 验证是否满足给定的所有条件,这里用了一个可变参数的方法.首先对所有给定的tag相|,然后重复1中的操作. JDK中的实现 在java.lang.reflect包中,有一个Modifier类.使用的就是这个思想. 这个类位于反射包中,主要是用于,在反射过程中,拿到的方法,变量等等,然后通过这个类来识别他们的修饰符,public/static/native等等. 因为这些修饰符可能是冲突的,可能是可以并存的,因此使用这种实现方法. 下面是类中对于修饰符的常量定义.(使用16进制是为了好看.看起来更加的直观). public static final int PUBLIC = 0x00000001; public static final int PRIVATE = 0x00000002; public static final int PROTECTED = 0x00000004; public static final int STATIC = 0x00000008; public static final int FINAL = 0x00000010; public static final int SYNCHRONIZED = 0x00000020; public static final int VOLATILE = 0x00000040; public static final int TRANSIENT = 0x00000080; public static final int NATIVE = 0x00000100; public static final int INTERFACE = 0x00000200; public static final int ABSTRACT = 0x00000400; public static final int STRICT = 0x00000800; 写一段代码测试一下: import java.lang.reflect.Field; import java.lang.reflect.Modifier; /** * Created by pfliu on 2019/05/10. */ public class ModifiersTest { private static int age = 999; public static void main(String[] args) throws NoSuchFieldException { Field myAge = ModifiersTest.class.getDeclaredField(\"age\"); int ageMod = myAge.getModifiers(); System.out.println(\"打印十进制:\" + ageMod); System.out.println(\"是否是private:\" + Modifier.isPrivate(age)); System.out.println(\"是否是final:\" + Modifier.isFinal(age)); } } 打印结果为: 打印十进制:10 是否是private:true 是否是final:false 原理和上面自己实现的类似,这里不再赘述.有兴趣的胖友可以查看JDK源码学习一下,这个类比较简单. ChangeLog 2019-05-09 完成 以上皆为个人所思所得，如有错误欢迎评论区指正。 欢迎转载，烦请署名并保留原文链接。 联系邮箱：huyanshi2580@gmail.com 更多学习笔记见个人博客------>呼延十 版权所有，盗版必究 all right reserved，powered by GitbookLast Modified On： 2019-05-10 09:37:54 "},"java/2019-05-10-监听nginx日志实现博客访问计数.html":{"url":"java/2019-05-10-监听nginx日志实现博客访问计数.html","title":"监听nginx日志实现博客访问计数","keywords":"","body":"前言 以前看到别人的博客的浏览人数xxx,很是羡慕,自己也想搞一个. 但是由于我的博客项目,是基于Jekyll的,是一个静态的站点,也就是说没有普通Web项目的后端部分. 如果是普通的web项目,那么只需要在每次访问的时候在service里面进行计数即可. Jekyll实现的博客项目还有一种更加受欢迎的做法,就是在前端完成这些,当用户加载页面的时候,前端去请求某一个API,然后进行计数并且返回一个热度值. 我的JS又写的不太好,所以我决定通过分析Nginx来实现. 实现 博客站点的所有请求都会经过Nginx进行访问,而Nginx是有日志记录的,主要包含以下几个信息: 访问来源的Ip 被访问页面 访问来源网址 请求的类型返回值等等信息. 分析需求发现,我们想要实现某篇文章的热度统计,以上几个信息就够了. 监听Nginx日志 nginx日志在默认情况下,会无限追加至/var/log/nginx/access.log中,那么我们可以通过监听文件来实现. 这块没有使用一些现成的实现,自己瞎写的.主要思路是: 记录当前文件的大小. 每隔10秒读一次文件的大小并且判断是否有新内容. 如果有新内容,则读取新内容,并将其解析,使用redis的string类型来存储访问量.因为redis的string类型也支持incr操作,比较方便. 实现代码如下: import org.slf4j.Logger; import org.slf4j.LoggerFactory; import org.springframework.beans.factory.annotation.Value; import org.springframework.stereotype.Component; import redis.clients.jedis.Jedis; import javax.annotation.PostConstruct; import java.io.File; import java.io.RandomAccessFile; import java.net.URLDecoder; import java.time.LocalDate; import java.time.LocalDateTime; import java.util.concurrent.Executors; import java.util.concurrent.ScheduledExecutorService; import java.util.concurrent.TimeUnit; import java.util.regex.Matcher; import java.util.regex.Pattern; /** * Created by pfliu on 2019/05/07. */ @Component public class NginxLogListener { @Value(\"${nginx.log.path}\") private String fileName; @Value(\"${redis.url}\") private String redisUrl; private final static Logger logger = LoggerFactory.getLogger(NginxLogListener.class); private static long lastFileSize; private static String LAST_FILE_SIZE_KEY = \"last_file_size_key\"; private static String LOG_REGIX = \"([^ ]*) ([^ ]*) ([^ ]*) (\\\\[.*\\\\]) (\\\\\\\".*?\\\\\\\") (-|[0-9]*) (-|[0-9]*) (\\\\\\\".*?\\\\\\\") (\\\\\\\".*?\\\\\\\")\"; @PostConstruct public void listen() { final File logFile = new File(fileName); Jedis jedis = new Jedis(redisUrl); logger.info(\" execute the default constructor\"); lastFileSize = Long.valueOf(jedis.get(LAST_FILE_SIZE_KEY) == null ? \"0\" : jedis.get(LAST_FILE_SIZE_KEY)); ScheduledExecutorService executorService = Executors.newScheduledThreadPool(1); executorService.scheduleWithFixedDelay(() -> { try { Thread.currentThread().setName(\"right-thread\"); long len = logFile.length(); if (len lastFileSize) { //指定文件可读可写 RandomAccessFile randomFile = new RandomAccessFile(logFile, \"rw\"); randomFile.seek(lastFileSize);//移动文件指针位置 String tmp = \"\"; while ((tmp = randomFile.readLine()) != null) { // 文件有更新的时候读取全部更新 String log = new String(tmp.getBytes(\"utf-8\")); parseLog(log, jedis); logger.info(\"new log:\" + log); } lastFileSize = randomFile.length(); jedis.set(LAST_FILE_SIZE_KEY, lastFileSize + \"\"); randomFile.close(); } } catch (Exception e) { logger.error(\" read file error,now = {}\", LocalDateTime.now().toString(), e); } finally { } }, 0, 10, TimeUnit.SECONDS); } // 解析一条日志 private void parseLog(String log, Jedis jedis) { try { Pattern p = Pattern.compile(LOG_REGIX); Matcher m = p.matcher(log); while (m.find()) { // 使用正则表达式进行匹配,之后逐一拿到需要的字段 String ip = m.group(1); String page = m.group(5).replace(\"\\\"GET \", \"\").replace(\"HTTP/1.1\\\"\", \"\").trim(); if (page.startsWith(\"/\") && page.endsWith(\"/\")) { logger.info(\"current thread :\" + Thread.currentThread().getName()); logger.info(\"save : ip = {}, page = {}\", ip, page); jedis.incr(LocalDate.now().toString()); jedis.incr(decode(page).toLowerCase()); } } } catch (Exception e) { logger.error(\"parse error, log={}.\", log, e); } } //对url中进行解码,url会将中文变成GBK编码 public String decode(String s) { try { return URLDecoder.decode(s, \"utf-8\"); } catch (Exception e) { logger.error(\"decode error.s = {}, e= {}\", s, e.getMessage(), e); } return \"decode-wrong\"; } } 其中主要的代码在parseLog方法中,在redis中对当前页面的key进行一次incr操作,同时对当前日期的key进行加1操作,这样可以顺便统计今天的访问量. 这里还可以使用redis的hyperLogLog数据结构,对每个页面进行唯一ip的统计,可以统计拿到多少ip访问过此页面,这个我没有做. 提供对外API 这块比较简单,一个简单的接口就可以,接口内部读取redis. 代码如下: import com.alibaba.fastjson.JSONObject; import com.huyan.lucenedemo.util.JedisCli; import org.slf4j.Logger; import org.slf4j.LoggerFactory; import org.springframework.beans.factory.annotation.Value; import org.springframework.web.bind.annotation.GetMapping; import org.springframework.web.bind.annotation.RequestParam; import org.springframework.web.bind.annotation.RestController; import redis.clients.jedis.Jedis; /** * Created by pfliu on 2019/05/08. */ @RestController public class AccessController { private final static Logger logger = LoggerFactory.getLogger(AccessController.class); private static JSONObject zeroJson = new JSONObject(); static { zeroJson.put(\"num\", \"0\"); } @Value(\"${redis.url}\") private String redisUrl; @GetMapping(\"/count\") public String access(@RequestParam(\"s\") String s, @RequestParam(\"callback\") String callback) { try { Jedis jedis = JedisCli.getJedis(redisUrl); JSONObject o = new JSONObject(); String c = jedis.get(s.trim().toLowerCase()); c = null == c ? \"0\" : c; o.put(\"num\", c); return callback + \"(\" + o.toJSONString() + \")\"; } catch (NumberFormatException e) { logger.error(\"get count from {} error\", s, e); e.printStackTrace(); } return callback + \"(\" + zeroJson.toJSONString() + \")\"; } } 前端实现 和以往一样,前端的代码都是凑活实现了功能,这里就不贴了. 实现思路是:在每个页面启动的时候请求刚才提供的API.将返回值写入某个标签即可. 需要注意的几个问题 这里是在编码的时候就能想到的几个问题: 对url的编解码,需要保证写入和读取的key相同. 因为url会自动编码,而在参数中传递的字段又不会,所以在写入的时候需要进行一次解码. url中的大小写 url是大小写敏感的,但是作为参数传递的时候是大小写不敏感的..所以需要注意. 奇怪操作导致的坑 单例Jedis导致的问题 在我的灵机一动之下,初始版本的代码中获取jedis示例使用了下面的代码. public static Jedis jedis; public static Jedis getJedis(String url){ if (null == jedis) { jedis = new Jedis(url); } return jedis; } 算是实现一个伪单例吧,核心思想也是不要建立那么多的jedis对象. 然后在线上出现了,获取的热度值为OK的问题. 开始我以为是写入错误,检查之后发现redis中的值都没有问题.后来根据这个\"OK\"才想到的,因为在redis中set命令的返回值就是OK.所以我觉得可能是,写入和读取都是用同一个jedis实例,而在使用的时候并没有进行加锁等操作来保证线程安全,因此在读取的时候正好拿到了其他线程在写入的返回值.通过将jedis获取方法修改成读取使用同一个对象,写入每次使用一个对象解决了这个问题. 热度自动翻倍 看起来这不是个bug,多好的事啊,哈哈哈. 我在测试时候发现,我请求一次,会被服务器记录三遍. 经过观察,是在服务器上没有kill掉老的服务,而重新起了新的服务导致的,解决方法是编写了启动脚本,在脚本中会kill掉老的服务然后启动新服务,通过执行脚本而不是直接java -jar启动. 完. ChangeLog 2019-05-10 完成 以上皆为个人所思所得，如有错误欢迎评论区指正。 欢迎转载，烦请署名并保留原文链接。 联系邮箱：huyanshi2580@gmail.com 更多学习笔记见个人博客------>呼延十 版权所有，盗版必究 all right reserved，powered by GitbookLast Modified On： 2019-05-11 14:26:39 "},"java/2019-05-19-一致性hash算法及其Java实现.html":{"url":"java/2019-05-19-一致性hash算法及其Java实现.html","title":"一致性hash算法及其Java实现","keywords":"","body":"目录 目录 背景 分配方法 一致性hash原理 使用虚拟节点解决hash不均匀的问题 总结 Java实现一致性hash算法缓存客户端 背景 随着业务系统越来越大,我们需要对API的访问进行更多的缓存,使用Redis是一个很好的解决方案. 但是单台Redis性能不足够且迟早要走向集群的,那么怎么才能良好的利用Redis集群来进行缓存呢? 当一个请求到来,我们如何决定将这个请求的内容缓存在那台Redis服务器上?我们一一道来. 分配方法 随机分配 假设我们有X台服务器,当一个请求来到的时候,我们获取一个0-X的随机数,然后将内容缓存在该服务器上. 这明显是不可选的,想要查询的时候我们自己也不知道在哪,只能逐个遍历服务器,知道拿到为止. hash取模 还有一种常见的方式就是对集群数量进行hash取模.比如我们现在有3台服务器,那么对请求的key进行hash,之后拿到的hashcode对3进行取模,得到的数字就是该key应该存储的服务器. 这样虽然解决了上面的获取问题,但是扩展性极其差,设想一下现在我们需要新添加一台机器,也就是机器数量来到了4,那么对4取模的结果和对3取模的结果基本上全部不一样,也就是说我们需要对所有的key进行一次重新的hash计算并重新存储. 一致性hash 这也是我们今天的重点,它于1997年由麻省理工学院提出.我们在下面单独讲解一下他. 一致性hash原理 其实本质上,一致性hash也是hash取模,只是是永远的对2的32次方-1取模. 一致性hash引入了一个叫做一致性hash环的概念,即将(0-2^32-1)中间的所有整数首尾相接连接成一个环.如下图: 然后将所有的节点映射到环上,假设我们有3个节点,N1,N2.N3.那么如下图: . 之后我们将要存储的所有key也都映射到环上,假设我们有6个key. 这样之后,顺时针旋转key,将其存储在遇到的第一个服务器上,这样有什么好处呢? 那就是扩展性,当新插入一个节点时,只会影响到少部分key,需要重新计算的key很少,我们添加一个节点试试: 可以发现,只有N3数据需要从N2节点迁移到N4. 是不是看起来挺美滋滋的,啥好处都有,有啥缺点呢? 缺点当然有. 上面的图是一种理想状态,基本算是均匀的分布了,但是实际使用中,你用一个集群中的机器名(有很大的可能性很类似)去hash,拿到的结果可能很相近,也就是说,并不是像图中这样分散的,而是聚集在一起,而key是分散的,这样会导致,大量的key命中了其中一个或者多个服务器,而有一部分却空闲.总之,负载不均衡. redis的key都是字符串,而字符串的hashcode方法是可能会返回负值的,而一致性hash环是只有正值的,因此需要我们使用别的hash算法.(淡然你也可以粗暴的进行取绝对值). 使用虚拟节点解决hash不均匀的问题 hash不均匀主要出现在节点很少的时候,那么我们可以手动模拟一些节点出来,也就是所谓的虚拟节点,比如我们只有3个节点,但是我们定义一个规则,比如A-1,A-2,A-3,这三个节点都可以被映射到环上,但是在真正存储的时候我们都存储在A上. 只要我们的虚拟节点足够多,我们就可以让其尽可能的均匀分布在环上. 总结 一致性hash算法是使用虚拟的环状数据结构,解决了简单hash算法中扩展性差的问题,在分布式缓存以及负载均衡中有许多的应用. Java实现一致性hash算法缓存客户端 Java中提供了ConcurrentSkipListMap类,可以很好的使用在这里,不仅可以轻松的模拟环状结构,并发安全且使用跳表结构的ConcurrentSkipListMap可以提供很好的并发性能. 对于虚拟节点的多少,其实是可以大概估算出来的,因此在下面的代码中,我将其作为一个变量,在初始化的时候由当前节点的数量计算得到,当然我没有具体实现计算方法.这么设计是出于什么考虑呢,想让虚拟节点的数量尽量的刚刚好,万一节点很多,还是用固定的虚拟节点,对均匀性提升不会很大,反而会造成性能损耗等. 代码中主要提供了一下几个方法: 初始化,用一个redis配置的字符串 添加和删除节点,会将其虚拟节点一起操作. jedis的get和set操作,当然在实际情况下不会只有这两个方法,这里只做模拟,对更多的方法没有做一个实现. 好了,废话不多说了,都在注释里面了! package util; import redis.clients.jedis.Jedis; import java.util.concurrent.ConcurrentNavigableMap; import java.util.concurrent.ConcurrentSkipListMap; /** * Created by pfliu on 2019/05/19. */ public class ConsistentHashRedis { // 用跳表模拟一致性hash环,即使在节点很多的情况下,也可以有不错的性能 private final ConcurrentSkipListMap circle; // 虚拟节点数量 private final int virtual_size; public ConsistentHashRedis(String configs) { this.circle = new ConcurrentSkipListMap<>(); String[] cs = configs.split(\",\"); this.virtual_size = getVirtualSize(cs.length); for (String c : cs) { this.add(c); } } /** * 将每个节点添加进环中,并且添加对应数量的虚拟节点 */ private void add(String c) { if (c == null) return; for (int i = 0; i tailMap = circle.tailMap(keyHash); String config = tailMap.isEmpty() ? circle.firstEntry().getValue() : tailMap.firstEntry().getValue(); // 注意,由于使用了虚拟节点,所以这里要做 虚拟节点 -> 真实节点的映射 String[] cs = config.split(\"-\"); return new Jedis(cs[0]); } /** * 对外暴露的添加节点接口 */ public boolean addJedis(String cs) { add(cs); return true; } /** * 对外暴露的删除节点节点 */ public boolean deleteJedis(String cs) { delete(cs); return true; } /** * 从环中删除一个节点极其虚拟节点 */ private void delete(String cs) { if (cs == null) return; for (int i = 0; i 完。 ChangeLog 2019-05-19 完成 以上皆为个人所思所得，如有错误欢迎评论区指正。 欢迎转载，烦请署名并保留原文链接。 联系邮箱：huyanshi2580@gmail.com 更多学习笔记见个人博客------>呼延十 版权所有，盗版必究 all right reserved，powered by GitbookLast Modified On： 2019-06-10 14:13:07 "},"java/2019-04-28-优雅的实现程序计时器.html":{"url":"java/2019-04-28-优雅的实现程序计时器.html","title":"优雅的实现程序计时器","keywords":"","body":"日常编码中,如果想对某一段程序计时,应该怎么做呢?比较简单粗暴的办法就是开始和结束各自取当前时间戳. long start = System.currentTimeMillis(); dosomething(); System.out.println(\"做了一些事情:\" + (System.currentTimeMillis() - start)); 其实看起来还好对不对,我偶尔这么用一下也觉得还好,知道某一次维护某一份代码. 前任因为需要对程序的性能做一些优化,所以要找到程序耗时较高的部分,所以几个主要的类里面到处是这种代码,在他进行优化完毕之后并没有进行删除. 而我当时程序已经运行良好了,需要进行代码clean(因为实在是太丑了),一个个删除实在是累skr人. 而且long start = System.currentTimeMillis();这一句实在是不好找,因为他没有引用别的参数,所以并不会有编译器来提醒我哪里还有遗漏的,导致在那之后好久都会偶尔又找到一条呢! 而我在日常写一些奇怪的类的时候,也有打印耗时的需求,比如我前面一些博客里面,说怎么操作优化了效率,总不能空口白话,因此也需要经常的打印程序耗时.我感觉到上面的这种粗暴的办法太傻了,但是也没想到什么好办法,知道看到了Ticker类. 这个类的实现功能是,可以对程序分段计时并标注,并且将代码封装起来,尽量少的侵入业务代码,同时最后以较好的可读性打印出来. 实现方法,维护一个的list,注意前面这么写只是代表了一个对象,而不是一个Map.用户每次手动调用计时的时候,计算与前一次计时之间的间隔时间,将其保存起来,同时,Ticker保存初始化的时间,以及最终调用toString的时间,因此你可以很清楚的看到一个类似于: thing1: 10ms thing2: 20ms total: 30ms 这样子的输出. 下面是类的代码以及使用示例: package util; import java.util.ArrayList; import java.util.List; public class Ticker { private final List tags = new ArrayList<>(2); private final long start; private long last; private long end; public Ticker() { start = System.currentTimeMillis(); last = start; } public void tack() { last = System.currentTimeMillis(); } public void tick(String tag) { long now = System.currentTimeMillis(); tags.add(new T(tag, (int) (now - last))); last = now; } public int total() { if (end == 0) end = System.currentTimeMillis(); return (int) (end - start); } public long getBegin() { return start; } @Override public String toString() { return summary(); } private String summary() { end = System.currentTimeMillis(); StringBuilder sb = new StringBuilder(32); for (T tag : tags) { sb.append(tag.tag).append(\" \").append(tag.since).append(\"ms, \"); } sb.append(\"total \"); if ((end - start) main方法中的测试代码输出: db 1005ms, col 1ms, total 1006ms 是不是感觉好很多了呢. 完全没有什么依赖,没有什么副作用,copy到项目里就能用,眼睛舒服了许多. 完。 ChangeLog 2019-04-28 完成 以上皆为个人所思所得，如有错误欢迎评论区指正。 欢迎转载，烦请署名并保留原文链接。 联系邮箱：huyanshi2580@gmail.com 更多学习笔记见个人博客------>呼延十 版权所有，盗版必究 all right reserved，powered by GitbookLast Modified On： 2019-04-28 23:30:50 "},"java/2019-05-12-Java中的常量类缓存机制.html":{"url":"java/2019-05-12-Java中的常量类缓存机制.html","title":"Java中的常量类缓存机制","keywords":"","body":"还记得被多个对象的判断==/equals支配的恐惧吗? 随便来一个, public static void main(String[] args) { Integer i = 12; //1 Integer i1 = 12; //2 Integer i2 = 129; //3 Integer i3 = 129; //4 System.out.println(i == i1); // 5 System.out.println(i2 == i3); //6 } 这个的输出结果是什么呢? 直接展示答案吧,输出结果是: true false 我们来研究一下为什么. 首先我们要知道,在1.5之后的JDK为我们提供了自动装箱与拆箱,用来解决8中基本类型->对象的转换问题,这一点如果不是很清楚了话可以先google了解一下. 上面代码中的语句1-4无疑都是发生了装箱的,那么我们反编译一下这段代码,来看一下在装箱过程中到底发生了什么. 在命令行中执行以下命令: javac IntegerTest.java javap -v -c -s -l IntegerTest 可以看到输出结果如下: 可以看到自动装箱的时候调用的是Integer.valueOf()方法,那么我们看一下他的实现: public static Integer valueOf(int i) { if (i >= IntegerCache.low && i 当传入的数字在某个范围(这个范围默认是-128到127)之间时,直接返回缓存的一个列表,找一下缓存列表的初始化的地方: private static class IntegerCache { static final int low = -128; static final int high; static final Integer cache[]; static { // high value may be configured by property int h = 127; String integerCacheHighPropValue = sun.misc.VM.getSavedProperty(\"java.lang.Integer.IntegerCache.high\"); if (integerCacheHighPropValue != null) { try { int i = parseInt(integerCacheHighPropValue); i = Math.max(i, 127); // Maximum array size is Integer.MAX_VALUE h = Math.min(i, Integer.MAX_VALUE - (-low) -1); } catch( NumberFormatException nfe) { // If the property cannot be parsed into an int, ignore it. } } high = h; cache = new Integer[(high - low) + 1]; int j = low; for(int k = 0; k = 127; } private IntegerCache() {} } 这是IntegerCache缓存类的实现,在类加载的时候用静态方法快进行了初始化,将缓存范围内的值预先加载好放在数组中. 可以看到对缓存范围的上限数字是通过读取配置来设置的,因此,Integer的缓存范围是可以通过参数-XX:AutoBoxCacheMax=size来设置的. 其他常量类的缓存 这种缓存行为不仅适用于Integer对象。针对所有整数类型的类都有类似的缓存机制。 ByteCache 用于缓存 Byte 对象, 固定范围[-128-127]. ShortCache 用于缓存 Short 对象,固定范围[-128-127]. LongCache 用于缓存 Long 对象,固定范围[-128-127]. CharacterCache 用于缓存 Character 对象, 固定范围[0-127]. 而通过参数设置缓存范围,只有Integer可以.其他的都不允许. ChangeLog 2019-05-10 完成 以上皆为个人所思所得，如有错误欢迎评论区指正。 欢迎转载，烦请署名并保留原文链接。 联系邮箱：huyanshi2580@gmail.com 更多学习笔记见个人博客------>呼延十 版权所有，盗版必究 all right reserved，powered by GitbookLast Modified On： 2019-05-13 00:00:25 "},"java/2019-07-21-Java中几个和时间有关的类.html":{"url":"java/2019-07-21-Java中几个和时间有关的类.html","title":"Java中几个和时间有关的类","keywords":"","body":"目录 目录 前言 TimeUnit Period Duration 总结 前言 闲来无聊,看几个和Java.time有关的类. TimeUnit 在几个月以前,我还记得以前学java的时候的教诲,当需要写一个小时的秒数的时候,不要写int seconds = 3600;,而是要int seconds = 1 * 60 * 60;因为这样可以更加清楚的表达一个小时的秒数这个概念,殊不知,早已经不用这么做了. 在1.5之后的版本中,java.util.concurrent包中提供了TimeUnit这个类,可以方便的进行时间的转换. 它是一个枚举类,包含天,小时,分钟,秒,毫秒,微秒,纳秒等几个实例,且每个实例都有转换到其他实例的方法.使用示例如下. public static void main(String [] args) throws InterruptedException { //2小时的秒数 System.out.println(TimeUnit.HOURS.toSeconds(2)); // 25小时的天数 System.out.println(TimeUnit.HOURS.toDays(25)); // 2秒的毫秒数 System.out.println(TimeUnit.SECONDS.toMillis(2)); } Period 要用基于日期的值（年、月、日）来定义大量的时间，使用周期类。周期类提供了各种 get 方法， 例如 getMonths， getDays 和 getYears，这样您就可以从周期中提取出时间的数量。 如果想获得这段时间的某个时间单元的总数,可以使用ChronoUnit.between(). 使用示例如下:(假设你的生日为1990年2月3号,我们来计算这个人的年龄) public static void testPeriod() { LocalDate now = LocalDate.now(); LocalDate birthday = LocalDate.of(1990, 2, 2); Period p = Period.between(birthday, now); long x = ChronoUnit.DAYS.between(birthday, now); System.out.println(String.format(\"%d years %d months %d days. total %d day.\", p.getYears(), p.getMonths(), p.getDays(), x)); // 检查两个日期的大小,如果前面的大于后面的,返回值为true. System.out.println(p.isNegative()); } 总之,当你想要获取某个日期离现在的总天/月/年数,可以使用ChronoUnit.between(),当你想要获取某个日期离现在的日,月,年可以使用Period Duration Duration比较适合短时间(一天内),高精度的时间间隔计算. public static void testDuration() { Duration d = Duration.between(LocalDateTime.of(2019, 7, 21, 1, 1, 1), LocalDateTime.now()); // 总小时数量 System.out.println(d.toHours()); // 总毫秒数 System.out.println(d.toMillis()); // 是否前面的时间大于后面的时间 System.out.println(d.isNegative()); } 总结 Duration ： 可被转换为天,小时，分钟，秒，毫秒，纳秒 Period ：可被转换为年，月，天 ChronoUnit：可以测量两个时间之间的间隔时间,并且转换为各种时间单元. TimeUnit: 可以做各个时间单元之间的数量转换,比如2小时是多少秒.这种需求. 完. 完。 ChangeLog 2019-05-19 完成 以上皆为个人所思所得，如有错误欢迎评论区指正。 欢迎转载，烦请署名并保留原文链接。 联系邮箱：huyanshi2580@gmail.com 更多学习笔记见个人博客------>呼延十 版权所有，盗版必究 all right reserved，powered by GitbookLast Modified On： 2019-07-21 20:27:01 "},"java/2018-03-13-java8-stream api 入门.html":{"url":"java/2018-03-13-java8-stream api 入门.html","title":"java8-stream api 入门","keywords":"","body":"什么是Stream，为什么需要Stream Stream 作为 Java 8 的一大亮点，它与 java.io 包里的 InputStream 和 OutputStream 是完全不同的概念。它也不同于 StAX 对 XML 解析的 Stream，也不是 Amazon Kinesis 对大数据实时处理的 Stream。 Java 8 中的 Stream 是对集合（Collection）对象功能的增强，它专注于对集合对象进行各种非常便利、高效的聚合操作（aggregate operation），或者大批量数据操作 (bulk data operation)。Stream API 借助于同样新出现的 Lambda 表达式，极大的提高编程效率和程序可读性。 同时它提供串行和并行两种模式进行汇聚操作，并发模式能够充分利用多核处理器的优势，使用 fork/join 并行方式来拆分任务和加速处理过程。通常编写并行代码很难而且容易出错, 但使用 Stream API 无需编写一行多线程的代码，就可以很方便地写出高性能的并发程序。所以说，Java 8 中首次出现的java.util.stream 是一个函数式语言+多核时代综合影响的产物。 ----这段介绍引用自IBM的《Java 8 中的 Streams API 详解》 文章写的非常好，给我很大启发，链接会在文末给出 流的使用过程 使用流的过程分为三个步骤：1.创建一个流2.对其进行操作(可以是多个操作)3.关闭一个流 1.创建流 java8提供了多种构造流的方法 Collection 数组 BufferedReader 静态工厂 自己构建 其他 创建流的示例代码如下： List strList = new ArrayList<>(); strList.add(\"HuHanShi\"); strList.add(\"HuBlanker\"); String[] strings = {\"HuHanShi\", \"HuBlanker\"}; //Collection Stream stream = strList.stream(); stream = strList.parallelStream(); //数组 stream = Arrays.stream(strings); stream = Stream.of(strings); //BufferedReader stream = new BufferedReader(new InputStreamReader(System.in)).lines(); //静态工厂 IntStream streamInt = IntStream.range(0, 10); //自己生成流如果有需要放到最后面说 //其他：随机生成一个int的流 streamInt = new Random().ints(); //其他：按照给定的正则表达式切割字符串后得到一个流 stream = Pattern.compile(\",\").splitAsStream(\"wo,w,wa,a\"); stream.forEach(System.out::println);//输出结果为：wo w wa a 2.操作流 当把数据结构包装成流之后，就要开始对里面的元素进行各种操作了。流的操作分为两种：Intermediate：这类型的方法不会修改原来的流，而是会返回一个新的流以便后续操作。例如：map,filter,sorted.Terminal：这类型的方法会真正的将流进行遍历，在使用过后，流也将会被“消耗”，无法继续操作。接下来将对常用的(我看过的)流的操作方法一一举例说明： map() 对当前的流进行一个操作并将得到的结果包装成一个新的流返回。 //str是个字符串列表，将其转换成大写。 strList.stream().map(String::toUpperCase).collect(Collectors.toList()); flatMap() flatMap与map的区别是他会将stream内部的结构扁平化，对每一个值都将其转化为一个流，最后将所有刘扁平化为一个流返回。 Stream> moreStream = Stream .of(Arrays.asList(1, 8), Arrays.asList(2, 4), Arrays.asList(2, 4, 5, 6)); moreStream.flatMap(Collection::stream).forEach(System.out::println); 输出结果为：1，8，2，4，2，4，5，6.而不是：[1,8],[2,4],[2,4,5,6]. filter() filter 对原始 Stream 进行某项测试，通过测试的元素被留下来生成一个新 Stream。 //留下包含“Hu”的字符串 strList.stream().filter(perStr -> perStr.contains(\"Hu\")).forEach(System.out::print); forEach() forEach 方法接收一个 Lambda 表达式，然后在 Stream 的每一个元素上执行该表达式。 forEach是Terminal操作，当遍历完成时，流被消耗无法继续对其进行操作。 错误示例： //上面的几个示例中用到了forEach来进行打印操作，所以只举一下错误的例子。 //！这句话是错误的，当forEach之后无法再进行map操作。 strList.stream().forEach(System.out::print).map(); peek() 有人要问了，我想对每一个元素进行操作一下但是后续还要用怎么办呢，当然是有办法的，那就是peek()方法。 //先将strList中的字符串打印一遍之后将其转换为大写。 strList.stream().peek(System.out::print).map(perStr->perStr.toUpperCase()).collect(Collectors.toList()); reduce() 这个方法的主要作用是把 Stream 元素组合起来。它提供一个起始值（种子），然后依照运算规则（BinaryOperator），和前面 Stream 的第一个、第二个、第 n 个元素组合。从这个意义上说，字符串拼接、数值的 sum、min、max、average 都是特殊的 reduce。 Integer sum = moreStream.flatMap(Collection::stream).reduce(0,(a,b)->a+b); 这个例子将flatMap中的结果进行了累加操作。reduce()还可以用与字符串连接，求最大最小值等等。 sorted() 对stream中的值进行排序。 strList.sort(String::compareTo); 相比于数组的排序，stream的排序可以先剔除掉一些不需要排序的值，可以减少无用操作。 接下来将一些原理(类型)差不多的放一起说一哈。 limit()/skip() 取前n个元素/跳过前n个元素。 //对strList先取前两个再扔掉第一个然后打印，结果为：HuBlanker。 strList.stream().limit(2).skip(1).forEach(System.out::print); findFirst() 取stream得第一个值，值得一提的是返回值为Optional<>.Optional是一个容器，可以包含一个值，使用它可以尽量避免NullPointException。 具体见：java8 Optional 类初体验 String first = strList.stream().findFirst().get(); min()/max()/distinct() 取最小/最大/无重复值。min和max操作可以通过reduce方法实现，但是因为经常使用所以单独写了出来。 Arrays.asList(1,1,2,3,4,5,6).stream().min(Integer::min); Arrays.asList(1,1,2,3,4,5,6).stream().min(Integer::max); Arrays.asList(1,1,2,3,4,5,6).stream().distinct(); Match类方法 match类方法返回一个boolean值。 allMatch：Stream 中全部元素符合传入的 predicate，返回 true anyMatch：Stream 中只要有一个元素符合传入的 predicate，返回 true noneMatch：Stream 中没有一个元素符合传入的 predicate，返回 true numList.stream().noneMatch(a -> a > 0); numList.stream().allMatch(a -> a > 0); numList.stream().anyMatch(a -> a > 0); 3.关闭一个流(将流转化为其他数据结构) 当我们对一个流进行了足够的操作之后，希望将其转换为数据，List等数据结构方便存储。Stream在转换为其他数据结构的时候也是极其方便的。 //List numList.stream().collect(Collectors.toList()); //Set numList.stream().collect(Collectors.toSet()); //Array numList.stream().toArray(); //String numList.stream().toString(); 结束语 stream的基本用法到这里就差不多啦，以后有时间的话将自己使用的一些具体栗子逐渐补充一下，毕竟有栗子我们看起来总是更加容易懂一些。最后！让我再来引用来自IBM的Stream API 详解中的结束语来结束这篇写了好几天的文章吧。 Stream 的特性可以归纳为： 不是数据结构 它没有内部存储，它只是用操作管道从 source（数据结构、数组、generator function、IO channel）抓取数据。 它也绝不修改自己所封装的底层数据结构的数据。例如 Stream 的 filter 操作会产生一个不包含被过滤元素的新 Stream，而不是从 source 删除那些元素。 所有 Stream 的操作必须以 lambda 表达式为参数 不支持索引访问 你可以请求第一个元素，但无法请求第二个，第三个，或最后一个。不过请参阅下一项。 很容易生成数组或者 List 惰性化 很多 Stream 操作是向后延迟的，一直到它弄清楚了最后需要多少数据才会开始。 Intermediate 操作永远是惰性化的。 并行能力 当一个 Stream 是并行化的，就不需要再写多线程代码，所有对它的操作会自动并行进行的。 可以是无限的 集合有固定大小，Stream 则不必。limit(n) 和 findFirst() 这类的 short-circuiting 操作可以对无限的 Stream 进行运算并很快完成。 参考文章： Java 8 中的 Streams API 详解 ChangeLog 2018-03-18 完成 以上皆为个人所思所得，如有错误欢迎评论区指正。 欢迎转载，烦请署名并保留原文链接。 联系邮箱：huyanshi2580@gmail.com 更多学习笔记见个人博客------>呼延十 版权所有，盗版必究 all right reserved，powered by GitbookLast Modified On： 2019-03-26 11:07:51 "},"java/2018-11-19-java的volatile关键字详解.html":{"url":"java/2018-11-19-java的volatile关键字详解.html","title":"java的volatile关键字详解","keywords":"","body":"前言 在学习ConcurrentHashMap源码的过程中,发现自己对并发编程简直是一无所知,因此打算从最基础的volatile开始学习. volatile虽然很基础,但是对于毫无JMM基础的我来说,也是十分晦涩,看了许多文章仍然不能很好的表述出来. 后来发现一篇文章(参考链接第一篇),给了我一些启示:用回答问题的方式来学习知识及写博客,因为对我这种新手来说,回答别人的问题,总比自己\"演讲\"要来的容易许多. volatile的用法 volatile只可以用来修饰变量,不可以修饰方法以及类 public class Singleton { private volatile static Singleton singleton; private Singleton (){} public static Singleton getSingleton() { if (singleton == null) { synchronized (Singleton.class) { if (singleton == null) { singleton = new Singleton(); } } } return singleton; } } 这是很经典的双重锁校验实现的单例模式,想必很多人都看到过,代码中可能会被多个线程访问的singleton变量使用volatile修饰. volatile的作用及原理 当一个变量被volatile修饰时,会拥有两个特性: 保证了不同线程对该变量操作的内存可见性.(当一个线程修改了变量,其他使用次变量的线程可以立即知道这一修改). 禁止了指令重排序. 1. 保证内存可见性 JMM操作变量的时候不是直接在主存进行操作的,而是每个线程拥有自己的工作内存,在使用前,将该变量的值copy一份到自己的工作内存,读取时直接读取自己的工作内存中的值.写入操作时,先将修改后的值写入到自己的工作内存,再讲工作内存中的值刷新回主存. 类似于下图: 为什么这么搞呢?当然是为了提高效率,毕竟主存的读写相较于CPU中的指令执行都太慢了. 这样就会带来一个问题.当执行 i = i + 1;(i初始化为0) 语句时,单线程操作当然没有问题,但是如果两个线程操作呢?得到的结果是2吗? 不一定. 让我们详细分解一下执行这句话的操作. 读取内存中的i=0到工作内存(1)->工作内存中的i=i+1=1(2)- > 将工作内存中的i=1刷新回主存(3). 这是单线程操作的情况,那么假设当线程1执行到了(2)的时候,线程2开始了,进行完了(1)步骤,那么这时候的情况是什么呢? 线程1位于(2),线程2位于(1). 线程1的工作内存中i=1,线程2的工作内存中i=0,之后分别进行余下的步骤,最后拿到的结果为1. 这是什么原因造成的呢?因为普通的变量没有保证内存可见性.即:线程1已经修改了i的值,其他的线程却没有得到这个消息. volatile保证了这一点,用volatile修饰的变量,读取操作与普通变量相同.但是写入操作发生后会立即将其刷新回主存,并且使其他线程中对这一变量的缓存失效! 缓存失效了怎么办呢?去再次读取主存呗,主存此时已经修改了(立即刷新了),则保证了内存可见性. 小栗子: public class VolatileTest { private static Boolean stop = false;//(1) private static volatile Boolean stop = false;//(2) public static void main(String args[]) throws InterruptedException { //新建立一个线程 Thread testThread = new Thread() { @Override public void run() { System.out.println(); int i = 1; //不断的对i进行自增操作 while (!stop) { i++; } System.out.println(\"Thread stop i=\" + i); } }; //启动该线程 testThread.start(); //休眠一秒 Thread.sleep(1000); //主线程中将stop置为true stop = true; System.out.println(Thread.currentThread() + \"now, in main thread stop is: \" + stop); testThread.join(); } } 这段代码在主线程的第二行定义了一个布尔变量stop, 然后主线程启动一个新线程，在线程里不停得增加计数器i的值，直到主线程的布尔变量stop被主线程置为true才结束循环。 主线程用Thread.sleep停顿1秒后将布尔值stop置为true。 因此，我们期望的结果是，上述Java代码执行1秒钟后停止，并且打印出1秒钟内计数器i的实际值。 然而，执行这个Java应用后，你发现它进入了死循环,程序没有停止. 将(1)处的代码改为(2)处的,即对stop的变量添加volatile修饰,你会发现程序如我们预期的那样停止了. 2.禁止指令重排序 JVM在不影响单线程执行结果的情况下回对指令进行重排序,比如: int i = 1;//(1) int j = 2;//(2) int h = i * j;//(3) 上述代码中,(3)执行依赖于(1)(2)的执行,但是(1)(2)的执行顺序并不影响结果,也就是说当我们进行了上述的编码,JVM真正执行的可能是(1)(2)(3),也可能是(2)(1)(3). 这在单线程中是无所谓的,还会带来性能的提升. 但是在多线程中就会出现问题,比如下面的代码: //线程1 context = loadContext();//(1) inited = true;//(2) //线程2 while(!inited ){ //根据线程A中对inited变量的修改决定是否使用context变量 sleep(100); } doSomethingwithconfig(context); 如果每个线程中的指令都顺序执行,则没有问题,但是在线程1中,两个语句并无依赖关系,因此可能会发生重排序,如果发生了重排序: inited = true;//(2) context = loadContext();//(1) 线程1重排序之后先执行了(2)语句,在线程2中,程序跳出了循环,执行doSomethingwithconfig,因为他认为context已经进行了初始化,然后并没有,就会出现错误. 使用volatile关键字修饰inited变量,JVM就会阻止对inited相关的代码进行重排序.这样就能够按照既定的顺序指执行. volatile总结 volatile是轻量级同步机制,与synchronized相比,他的开销更小一些,同时安全性也有所降低,在一些特定的场景下使用它可以在完成并发目标的基础上有一些性能上的优势.但是同时也会带来一些安全上的问题,且比较难以排查,使用时需要谨慎. volatile的使用场景 使用volatile修饰的变量最好满足以下条件: 对变量的写操作不依赖于当前值 该变量没有包含在具有其他变量的不变式中 这里举几个比较经典的场景: 状态标记量,就是前面例子中的使用. 一次性安全发布.双重检查锁定问题(单例模式的双重检查). 独立观察.如果系统需要使用最后登录的人员的名字,这个场景就很适合. 开销较低的“读－写锁”策略.当读操作远远大于写操作,可以结合使用锁和volatile来提升性能. 注意事项 volatile并不能保证操作的原子性,想要保证原子性请使用synchronized关键字加锁. 参考链接 http://www.techug.com/post/java-volatile-keyword.html http://www.importnew.com/23535.html 完。 ChangeLog 2018-11-22 完成 以上皆为个人所思所得，如有错误欢迎评论区指正。 欢迎转载，烦请署名并保留原文链接。 联系邮箱：huyanshi2580@gmail.com 更多学习笔记见个人博客------>呼延十 版权所有，盗版必究 all right reserved，powered by GitbookLast Modified On： 2019-03-26 11:07:51 "},"java/2019-04-22-Java实现计数器-Counter.html":{"url":"java/2019-04-22-Java实现计数器-Counter.html","title":"Java实现计数器-Counter","keywords":"","body":"试着实现一个更好的计数器.可以对输入的List进行计数. 最终实现版本使用泛型,使得可以对任意对象进行技术,但是在编写过程中,先以String为例. 那么计数这个行为的输入值是List,输出值为Map. 这里不是强行要求Integer的,只要能够标识数量即可. 简单版本 直接随手写一个: HashMap c = new HashMap<>(); stringList.forEach(per->{ c.put(per, c.getOrDefault(per, 0) + 1);//步骤1 }); return c; } 这里面有几个点: Integer是一个不可变的类,因此,在步骤1中发生了,取到当前数字,对其加一生成新的Integer对象,将这个对象放进map里面.频繁的创建中间对象,浪费. 对于需要计数的每一个值,进行了两次map的操作,第一次获取其当前次数,第二次put加一之后的次数. 可变Integer 先解决第一个问题,封装一个可变的Integer类或者使用AtomicInteger. 在没有多线程的要求下,自己封装一个: public static final class MutableInteger { private int val; public MutableInteger(int val) { this.val = val; } public int get() { return this.val; } public void set(int val) { this.val = val; } public String toString() { return Integer.toString(val); } } 对map的操作减少 对于每一个字符串,都需要get确认,然后put新值,这明显是不科学的. HashMap的put方法,其实是有返回值的,会返回旧值. 这就意味着我们可以通过一次map操作来达到目的. 经过这样两次的优化,现在的方法为: public static Map count2(List strings) { HashMap c = new HashMap<>(); strings.forEach(per -> { MutableInteger init = new MutableInteger(1); MutableInteger last = c.put(per, init); if (last != null) { init.set(last.get() + 1); } }); return c; } 简单测试一下: public static void main(String[] args) { List list = new ArrayList<>(); String[] ss = {\"my\", \"aa\", \"cc\", \"aa\", \"cc\", \"b\", \"w\", \"sssssa\", \"10\", \"10\"}; for (int i = 0; i 测试结果如下: {aa=20000000, cc=20000000, b=10000000, w=10000000, sssssa=10000000, my=10000000, 10=20000000} 4234 {aa=20000000, cc=20000000, b=10000000, w=10000000, sssssa=10000000, my=10000000, 10=20000000} 951 可以看到结果非常明显,效率提高了4倍. NOTE: 这个测试明显是有偏向的,因为我这个1亿条数据,只有几种,所以数据重复率非常高.但是日常使用中数据重复率不会有这么夸张. 但是构建1亿条重复率不高的测试数据,太麻烦了. 分析 其实起作用比较大的是可变的Integer类. 而map的操作我们知道,取和放到时O(1)的.所以这个的提升不是特别的大.经测试,修改为两次操作,仅增加80ms. 最终代码(使用泛型实现通用类) 实现了以下几个API: add(T): 向计数器添加一个值. addAll(List): 一次性添加多个值.以List的形式. get(T): 返回该值目前的数量. getALl(): 返回该计数器目前所有的计数信息.形式为,Map package daily.counter; import java.util.HashMap; import java.util.List; import java.util.Map; /** * Created by pfliu on 2019/04/21. */ public class Counter { private HashMap c = new HashMap<>(); public void add(T t) { MutableInteger init = new MutableInteger(1); MutableInteger last = c.put(t, init); if (last != null) { init.set(last.get() + 1); } } public void addAll(List list) { list.forEach(this::add); } public int get(T t) { return c.get(t).val; } public Map getAll() { Map ret = new HashMap<>(); c.forEach((key, value) -> ret.put(key, value.val)); return ret; } public static final class MutableInteger { private int val; MutableInteger(int val) { this.val = val; } public int get() { return this.val; } void set(int i) { this.val = i; } } } 当然你完全不用自己实现,网上一大把已经实现的. 但是自己思考一下为什么要这样实现,还是有很多的好处的. 联系我 最后，欢迎关注我的个人公众号【 呼延十 】，会不定期更新很多后端工程师的学习笔记。 也欢迎直接公众号私信或者邮箱联系我，一定知无不言，言无不尽。 完。 ChangeLog 2019-04-22 完成 以上皆为个人所思所得，如有错误欢迎评论区指正。 欢迎转载，烦请署名并保留原文链接。 联系邮箱：huyanshi2580@gmail.com 更多学习笔记见个人博客------>呼延十 版权所有，盗版必究 all right reserved，powered by GitbookLast Modified On： 2020-11-02 11:27:33 "},"java/2018-11-28-Java8-Date-Time-使用案例.html":{"url":"java/2018-11-28-Java8-Date-Time-使用案例.html","title":"Java8-Date-Time-使用案例","keywords":"","body":"PS: 本文的代码保证正确性,原则是:下一次使用时直接copy可用. 工作中遇到新的需求会更新此文. 对日期及时间的处理,我们都不陌生,但是总会有你不熟悉的新需求产生,毕竟产品经理的奇思妙想是很多的. 本文记录日常工作中使用到的获取特殊时间点的一些方式,不一定出厂最优解,但我会努力改进至最优解. 时间戳转换为LocalDateTime long showTime = System.currentTimeMillis(); LocalDateTime localDateTime = LocalDateTime.ofInstant(Instant.ofEpochMilli(showTime),ZoneId.of(\"Asia/Shanghai\")); LocalDateTime格式化输出 String s = LocalDateTime.now().format(DateTimeFormatter.ofPattern(\"yyyy-MM-dd HH:mm:ss\")); System.out.println(s); 获取当天的时间戳范围(0点-24点) long start = Timestamp.valueOf(LocalDateTime.of(LocalDate.now(), LocalTime.MIN)).getTime(); long end = Timestamp.valueOf(LocalDateTime.of(LocalDate.now(), LocalTime.MAX)).getTime(); 获取当前时间一天前的时间戳 long time = Timestamp.valueOf(LocalDateTime.now().minusDays(1)).getTime(); 日期的字符串转换为时间戳 private Long dateTimeStrToTimeStamp(String dateTime) { //解析日期 LocalDateTime localDateTime = LocalDateTime .parse(dateTime.substring(0,19), DateTimeFormatter.ofPattern(\"yyyy-MM-dd HH:mm:ss\")); //获取时间戳 return Timestamp.valueOf(localDateTime).getTime(); } 获取下周一和下周日的LocalDate LocalDate start = LocalDate.now().plusDays(8 - LocalDate.now().getDayOfWeek().getValue()); LocalDate end = LocalDate.now().plusDays(14 - LocalDate.now().getDayOfWeek().getValue()); ChangeLog 2018-11-28 添加了前五个 以上皆为个人所思所得，如有错误欢迎评论区指正。 欢迎转载，烦请署名并保留原文链接。 联系邮箱：huyanshi2580@gmail.com 更多学习笔记见个人博客------>呼延十 版权所有，盗版必究 all right reserved，powered by GitbookLast Modified On： 2019-04-15 15:36:17 "},"java/2018-11-18-抽象类和接口的区别.html":{"url":"java/2018-11-18-抽象类和接口的区别.html","title":"抽象类和接口的区别","keywords":"","body":"面试中经常会问到这个问题,那么我们到底应该怎么回答呢? 语法方面 首先,在java语言中,抽象类和接口在语法方面就是有一些区别的,总结整理如下: 相同点 都是位于较上层的抽象层. 都不能被实例化. 都可以只声明方法,不实现. 不同点 抽象类可以有不抽象的方法,即某个方法有默认的实现,而接口不可以. 使用抽象类使用extends关键字集成,而接口使用implement关键字来实现. 抽象类可以有构造器,接口不可以. 抽象类里的方法可以使用public,protected,default等修饰符,接口的只可以是public. 抽象类可以有main方法,接口不可以. 继承抽象类的类必须实现所有抽象方法,否则自身也是抽象类,接口的实现类必须实现所有抽象方法. 设计思想方面 上面语法方面的知识重要吗?重要,不了解的话你无法使用它们. 但是上面的不同点足以让我们来判断在某一个场景下该使用哪个吗? 我觉得不是,我觉得使用他他们最重要的是设计思想方面. 假如,现在要设计一个Door的类.我们通过两种方式都可以实现. //抽象类 abstract class AbstractDoor { public abstract void open(); public abstract void close(); } //接口 interface Door { void open(); void close(); } 这两种实现那种比较好一些?都还行,简单易懂. 那么这时候我们需要给门添加报警功能,变成防盗门!怎么做呢? abstract class AbstractDoor { public abstract void open(); public abstract void close(); public abstract String alarm(); } interface Door { void open(); void close(); void alarm(); } 将上述代码改成这样吗?这样好吗? 细想一下,门是一个实体,门的抽象类里面应该有报警功能吗? 因此,我们其实应该做的是这样的. abstract class AbstractDoor { public abstract void open(); public abstract void close(); } interface Alarmable { void alarm(); } 定义一个抽象类AbstractDoor,作为门的基类,同时定义一个alarmable的接口.(alarmable是我自己写的,我不知道有没有这个单词,大家懂就好). 定义了一个门的抽象类,所有的门都必须有这两个方法.(不能开关的叫什么门啊!),同时定义了一个可报警的接口,当我们需要一个防盗门的时候,只需要继承AbstractDoor,同时实现Alarmable的接口,这样就拥有了这三个方法. 同时,这样做的扩展性极好,当你发现门应该多一个共同的方法时,比如,锁住,你可以在AbstractDoor中扩展,当你需要一个可以报警的窗户的时候,你可以实现Alarmable接口.岂不是美滋滋. 面试中如何回答我不敢给出正确答案,但是我认为,代码是写给人看的,所以你需要正确的设计以及正确的命名,来让代码的阅读者一看便懂,而不是深陷与语法,毕竟语法可以被创造.否则,我们需要抽象类和接口的区别干什么?直接将所有项目中用到的方法一股脑塞进一个类不就好了. 注意事项 本文的区别仅限于通俗意义上的区别. 另外,在java8中,Oracle已经开始尝试向接口中引入默认方法和静态方法，以此来减少抽象类和接口在语法上的差异。在java8之后,我们可以为接口提供默认实现的方法并且不用强制子类来实现它.有兴趣的胖友可以移步这里查看一哈.Java8 接口的静态方法和默认方法. 完。 ChangeLog 2018-11-18 完成 以上皆为个人所思所得，如有错误欢迎评论区指正。 欢迎转载，烦请署名并保留原文链接。 联系邮箱：huyanshi2580@gmail.com 更多学习笔记见个人博客------>呼延十 版权所有，盗版必究 all right reserved，powered by GitbookLast Modified On： 2019-03-26 11:07:51 "},"java/2018-03-31-java8-Date-Time-api.html":{"url":"java/2018-03-31-java8-Date-Time-api.html","title":"java8-Date-Time-api","keywords":"","body":"java8里面新增了一套处理时间和日期的API，为什么要搞一套全新的API呢，因为原来的java.util.Date以及Calendar实在是太难用了。如果你有过在程序中处理时间的经验你就会知道，在java8以前，处理时间是多么让人痛苦。 举个简单的小栗子： 如果你需要查询当前周的订单，那么你需要先获取本地时间，然后根据本地时间获取一个Calendar，然后对Calendar进行一些时间上的加减操作，然后获取Calendar中的时间。 而在java8中，你只需要这样： LocalDate date = LocalDate.now(); //当前时间减去今天是周几 LocalDate start = date.minusDays(date.getDayOfWeek().getValue()); //当前时间加上（8-今天周几） LocalDate end = date.plusDays(8 -date.getDayOfWeek().getValue()); 是不是很简单呢，接下来就将看一下java8的时间api具体怎么使用吧。 java8中提供里真正的日期，时间分割开来的操作，LocalDate是日期相关操作，LocalTime是时间(即每天24个小时)的操作。想要获取时间及日期的话请使用LocalDateTime. LocalDate首先，获取日期： // 取当前日期： LocalDate today = LocalDate.now(); // -> 2014-12-24 // 根据年月日取日期，12月就是12： LocalDate crischristmas = LocalDate.of(2014, 12, 25); // -> 2014-12-25 // 根据字符串取： LocalDate endOfFeb = LocalDate.parse(\"2014-02-28\"); // 严格按照ISO yyyy-MM-dd验证，02写成2都不行，当然也有一个重载方法允许自己定义格式 LocalDate.parse(\"2014-02-29\"); // 无效日期无法通过：DateTimeParseException: Invalid date 日期转换： // 取本月第1天： LocalDate firstDayOfThisMonth = today.with(TemporalAdjusters.firstDayOfMonth()); // 2014-12-01 // 取本月第2天： LocalDate secondDayOfThisMonth = today.withDayOfMonth(2); // 2014-12-02 // 取本月最后一天，再也不用计算是28，29，30还是31： LocalDate lastDayOfThisMonth = today.with(TemporalAdjusters.lastDayOfMonth()); // 2014-12-31 // 取下一天： LocalDate firstDayOf2015 = lastDayOfThisMonth.plusDays(1); // 变成了2015-01-01 // 取2015年1月第一个周一，这个计算用Calendar要死掉很多脑细胞： LocalDate firstMondayOf2015 = LocalDate.parse(\"2015-01-01\").with(TemporalAdjusters.firstInMonth(DayOfWeek.MONDAY)); // 2015-01-05 LocalTime获取时间： //包含毫秒 LocalTime now = LocalTime.now(); // 11:09:09.240 //不包含毫秒 LocalTime now = LocalTime.now().withNano(0)); // 11:09:09 //构造时间 LocalTime zero = LocalTime.of(0, 0, 0); // 00:00:00 LocalTime mid = LocalTime.parse(\"12:00:00\"); // 12:00:00 LocalDateTime的很多操作都和LocalDate差不多，具体的请查看一下源码就秒懂了。 提醒一下朋友们：千万不要觉得学习LocalDate及相关操作很麻烦，而继续使用java.util.date,因为当你认真的看一下，你会发现用不了半个小时你就可以基本掌握LocalDate的使用。而这半个小时带来的效率提升，代码质量的提升是很大的。 我就是很早就知道了LocalDate但是懒得学习，总觉得java.util.Date可以凑活使用即使他很渣，但是当我终于静下心来学了一下之后，后悔莫及！！！！我为什么没有早点认真学习呢！我为什么要使用愚蠢的java.util.Date那么久呢！！！ ChangeLog 2018-03-31 完成 以上皆为个人所思所得，如有错误欢迎评论区指正。 欢迎转载，烦请署名并保留原文链接。 联系邮箱：huyanshi2580@gmail.com 更多学习笔记见个人博客------>呼延十 版权所有，盗版必究 all right reserved，powered by GitbookLast Modified On： 2019-05-13 10:00:10 "},"java/2018-03-11-java8-Optional类初体验.html":{"url":"java/2018-03-11-java8-Optional类初体验.html","title":"java8-Optional类初体验","keywords":"","body":"众所周知，在java语言开发中，NullPointerException是一直被大家所深恶痛绝的。然而在以前的java版本中，对空值的判断有繁琐而无趣。且十分影响代码的美观。例如下面这种情况： User user = ......; if (user != null){ String name = user.getName(); if (name != null){ log.debug(name); } log.debug(\"the name is not exist!\"); }else { log.debug(\"the user is not exist!\"); } 这种代码真的是，，，，，，脑壳疼。然而在java 8 中，这种情况得以改善了！那就是引入了Optional类。 Optional实际上是个容器：它可以保存类型T的值，或者仅仅保存null。Optional提供很多有用的方法，这样我们就不用显式进行空值检测。 所幸OPtional 类的源码加上注释不过三百多行，我就将其中的方法一一道来。 构造方法 Optional的构造方法有三种，Optional.of(),Optional.ofNullable(),Optional.empty()。Optional.of(T)这种构造方式要求栓如的值不能为空，否则直接回抛出NullPointException。Optional.ofNullable(T)这种构造方式可以接受空值，当参数为空值时调用Optional.empty()构造一个空的Optional对象。Optional.empty()字面意思。 其他方法 isPresent() 返回boolean，表示Optional的值是否为空。 强烈不见使用此方法，因为它的作用和 return user != null 一毛一样，甚至我觉得他还没有后者通俗易懂。。get()取到Optional内部的value，即构造时传入的对象。 不建议。。。接下来的就是重点了！ ifPresent(Consumer consumer)通俗点讲，这个方法的作用是：存在则对它做点什么。栗子： Optional userOpt = Optional.of(user); userOpt.ifPresent(System.out::println); // no elegant method! if (userOpt.isPresent()){ System.out.println(userOpt.get()); } 几个orElseorElse(T)作用：存在则返回，为空则返回默认值。 userOpt.orElse(new User()); userOpt不为空时则返回他的值，为空值返回一个默认值，即新的User对象。 orElseGet(Supplier other) 作用:存在则返回，不存在则返回一个有函数产生的对象。 userOpt.orElseGet(()-> make()); User make(){ return new User(\"huyanshi\",18,\"china\"); } 这里的make()方法很没有必要，，，，可以直接由orElse()来设置默认值的，但是我偷懒了。。 orElseThrow(Supplier exceptionSupplier) 作用：存在则返回，不存在则抛出异常，具体抛啥异常可以自己定义。 userOpt.orElseThrow(MyException::new); map map(map(Function mapper)) 如果有值，则对其执行调用mapping函数得到返回值。如果返回值不为null，则创建包含mapping返回值的Optional作为map方法返回值，否则返回空Optional。 map方法用来对Optional实例的值执行一系列操作。通过一组实现了Function接口的lambda表达式传入操作。 //map方法执行传入的lambda表达式参数对Optional实例的值进行修改。 //为Lambda表达式的返回值创建新的Optional实例作为map方法的返回值。 Optional upperName = myValue.map((value) -> value.toUpperCase()); System.out.println(upperName.orElse(\"No value found\")); flatMap(Function如果有值，为其执行mapping函数返回Optional类型返回值，否则返回空Optional。flatMap与map（Funtion）方法类似，区别在于flatMap中的mapper返回值必须是Optional。调用结束时，flatMap不会对结果用Optional封装。flatMap方法与map方法类似，区别在于mapping函数的返回值不同。map方法的mapping函数返回值可以是任何类型T，而flatMap方法的mapping函数必须是Optional。 //map方法中的lambda表达式返回值可以是任意类型，在map函数返回之前会包装为Optional。 //但flatMap方法中的lambda表达式返回值必须是Optionl实例。 upperName = myValue.flatMap((value) -> Optional.of(value.toUpperCase())); System.out.println(upperName.orElse(\"No value found\")); map和flatmap使用方法类似，区别仅在于mapper方法的返回值类型不同，flatmap方法不会发展返回值再使用Optional进行封装，因此传入的方法必须返回Optional类型。filter如果有值并且满足断言条件返回包含该值的Optional，否则返回空Optional。filter个方法通过传入限定条件对Optional实例的值进行过滤。对于filter函数我们可以传入实现了Predicate接口的lambda表达式。 userOpt.filter(user1 -> user1.getName().length() > 6); 如果user的名字长度大于6则返回自身，小于6则返回一个空值。 完。 版权所有，盗版必究 all right reserved，powered by GitbookLast Modified On： 2019-03-26 11:07:51 "},"java/集合/2019-05-02-Java中-Comparable和-Comparator的区别及联系.html":{"url":"java/集合/2019-05-02-Java中-Comparable和-Comparator的区别及联系.html","title":"Java中-Comparable和-Comparator的区别及联系","keywords":"","body":"其实我现在觉得关系不是很大...但是在今天及以前我也一直很迷惑,所以还是将自己的一些理解写出来备忘. Comparable Comparable定义在java.lang包里,意味着可以被比较的能力,因此某个类想要可以被排序,被比较大小,需要实现这个接口. public int compareTo(T o); 接口里只定义了这一个方法,代表了:传入一个对象,将对象和元素自身进行比较,如果元素自身大,返回1,相等返回0,元素自身小于参数则返回-1. 例如: private static class Student implements Comparable { int id; String name; int age; @Override public int compareTo(Object o) { return this.id - ((Student) o).id; } } 代码中定义了Student类,以及实现了Comparable,即只比较他们的id的大小即可. Comparator Comparator定义与java.util包中,代表着一个角色,这个角色的功能是对传入的两个元素进行大小的比较,并且返回结果. int compare(T o1, T o2); 这是最主要的一个方法,我们需要传入两个同一类型的元素. 使用示例: private static class StudentCom1 implements Comparator{ @Override public int compare(Student o1, Student o2) { return o1.id - o2.id; } } 代码中定义了一个Student的比较器,实现了Comparator. 他们的区别及联系 那么问题来了,都有Comparable了,还要Comparator干什么? 设想一个场景,我们定义了一个学生类,如上面代码所示,那么学生可以按着id的大小进行排序. 然后现在有两个使用的地方,第一个是考试,需要学生按照id排序.第二个是学生统计,需要学生按照年龄进行排序. 怎么实现两种完全不同的排序方式呢?或者更极端一点,一会需要按照id增序,一会需要按照id降序呢?改源代码肯定是不科学的. 这个时候就可以采用以下方案: 学生实现自然排序,即最通用的那种排序方式,比如按照id增序. 实现几个不同的比较器,比如运动会比较器,吃饭比较器等等. 在需要默认排序的情况下,直接调用学生的comparTo即可. 在特定情景下,调用集合类的排序方法,传入一个想要的比较器即可. 总结 他们的区别是角色不同,想要实现的目的也不同.一个是内部自然排序,只能有一种定义.一个是外部的比较器,可以定义多个不同的比较器,按需取用. 唯一的联系可能就是他们最终都是对两个元素定义一个孰大孰小? ChangeLog 2019-05-02 完成 以上皆为个人所思所得，如有错误欢迎评论区指正。 欢迎转载，烦请署名并保留原文链接。 联系邮箱：huyanshi2580@gmail.com 更多学习笔记见个人博客------>呼延十 版权所有，盗版必究 all right reserved，powered by GitbookLast Modified On： 2019-05-01 23:17:49 "},"java/2019-01-29-Java的序列化与反序列化.html":{"url":"java/2019-01-29-Java的序列化与反序列化.html","title":"Java的序列化与反序列化","keywords":"","body":"前言 Java的序列化与反序列化是Java中比较重要的一个知识,本文将总结一下,怎么使用序列化功能以及经常遇到的一些问题的解答. 什么是Java的序列化 JDK提供给我们的,可以将某一个对象转化为二进制字节流保存,并从字节流恢复对象的一种技术. 我们可以再网络传输对象,或者持久化对象时使用这项技术. 怎么进行序列化与反序列化 Java中通过继承Serializable接口来获得序列化与反序列化的能力,使用ObjectInputStream和ObjectOutputStream来进行具体的对象序列化读写. 示例如下: package daily; import java.io.FileInputStream; import java.io.FileOutputStream; import java.io.ObjectInputStream; import java.io.ObjectOutputStream; import java.io.Serializable; import java.util.ArrayList; /** * created by huyanshi on 2019/1/29 */ public class SerializTest implements Serializable { private static int staticValue = 10; private int value; SerializTest(int value) { this.value = value; } public static void main(String[] args) { try { //初始化 SerializTest test = new SerializTest(100); //序列化 ObjectOutputStream oos = new ObjectOutputStream( new FileOutputStream(\"/Users/pfliu/Desktop/serialized.ser\")); System.out.println(test.value); System.out.println(SerializTest.staticValue); oos.writeObject(test); SerializTest.staticValue = 250; //反序列话 ObjectInputStream ois = new ObjectInputStream( new FileInputStream(\"/Users/pfliu/Desktop/serialized.ser\")); SerializTest test1 = (SerializTest) ois.readObject(); System.out.println(test1.value); System.out.println(SerializTest.staticValue); } catch (Exception e) { System.out.println(\"error\"); } } } 在上面的代码中,我们new了一个对象,并将其进行了序列化与反序列化,并在序列化之前和反序列化之后打印了对象的值,结果为值相同.同时,在桌面上生成了Serialized.set文件. 为什么必须要实现Serializable接口? 点开该接口的源码,我们可以发现,这是一个空的接口,即没有任何的定义,那么它是怎么使用的呢? 在序列化的过程中,我们会调用ObjectOutputStream的writeObject方法,该方法,该方法调用writeObject0方法,该方法中有如下代码: if (obj instanceof String) { writeString((String) obj, unshared); } else if (cl.isArray()) { writeArray(obj, desc, unshared); } else if (obj instanceof Enum) { writeEnum((Enum) obj, desc, unshared); } else if (obj instanceof Serializable) { writeOrdinaryObject(obj, desc, unshared); } else { if (extendedDebugInfo) { throw new NotSerializableException( cl.getName() + \"\\n\" + debugInfoStack.toString()); } else { throw new NotSerializableException(cl.getName()); } } 可以看到,对传入的对象进行了几次判断,分别判断传入对象是否为:String,Array,Enum,Serializable. 什么意思呢?就是JDK规定了,只有字符串,数组,枚举,Serializable四种对象才允许序列化,其他的都会抛出NotSerializableException异常. 而这四种中,前面三种都是内定的,只有最后一种是留给程序员的序列化通道,因此我们想要序列化某一个类,必须实现Serializable接口. 序列化ID是干什么用的? 在看一些开源框架的代码时,发现他们的类都会有private static final long serialVersionUID = 8683452581122892189L;这个属性,这是用来干什么的呢? 序列化和反序列化的匹配是怎么匹配的?总不能随便来的吧,A类序列化后的二进制文件,B类能从哪里读出一个对象来嘛? 不能,类的路径以及功能代码必须完全相同,而序列化ID也是用来补充这一判断的. 试想一下,你在服务里new了一个对象,并将其序列化使用网络传输,那么收到这个二进制流的人都能序列化吗?不是的,他必须在自己的服务中有同样的类路径,同样的类定义,同时,他的类中定义的序列化ID必须与你的一致才可以.算是一定程度上的安全性保证吧. 当然,日常开发中我们使用默认生成的1L即可. 静态变量的序列化 我在上面的代码中,定义了一个静态变量,他也能被序列化吗? 在序列化之后,对静态变量重新赋值,那么两次打印的值相等吗? 打印结果是: 10 250 为什么呢?这个问题其实比较简单,静态变量是属于类的,而我们是序列化了对象,因此不包含类的静态变量是正常的. transient 关键字 transient 关键字用于在序列化时,忽略某一个字段,在反序列化后该字段为初始值,比如int=0,对象引用为null. ArrayList 的序列化 看了这么多理论知识,我们来看一下常用类ArrayList是怎么序列化的吧. ArrayList实现了Serializable自然不必多说,其中用来保存数据的属性定义为: /** * The array buffer into which the elements of the ArrayList are stored. * The capacity of the ArrayList is the length of this array buffer. Any * empty ArrayList with elementData == DEFAULTCAPACITY_EMPTY_ELEMENTDATA * will be expanded to DEFAULT_CAPACITY when the first element is added. */ transient Object[] elementData; // non-private to simplify nested class access 为什么会定义为transient呢?我序列化一个ArrayList,你不给我存储内部的值?我要你个空壳子干啥!我摔! 稳住,我们可以实际测试一下,会发现在序列化及反序列化的过程中,是保留了list中的值的. 为什么要定义为transient呢?怎么做到仍然保留数据的呢? 第一个问题 ArrayList内部是使用数组实现的,虽然他是动态数组,但是也是数组. 也就是说,当你定义了长度为100的Arraylist,只放入了一个对象,剩下的99个就为空了. 序列化的时候有必要将这99个空也记录下来吗?没有.因此定义为了transient. 第二个问题 在序列化的过程中,虚拟机会试图调用被序列化类的writeObject和readObject方法,调用不到才会去执行默认的这两个方法,也就是对应的输入输出流中的方法. 在ArrayList中有如下代码: private void writeObject(java.io.ObjectOutputStream s) throws java.io.IOException{ // Write out element count, and any hidden stuff int expectedModCount = modCount; s.defaultWriteObject(); // Write out size as capacity for behavioural compatibility with clone() s.writeInt(size); // Write out all elements in the proper order. for (int i=0; iArrayList instance from a stream (that is, * deserialize it). */ private void readObject(java.io.ObjectInputStream s) throws java.io.IOException, ClassNotFoundException { elementData = EMPTY_ELEMENTDATA; // Read in size, and any hidden stuff s.defaultReadObject(); // Read in capacity s.readInt(); // ignored if (size > 0) { // be like clone(), allocate array based upon size not capacity int capacity = calculateCapacity(elementData, size); SharedSecrets.getJavaOISAccess().checkArray(s, Object[].class, capacity); ensureCapacityInternal(size); Object[] a = elementData; // Read in all elements in the proper order. for (int i=0; i 可以在代码中看到,ArrayList自定义的序列化方法,没有序列化99个空值,只序列化了有意义的值. 总结 1.java的序列化需要实现Serializable接口,之后使用ObjectOutputStream及ObjectInputStream进行读写. 2.必须实现Serializable是因为JDK中进行了检查,不属于那四个类就会抛异常且不允许序列化. 3.序列化ID可以起到验证是不是同一个类的作用,当然是在两个类的代码完全一样的基础上. 4.transient关键字可以忽略一些字段,使其不参与序列化. 5.静态变量是不会序列化的,因为序列化的是对象,而静态变量属于类. 6.可以参考ArrayList的实现方法实现自己的自定义序列化,在这个自定义的过程中,可以做许多事情,比如对某些字段加密(常用于密码字段). 参考链接 https://www.ibm.com/developerworks/cn/java/j-lo-serial/index.html https://www.hollischuang.com/archives/1140 联系我 最后，欢迎关注我的个人公众号【 呼延十 】，会不定期更新很多后端工程师的学习笔记。 也欢迎直接公众号私信或者邮箱联系我，一定知无不言，言无不尽。 完. ChangeLog 2019-01-28 完成 以上皆为个人所思所得，如有错误欢迎评论区指正。 欢迎转载，烦请署名并保留原文链接。 联系邮箱：huyanshi2580@gmail.com 更多学习笔记见个人博客------>呼延十 版权所有，盗版必究 all right reserved，powered by GitbookLast Modified On： 2020-11-02 11:27:33 "}}