# 推荐系统概述


召回->粗排->精排->重排



# ItemCf

物品间的相似如何计算?  基于行为， 喜欢A的人也喜欢B。 那么A和B有相似性.

实现:

(用户对A的兴趣 * A和B的相似性.) + (用户对C端兴趣 * C和B的相似性) 全部加起来得到用户对B的兴趣.


物品相似度:

用户重复度。

这个视频讲得很好， 基本上讲解了itemcf的原理， 到如何工业界实现.

icf 是工业界最重要的召回通道之一。 重点.

两个索引:

* 用户-> 喜欢的物品
* 物品 -> 相似的物品.

当前我们的实现:

**开聊等行为的id, 让simdb去merge，指定活跃度和比例。  是否有更多可以调整的地方, 合并策略，如何从 n * k 个结果中，拿到limit?**

# itemcf变体: swing. 

放到单独文件了.

# ucf 

![s16150306152022](http://img.couplecoders.tech/s16150306152022.png) 


列表重合度.

对小红书来说,有点赞重合度, 关注作者重合度.

线上召回流程.

召回的很多,都用相应的公式算个分,取分最高的100个,返回给后续流程,为什么我们搞这么多呢? 我们当然有截断, 但是我们搞了好多


# 向量召回 矩阵补充,最近邻查找

矩阵补充是个模型. 离谱

其实是, 补充"未曝光"的部分的分数, 然后取高分推荐给用户

缺点:

1. 没用到物品属性,只用了ID
2. 负样本的选取方法不对
3. 模型不好, 内积不如余弦, 回归不如分类.

模型只能打分,用作召回用最近邻查找.

近似最近邻算法查找:

* Milvus, Faiss, Hnswlib.
* 近邻标准 (内积,余弦,欧氏距离等)

划扇形, 做缓存,找最近邻还挺快的呢.

# 双塔模型

用户,物品两个塔. 

各取各的id,离散特征,连续特征等其他特征.

最后拟合,就叫做双塔?

有三种训练双塔模型的方法.

两篇论文:
facebook, youtube.

* Poniwise:
二分类问题

* PairWise:
三元组训练

损失函数. 好几个. 

* ListWise

1正向, 一堆负样本.

最小化交叉啥, 也就是损失函数.







# 双塔的正负样本选择:

* 用户点击过的正样本
* 负样本(简单负采样和困难负采样)
 * 没召回的: 随机非均匀负采样,
 * 排序丢了的
 * 排序了没曝光的
 * 曝光了没有点击,这是错误的负样本.这是排序的负样本.


过采样或者降采样,控制下热冷门物品.



# 双塔的线上召回和模型更新

召回 

物品向量保存到向量数据库. 实时算用户向量. 用户向量作为query,查询k个最近邻.

物品稳定, 用户不稳定.

更新

* 全量更新 每天用前一天的做一个 1 epoch.
* 增量更新 online learning.

只更新embeddin层的参数.

全量训练效果更好. 




# 其他召回 

* GEOHash召回 
* 城市召回
* 关注,有交互作者召回
* 相似作者召回
* 缓存召回, 复用前n次推荐精排的结果, 需要退场, 很多退场的规则.

# 物品冷启动

促发布

* 精准,别让用户反感
* 激励发布
* 挖掘高潜

评价指标:
* 发布渗透率,人均发布量
* 点击率,交互率
* 消费市场,月活,日常
* 高热笔记占比

# 冷启动的召回

![s20373606152022](http://img.couplecoders.tech/s20373606152022.png)

双塔优化

* default embedding. 学习出来的
* 用相似的笔记的embedding.
* 多个向量召回池.

关键词, 类目召回.

只对最新笔记有用, 弱个性化,不精准.

# 聚类召回

内容相似笔记. 相当于prop?

神经网络. 

搞集群, 1000个集群, 相当于搞索引. 

划分1000个区域这种, 每个区域有一堆.

内容相似度模型.

笔记取向量. 其实就是prop的相似度啊. 

训练过程有点像双塔. 

Triplet hinge loss, 损失函数. 

正负样本:

itemcf, 帮忙搞正样本

负样本, 随机负采样. 

# loo-alike 人群扩散


计算用户相似度:

* userCF
* ID inbedding.


扩散别的用户.

笔记被点过,那些人的向量平均,就是笔记的向量.

然后笔记向量写入数据库, 用户query来查找,就能查找到了. 

简直离谱.

